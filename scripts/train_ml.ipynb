{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from IPython.display import display\n",
    "from joblib import dump\n",
    "from sklearn import set_config\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
    "                             f1_score, make_scorer)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import XGBClassifier, plot_tree\n",
    "\n",
    "from ml_model import PipelineManager, PredictionPipeline\n",
    "from utils.GPU_models import KerasClassifierModel, gpu_model_hub\n",
    "from utils.preprocessing_utils import (clean_and_preprocess_datasets,\n",
    "                                       clean_labs, clean_notas,\n",
    "                                       clean_sociodemograficos,\n",
    "                                       disease_tests_list, merge_classes,\n",
    "                                       merge_labs_notas,\n",
    "                                       word_count_feat_engineering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"diagram\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Feature and data config\n",
    "balance_classes = 'oversample' # False, 'oversample', or 'undersample'\n",
    "retrain_with_class_weight=False\n",
    "add_gpu_prediction = False\n",
    "consolidate_classes = False\n",
    "as_dual_class=False\n",
    "target_feature = 'CÃ³digo'\n",
    "text_feature = 'Plan'\n",
    "\n",
    "# Hyperparameter tuning configuration\n",
    "fit_pipeline = False\n",
    "cv = 5\n",
    "n_iter = 24\n",
    "n_jobs = -3\n",
    "\n",
    "# Paths\n",
    "cleaning_dict_path = \"utils/lab_test_name_aggregation.json\"\n",
    "save_path = Path('data') / 'output' / 'best_model.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleaning_dict_path, \"r\") as in_file:\n",
    "    dict_tests = json.load(in_file)\n",
    "\n",
    "df_notas = pd.read_csv('data/notas.csv', sep=';')\n",
    "df_laboratorios = pd.read_csv('data/laboratorios.csv', sep=';')\n",
    "df_sociodemografico = pd.read_csv('data/sociodemografico.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laboratorios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sociodemografico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sociodemografico = clean_sociodemograficos(df_sociodemografico)\n",
    "df_laboratorios = clean_labs(df_laboratorios, name_aggregation_dict=dict_tests)\n",
    "df_notas = clean_notas(df_notas, apply_lemmatization=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the sociodemographic data with the medical notes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_sociodemografico.merge(df_notas, how='inner', on='IDRecord')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate the classes\n",
    "if consolidate_classes:\n",
    "    df_merge = merge_classes(df_merge)\n",
    "\n",
    "# Perform word count feature engineering\n",
    "df_merge = word_count_feat_engineering(df_merge)\n",
    "\n",
    "# Preprocess the lab data and merge it with the sociodemographic data\n",
    "df_merge = merge_labs_notas(df_laboratorios, df_merge)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_merge.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merge.drop(labels=[target_feature], axis=1)\n",
    "y = df_merge[target_feature]\n",
    "if as_dual_class:\n",
    "    # Remove all but the first two characters of the classes, i.e. A5 or E1\n",
    "    y = y.str[:2]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform(y)\n",
    "\n",
    "np.unique(y_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labels, train_size=0.2, random_state=42, stratify=y_labels)\n",
    "np.unique(y_train, return_counts=True) # Let's check the number of samples per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balance_classes == 'oversample':\n",
    "    # Using a naive oversampling approach\n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "elif balance_classes == 'undersample':\n",
    "    # Using a naive oversampling approach\n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "np.unique(y_train, return_counts=True) # Let's check the number of samples per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further (optional) feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = \"nnlm-es-dim128\"\n",
    "embedding = \"nnlm-es-dim128-with-normalization\"\n",
    "# embedding = \"universal\"\n",
    "\n",
    "if add_gpu_prediction:\n",
    "    model_function = gpu_model_hub\n",
    "    clf = KerasClassifierModel(\n",
    "        build_fn=model_function,\n",
    "        class_number=len(df_notas[target_feature].unique()),\n",
    "        embedding = embedding,\n",
    "        epochs=400,\n",
    "        batch_size=400,\n",
    "        verbose=10,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train[text_feature], y_train)\n",
    "    clf.plot_learning_curves('data/output/gpu_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gpu_prediction:\n",
    "    y_pred = clf.predict(X_test[text_feature])\n",
    "    display(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gpu_prediction:\n",
    "    X_pred = clf.predict(df_merge[text_feature])\n",
    "    df_merge['GPU_prediction'] = X_pred\n",
    "    df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numerical features that will be used in the model\n",
    "numerical_features = list(\n",
    "    set(\n",
    "        [\n",
    "            \"Edad\",\n",
    "            \"top_lab_avg_value\",\n",
    "            \"top_lab_max_value\",\n",
    "            \"top_lab_count\",\n",
    "            \"total_lab_count\",\n",
    "            \"date_diff_mean\",\n",
    "            \"date_diff_max\",\n",
    "            \"first_lab_date\",\t\n",
    "            \"last_lab_date\",\n",
    "            \"date_diff_first_last\",\n",
    "        ]\n",
    "        + list(df_merge.drop(columns=\"IDRecord\").select_dtypes(include=\"int64\").columns)\n",
    "        + [f'{test[1]}_count' for test in disease_tests_list()]\n",
    "        + [f'{test[1]}_max' for test in disease_tests_list()]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Now select the categorical features\n",
    "categorical_features = [\n",
    "    \"Genero\",\n",
    "    \"GrupoEtnico\",\n",
    "    # \"AreaResidencial\",\n",
    "    \"EstadoCivil\",\n",
    "    # \"TSangre\",\n",
    "    # \"Tipo\",\n",
    "    \"top_lab_code\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the GPU prediction if we are using a GPU model for predicting the data\n",
    "if 'GPU_prediction' in df_merge:\n",
    "    categorical_features.append('GPU_prediction')\n",
    "\n",
    "pipeline = PipelineManager(estimator=\"classifier\")\n",
    "pipeline.set_numerical_features(numerical_features)\n",
    "pipeline.set_categorical_features(categorical_features)\n",
    "pipeline.set_text_feature(text_feature)\n",
    "pipeline.set_basic_pipeline()\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.linspace(1, 200, 10, dtype=int),\n",
    "    \"max_depth\": list(np.linspace(2, 15, 5, dtype=int)),\n",
    "    \"eta\": np.linspace(0.01, 0.5, 10, dtype=float),\n",
    "    \"min_child_weight\": np.linspace(0.5, 20, 5, dtype=float),\n",
    "    \"gamma\": np.linspace(0, 1, 5, dtype=float),\n",
    "    \"subsample\": np.linspace(0.1, 1, 5, dtype=float),\n",
    "    \"colsample_bytree\": np.linspace(0.2, 1, 5, dtype=float),\n",
    "    \"reg_lambda\": np.linspace(0, 10, 5, dtype=float),\n",
    "    \"reg_alpha\": np.linspace(0, 10, 5, dtype=float),\n",
    "    # \"scale_pos_weight\": np.linspace(0.1, 500, 100, dtype=float),\n",
    "}\n",
    "estimator = XGBClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": np.linspace(0, 5, 20, dtype=float),\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"auto\", \"scale\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"coef0\": np.linspace(0, 5, 20, dtype=float),\n",
    "    \"degree\": np.linspace(1, 5, 10, dtype=int),\n",
    "}\n",
    "estimator = SVC()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "pipeline.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \"Accuracy\": \"balanced_accuracy\",\n",
    "    \"Weighted_F1\": make_scorer(f1_score, average='weighted'),\n",
    "    # 'roc_auc':make_scorer(roc_auc_score, average='weighted'),\n",
    "    }\n",
    "if not fit_pipeline and not save_path.is_file():\n",
    "    print(f'Could not find saved model in {save_path.resolve()}, retraining pipeline')\n",
    "    fit_pipeline = True\n",
    "\n",
    "if fit_pipeline:\n",
    "    best_model = pipeline.find_best_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        n_iter=n_iter,\n",
    "        n_jobs=n_jobs,\n",
    "        scoring=scoring,\n",
    "        random_state=7,\n",
    "        refit='Weighted_F1',\n",
    "        verbose = 5,\n",
    "        # error_score='raise',\n",
    "        )\n",
    "    with pd.option_context('display.max_columns', None):\n",
    "        display(pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"]).head(30))\n",
    "else:\n",
    "    best_model = load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"]).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"])[[\n",
    "    'rank_test_Weighted_F1',\n",
    "    'rank_test_Accuracy',\n",
    "    'mean_fit_time',\n",
    "    'param_estimator',\n",
    "    'param_preprocessor__text__vectorizer',\n",
    "    'param_preprocessor__text__tfidf',\n",
    "    'param_preprocessor__numerical__scaler',\n",
    "    'param_preprocessor__numerical__imputer', 'param_feature_selector',\n",
    "    'mean_test_Accuracy',\n",
    "    'mean_test_Weighted_F1'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"])[[\n",
    "    'rank_test_Weighted_F1',\n",
    "    'rank_test_Accuracy',\n",
    "    'mean_fit_time',\n",
    "    'param_estimator',\n",
    "    'param_preprocessor__text__vectorizer',\n",
    "    'param_preprocessor__text__tfidf',\n",
    "    'param_preprocessor__numerical__scaler',\n",
    "    'param_preprocessor__numerical__imputer', 'param_feature_selector',\n",
    "    'mean_test_Accuracy',\n",
    "    'mean_test_Weighted_F1'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model using a sample-weighting mechanism to try to compensate for the dataset imbalance\n",
    "if retrain_with_class_weight:\n",
    "    sample_weights = compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_train,\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train, y_train, estimator__sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pipeline.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_decoded = label_encoder.inverse_transform(best_model['estimator'].classes_)\n",
    "\n",
    "with sns.axes_style(\"dark\"):\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test,\n",
    "        best_model.predict(X_test),\n",
    "        display_labels=labels_decoded,\n",
    "        normalize='true',\n",
    "        ax=ax, cmap='viridis',\n",
    "        values_format=\".2f\")\n",
    "    _ = ax.set_title('Confusion matrix, normalized on True labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.loc[0,'classification_report'].round(2).rename(index={str(class_label):label for class_label, label in zip(best_model['estimator'].classes_, labels_decoded)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the fmap file needed to correctly give names to the features in the decision tree plot\n",
    "fmap = pd.DataFrame(best_model.named_steps['feature_selector'].get_feature_names_out(best_model.named_steps['preprocessor'].get_feature_names_out()), columns=['feature'])\n",
    "# Feature type q is quantitative, feature type i is binary\n",
    "fmap['feature_type'] = 'i'\n",
    "fmap.loc[fmap.feature.str.contains('numerical__'), 'feature_type'] = 'q'\n",
    "fmap['feature'] = fmap.feature.str.replace(' ', '_')\n",
    "fmap['feature'] = fmap.feature.str.replace('numerical__', '')\n",
    "fmap['feature'] = fmap.feature.str.replace('categorical__', '')\n",
    "fmap_save_path = save_path.parent / 'feature_map.txt'\n",
    "fmap.to_csv(str(fmap_save_path), sep=\"\\t\", header=False)\n",
    "fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20), dpi=800)\n",
    "plot_tree(best_model.named_steps['estimator'], num_trees=2, ax=ax, fmap=str(fmap_save_path))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model test\n",
    "print(f'Predicted :{label_encoder.inverse_transform(best_model.predict(X_test.iloc[905].to_frame().T))}, real: {label_encoder.inverse_transform([y_test[905]])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the best performing model and pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dump(best_model, str(save_path))\n",
    "dump(score, str(save_path.parent / f'best_model_score{save_path.suffix}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save the full prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_pipeline = PredictionPipeline(estimator=best_model, preprocessing_fn=clean_and_preprocess_datasets, label_encoder=label_encoder)\n",
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dump(\n",
    "    prediction_pipeline,\n",
    "    str(save_path.parent / f\"prediction_pipeline{save_path.suffix}\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_pipeline.predict(X_test, preprocess_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_pipeline.predict(\n",
    "    X={\n",
    "        \"df_sociodemograficos\": pd.read_csv(\"data/sociodemografico.csv\", sep=\";\"),\n",
    "        \"df_laboratorios\": pd.read_csv(\"data/laboratorios.csv\", sep=\";\"),\n",
    "        \"df_notas\": pd.read_csv(\"data/notas.csv\", sep=\";\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_and_preprocess_datasets({\n",
    "        \"df_sociodemograficos\": pd.read_csv(\"data/sociodemografico.csv\", sep=\";\"),\n",
    "        \"df_laboratorios\": pd.read_csv(\"data/laboratorios.csv\", sep=\";\"),\n",
    "        \"df_notas\": pd.read_csv(\"data/notas.csv\", sep=\";\"),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing_utils import preprocess_json\n",
    "\n",
    "import json\n",
    "with open('utils/sample_example.json') as in_file:\n",
    "    sample_data = json.load(in_file)\n",
    "sample_data\n",
    "\n",
    "preprocess_json(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_pipeline.predict(\n",
    "    X=preprocess_json(sample_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DS4A_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f76a7c6cc494b0b3a89d8a51fced70cc96d4c7d6d1b394e23b2a78ee1e2a0cba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
