{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from IPython.display import display\n",
    "from joblib import dump\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
    "                             f1_score, make_scorer, roc_auc_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from ml_model import PipelineManager, PredictionPipeline\n",
    "from utils.GPU_models import KerasClassifierModel, gpu_model_hub\n",
    "from utils.preprocessing_utils import (clean_and_preprocess_datasets,\n",
    "                                       clean_labs, clean_notas,\n",
    "                                       clean_sociodemograficos, merge_classes,\n",
    "                                       merge_labs_notas,\n",
    "                                       word_count_feat_engineering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"diagram\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "as_dual_class=False\n",
    "target_feature = 'Código'\n",
    "text_feature = 'Plan'\n",
    "retrain_with_class_weight=False\n",
    "add_gpu_prediction = False\n",
    "consolidate_classes = False\n",
    "cv = 3\n",
    "n_iter = 20\n",
    "n_jobs = -2\n",
    "\n",
    "# False, 'oversample', or 'undersample'\n",
    "balance_classes = 'undersample'\n",
    "save_path = Path('data') / 'output' / 'best_model.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas = pd.read_csv('data/notas.csv', sep=';')\n",
    "df_laboratorios = pd.read_csv('data/laboratorios.csv', sep=';')\n",
    "df_sociodemografico = pd.read_csv('data/sociodemografico.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44600</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45038</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40391</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>usuaria la cual se ve pertinente seguimiento d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106350</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105840</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>EDUCACIÓN  Se brinda retroalimentación con rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IDRecord Código                                             Nombre  \\\n",
       "0    44600   A539                           SIFILIS, NO ESPECIFICADA   \n",
       "1    45038   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "2    40391   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "3   106350   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "4   105840   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "\n",
       "                  Tipo                                               Plan  \n",
       "0  Confirmado Repetido  - ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...  \n",
       "1  Confirmado Repetido  - TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...  \n",
       "2  Confirmado Repetido  usuaria la cual se ve pertinente seguimiento d...  \n",
       "3  Confirmado Repetido  1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...  \n",
       "4  Confirmado Repetido  EDUCACIÓN  Se brinda retroalimentación con rel...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Codigo</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95627</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>22/02/2022 18:43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125572</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>17/02/2022 13:41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55788</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>22/06/2021 12:50</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113766</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>5/08/2021 12:11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44596</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>5/08/2021 13:15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Codigo                      Nombre             Fecha Valor\n",
       "0     95627  902045  TIEMPO DE PROTROMBINA (PT)  22/02/2022 18:43   NaN\n",
       "1    125572  902045  TIEMPO DE PROTROMBINA (PT)  17/02/2022 13:41   NaN\n",
       "2     55788  902045  TIEMPO DE PROTROMBINA (PT)  22/06/2021 12:50  1.05\n",
       "3    113766  902045  TIEMPO DE PROTROMBINA (PT)   5/08/2021 12:11   NaN\n",
       "4     44596  902045  TIEMPO DE PROTROMBINA (PT)   5/08/2021 13:15   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_laboratorios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>No reportado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325</td>\n",
       "      <td>94</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Rural</td>\n",
       "      <td>Viudo/a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0         5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1       292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3       307    88  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "4       325    94  Hombre  Ninguno de los anteriores      Zona Rural   \n",
       "\n",
       "    EstadoCivil TSangre  \n",
       "0      Separado     NaN  \n",
       "1        Casado     NaN  \n",
       "2       Soltero      O+  \n",
       "3  No reportado     NaN  \n",
       "4       Viudo/a     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sociodemografico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44600</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45038</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40391</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>usuaria la cual se ve pertinente seguimiento d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106350</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105840</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>EDUCACIÓN  Se brinda retroalimentación con rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IDRecord Código                                             Nombre  \\\n",
       "0    44600   A539                           SIFILIS, NO ESPECIFICADA   \n",
       "1    45038   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "2    40391   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "3   106350   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "4   105840   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "\n",
       "                  Tipo                                               Plan  \n",
       "0  Confirmado Repetido  - ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...  \n",
       "1  Confirmado Repetido  - TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...  \n",
       "2  Confirmado Repetido  usuaria la cual se ve pertinente seguimiento d...  \n",
       "3  Confirmado Repetido  1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...  \n",
       "4  Confirmado Repetido  EDUCACIÓN  Se brinda retroalimentación con rel...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sociodemografico = clean_sociodemograficos(df_sociodemografico)\n",
    "df_laboratorios = clean_labs(df_laboratorios)\n",
    "df_notas = clean_notas(df_notas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the sociodemographic data with the medical notes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA PROGRAMA CRONICOS.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Nuevo</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140167</th>\n",
       "      <td>205218</td>\n",
       "      <td>28</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>explica acerca programa, recomienda adherencia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140168</th>\n",
       "      <td>205227</td>\n",
       "      <td>24</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>Elaboracion duelo frente diagnostico.   Reforz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140169</th>\n",
       "      <td>205253</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>FUROATO MOMETASONA 1 SPRY NASAL CADA FOSA NASA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140170</th>\n",
       "      <td>205577</td>\n",
       "      <td>62</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Impresión Diagnóstica</td>\n",
       "      <td>CONTROL MEICO MES-INFECTOLOGIA  VALORACIOJN IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140171</th>\n",
       "      <td>206307</td>\n",
       "      <td>57</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E149</td>\n",
       "      <td>DIABETES MELLITUS, NO ESPECIFICADA SIN MENCION...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA SEGUIMIENTO PROGRAMA NEFROPROTECCION ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140172 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0              5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1            292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "4            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "...          ...   ...     ...                        ...             ...   \n",
       "140167    205218    28  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "140168    205227    24  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "140169    205253    84  Hombre                    Mestizo     Zona Urbana   \n",
       "140170    205577    62  Hombre                    Mestizo     Zona Urbana   \n",
       "140171    206307    57  Hombre                    Mestizo     Zona Urbana   \n",
       "\n",
       "        EstadoCivil TSangre Código  \\\n",
       "0          Separado     NaN   E109   \n",
       "1            Casado     NaN   E119   \n",
       "2           Soltero      O+   E119   \n",
       "3           Soltero      O+   E109   \n",
       "4           Soltero      O+   E119   \n",
       "...             ...     ...    ...   \n",
       "140167          NaN     NaN   A539   \n",
       "140168      Soltero      O+   A530   \n",
       "140169       Casado     NaN   E109   \n",
       "140170  Desconocido     NaN   E119   \n",
       "140171  Desconocido     NaN   E149   \n",
       "\n",
       "                                                   Nombre  \\\n",
       "0       DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "1       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "2       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "3       DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "4       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "...                                                   ...   \n",
       "140167                           SIFILIS, NO ESPECIFICADA   \n",
       "140168  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "140169  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "140170  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "140171  DIABETES MELLITUS, NO ESPECIFICADA SIN MENCION...   \n",
       "\n",
       "                         Tipo  \\\n",
       "0         Confirmado Repetido   \n",
       "1         Confirmado Repetido   \n",
       "2         Confirmado Repetido   \n",
       "3         Confirmado Repetido   \n",
       "4            Confirmado Nuevo   \n",
       "...                       ...   \n",
       "140167    Confirmado Repetido   \n",
       "140168    Confirmado Repetido   \n",
       "140169    Confirmado Repetido   \n",
       "140170  Impresión Diagnóstica   \n",
       "140171    Confirmado Repetido   \n",
       "\n",
       "                                                     Plan  \n",
       "0       PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...  \n",
       "1                            CONTINUA PROGRAMA CRONICOS.   \n",
       "2       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "3       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "4       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "...                                                   ...  \n",
       "140167  explica acerca programa, recomienda adherencia...  \n",
       "140168  Elaboracion duelo frente diagnostico.   Reforz...  \n",
       "140169  FUROATO MOMETASONA 1 SPRY NASAL CADA FOSA NASA...  \n",
       "140170  CONTROL MEICO MES-INFECTOLOGIA  VALORACIOJN IN...  \n",
       "140171  CONTINUA SEGUIMIENTO PROGRAMA NEFROPROTECCION ...  \n",
       "\n",
       "[140172 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = df_sociodemografico.merge(df_notas, how='inner', on='IDRecord')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "      <th>acido</th>\n",
       "      <th>antibio</th>\n",
       "      <th>asintoma</th>\n",
       "      <th>cabeza</th>\n",
       "      <th>diabet</th>\n",
       "      <th>diet</th>\n",
       "      <th>gluco</th>\n",
       "      <th>hepat</th>\n",
       "      <th>insulin</th>\n",
       "      <th>keto</th>\n",
       "      <th>penici</th>\n",
       "      <th>preservativo</th>\n",
       "      <th>rpr</th>\n",
       "      <th>sable</th>\n",
       "      <th>serolo</th>\n",
       "      <th>sifili</th>\n",
       "      <th>test_reloj_orden</th>\n",
       "      <th>vih</th>\n",
       "      <th>top_lab_code</th>\n",
       "      <th>top_lab_avg_value</th>\n",
       "      <th>top_lab_max_value</th>\n",
       "      <th>top_lab_count</th>\n",
       "      <th>total_lab_count</th>\n",
       "      <th>date_diff_mean</th>\n",
       "      <th>date_diff_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>902213</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA PROGRAMA CRONICOS.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Nuevo</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0         5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1       292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "4       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "\n",
       "  EstadoCivil TSangre Código  \\\n",
       "0    Separado     NaN   E109   \n",
       "1      Casado     NaN   E119   \n",
       "2     Soltero      O+   E119   \n",
       "3     Soltero      O+   E109   \n",
       "4     Soltero      O+   E119   \n",
       "\n",
       "                                              Nombre                 Tipo  \\\n",
       "0  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...  Confirmado Repetido   \n",
       "1  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...  Confirmado Repetido   \n",
       "2  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...  Confirmado Repetido   \n",
       "3  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...  Confirmado Repetido   \n",
       "4  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...     Confirmado Nuevo   \n",
       "\n",
       "                                                Plan  acido  antibio  \\\n",
       "0  PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...      0        0   \n",
       "1                       CONTINUA PROGRAMA CRONICOS.       0        0   \n",
       "2  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "3  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "4  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "\n",
       "   asintoma  cabeza  diabet  diet  gluco  hepat  insulin  keto  penici  \\\n",
       "0         0       0       0     0      0      0        0     0       0   \n",
       "1         0       0       0     0      0      0        0     0       0   \n",
       "2         0       0       0     1      0      0        0     0       0   \n",
       "3         0       0       0     1      0      0        0     0       0   \n",
       "4         0       0       0     1      0      0        0     0       0   \n",
       "\n",
       "   preservativo  rpr  sable  serolo  sifili  test_reloj_orden  vih  \\\n",
       "0             0    0      0       0       0                 0    0   \n",
       "1             0    0      0       0       0                 0    0   \n",
       "2             0    0      0       0       0                 0    0   \n",
       "3             0    0      0       0       0                 0    0   \n",
       "4             0    0      0       0       0                 0    0   \n",
       "\n",
       "  top_lab_code  top_lab_avg_value  top_lab_max_value  top_lab_count  \\\n",
       "0       902213               10.0               10.0            1.0   \n",
       "1          NaN                NaN                NaN            NaN   \n",
       "2          NaN                NaN                NaN            NaN   \n",
       "3          NaN                NaN                NaN            NaN   \n",
       "4          NaN                NaN                NaN            NaN   \n",
       "\n",
       "   total_lab_count  date_diff_mean  date_diff_max  \n",
       "0              8.0             0.0            0.0  \n",
       "1              NaN             NaN            NaN  \n",
       "2              NaN             NaN            NaN  \n",
       "3              NaN             NaN            NaN  \n",
       "4              NaN             NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Consolidate the classes\n",
    "if consolidate_classes:\n",
    "    df_merge = merge_classes(df_merge)\n",
    "\n",
    "# Perform word count feature engineering\n",
    "df_merge = word_count_feat_engineering(df_merge)\n",
    "\n",
    "# Preprocess the lab data and merge it with the sociodemographic data\n",
    "df_merge = merge_labs_notas(df_laboratorios, df_merge)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_merge.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([  977,    94,  2614,  1970, 60586, 47408,  6278, 17437,  2808]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_merge.drop(labels=[target_feature], axis=1)\n",
    "y = df_merge[target_feature]\n",
    "if as_dual_class:\n",
    "    y = y.str[:2]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform(y)\n",
    "\n",
    "np.unique(y_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([  195,    19,   523,   394, 12117,  9481,  1256,  3487,   562]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labels, train_size=0.2, random_state=42, stratify=y_labels)\n",
    "np.unique(y_train, return_counts=True) # Let's check the number of samples per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([19, 19, 19, 19, 19, 19, 19, 19, 19]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if balance_classes == 'oversample':\n",
    "    # Using a naive oversampling approach\n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "elif balance_classes == 'undersample':\n",
    "    # Using a naive oversampling approach\n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "np.unique(y_train, return_counts=True) # Let's check the number of samples per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further (optional) feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = \"nnlm-es-dim128\"\n",
    "embedding = \"nnlm-es-dim128-with-normalization\"\n",
    "# embedding = \"universal\"\n",
    "\n",
    "if add_gpu_prediction:\n",
    "    model_function = gpu_model_hub\n",
    "    clf = KerasClassifierModel(\n",
    "        build_fn=model_function,\n",
    "        class_number=len(df_notas[target_feature].unique()),\n",
    "        embedding = embedding,\n",
    "        epochs=400,\n",
    "        batch_size=400,\n",
    "        verbose=10,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train[text_feature], y_train)\n",
    "    clf.plot_learning_curves('data/output/gpu_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gpu_prediction:\n",
    "    y_pred = clf.predict(X_test[text_feature])\n",
    "    display(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gpu_prediction:\n",
    "    X_pred = clf.predict(df_merge[text_feature])\n",
    "    df_merge['GPU_prediction'] = X_pred\n",
    "    df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the numerical features that will be used in the model\n",
    "numerical_features = list(\n",
    "    set(\n",
    "        [\n",
    "            \"Edad\",\n",
    "            \"top_lab_avg_value\",\n",
    "            \"top_lab_max_value\",\n",
    "            \"top_lab_count\",\n",
    "            \"total_lab_count\",\n",
    "            \"date_diff_mean\",\n",
    "            \"date_diff_max\",\n",
    "        ]\n",
    "        + list(df_merge.drop(columns=\"IDRecord\").select_dtypes(include=\"int64\").columns)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Now define the categorical features\n",
    "categorical_features = [\n",
    "    \"Genero\",\n",
    "    \"GrupoEtnico\",\n",
    "    \"AreaResidencial\",\n",
    "    \"EstadoCivil\",\n",
    "    \"TSangre\",\n",
    "    \"Tipo\",\n",
    "    \"top_lab_code\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_code&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                                               &#x27;la&#x27;,\n",
       "                                                                                               &#x27;que&#x27;,\n",
       "                                                                                               &#x27;el&#x27;,\n",
       "                                                                                               &#x27;en&#x27;,\n",
       "                                                                                               &#x27;y&#x27;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;los&#x27;,\n",
       "                                                                                               &#x27;del&#x27;,\n",
       "                                                                                               &#x27;se&#x27;,\n",
       "                                                                                               &#x27;las&#x27;,\n",
       "                                                                                               &#x27;por&#x27;,\n",
       "                                                                                               &#x27;un&#x27;,\n",
       "                                                                                               &#x27;para&#x27;,\n",
       "                                                                                               &#x27;con&#x27;,\n",
       "                                                                                               &#x27;no&#x27;,\n",
       "                                                                                               &#x27;una&#x27;,\n",
       "                                                                                               &#x27;su&#x27;,\n",
       "                                                                                               &#x27;al&#x27;,\n",
       "                                                                                               &#x27;lo&#x27;,\n",
       "                                                                                               &#x27;como&#x27;,\n",
       "                                                                                               &#x27;más&#x27;,\n",
       "                                                                                               &#x27;pero&#x27;,\n",
       "                                                                                               &#x27;sus&#x27;,\n",
       "                                                                                               &#x27;le&#x27;,\n",
       "                                                                                               &#x27;ya&#x27;,\n",
       "                                                                                               &#x27;o&#x27;,\n",
       "                                                                                               &#x27;este&#x27;,\n",
       "                                                                                               &#x27;sí&#x27;,\n",
       "                                                                                               &#x27;porque&#x27;, ...],\n",
       "                                                                                   strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                                  (&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  &#x27;Plan&#x27;)])),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                (&#x27;estimator&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_code&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                                               &#x27;la&#x27;,\n",
       "                                                                                               &#x27;que&#x27;,\n",
       "                                                                                               &#x27;el&#x27;,\n",
       "                                                                                               &#x27;en&#x27;,\n",
       "                                                                                               &#x27;y&#x27;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;los&#x27;,\n",
       "                                                                                               &#x27;del&#x27;,\n",
       "                                                                                               &#x27;se&#x27;,\n",
       "                                                                                               &#x27;las&#x27;,\n",
       "                                                                                               &#x27;por&#x27;,\n",
       "                                                                                               &#x27;un&#x27;,\n",
       "                                                                                               &#x27;para&#x27;,\n",
       "                                                                                               &#x27;con&#x27;,\n",
       "                                                                                               &#x27;no&#x27;,\n",
       "                                                                                               &#x27;una&#x27;,\n",
       "                                                                                               &#x27;su&#x27;,\n",
       "                                                                                               &#x27;al&#x27;,\n",
       "                                                                                               &#x27;lo&#x27;,\n",
       "                                                                                               &#x27;como&#x27;,\n",
       "                                                                                               &#x27;más&#x27;,\n",
       "                                                                                               &#x27;pero&#x27;,\n",
       "                                                                                               &#x27;sus&#x27;,\n",
       "                                                                                               &#x27;le&#x27;,\n",
       "                                                                                               &#x27;ya&#x27;,\n",
       "                                                                                               &#x27;o&#x27;,\n",
       "                                                                                               &#x27;este&#x27;,\n",
       "                                                                                               &#x27;sí&#x27;,\n",
       "                                                                                               &#x27;porque&#x27;, ...],\n",
       "                                                                                   strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                                  (&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  &#x27;Plan&#x27;)])),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                (&#x27;estimator&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;,\n",
       "                                  &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;,\n",
       "                                  &#x27;top_lab_code&#x27;]),\n",
       "                                (&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardS...\n",
       "                                  &#x27;diet&#x27;, &#x27;asintoma&#x27;, &#x27;keto&#x27;, &#x27;total_lab_count&#x27;,\n",
       "                                  &#x27;serolo&#x27;]),\n",
       "                                (&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                              &#x27;la&#x27;,\n",
       "                                                                              &#x27;que&#x27;,\n",
       "                                                                              &#x27;el&#x27;,\n",
       "                                                                              &#x27;en&#x27;,\n",
       "                                                                              &#x27;y&#x27;,\n",
       "                                                                              &#x27;a&#x27;,\n",
       "                                                                              &#x27;los&#x27;,\n",
       "                                                                              &#x27;del&#x27;,\n",
       "                                                                              &#x27;se&#x27;,\n",
       "                                                                              &#x27;las&#x27;,\n",
       "                                                                              &#x27;por&#x27;,\n",
       "                                                                              &#x27;un&#x27;,\n",
       "                                                                              &#x27;para&#x27;,\n",
       "                                                                              &#x27;con&#x27;,\n",
       "                                                                              &#x27;no&#x27;,\n",
       "                                                                              &#x27;una&#x27;,\n",
       "                                                                              &#x27;su&#x27;,\n",
       "                                                                              &#x27;al&#x27;,\n",
       "                                                                              &#x27;lo&#x27;,\n",
       "                                                                              &#x27;como&#x27;,\n",
       "                                                                              &#x27;más&#x27;,\n",
       "                                                                              &#x27;pero&#x27;,\n",
       "                                                                              &#x27;sus&#x27;,\n",
       "                                                                              &#x27;le&#x27;,\n",
       "                                                                              &#x27;ya&#x27;,\n",
       "                                                                              &#x27;o&#x27;,\n",
       "                                                                              &#x27;este&#x27;,\n",
       "                                                                              &#x27;sí&#x27;,\n",
       "                                                                              &#x27;porque&#x27;, ...],\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  TfidfTransformer())]),\n",
       "                                 &#x27;Plan&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;, &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;, &#x27;top_lab_code&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sable&#x27;, &#x27;test_reloj_orden&#x27;, &#x27;hepat&#x27;, &#x27;date_diff_mean&#x27;, &#x27;sifili&#x27;, &#x27;date_diff_max&#x27;, &#x27;top_lab_max_value&#x27;, &#x27;vih&#x27;, &#x27;preservativo&#x27;, &#x27;penici&#x27;, &#x27;insulin&#x27;, &#x27;Edad&#x27;, &#x27;top_lab_avg_value&#x27;, &#x27;gluco&#x27;, &#x27;diabet&#x27;, &#x27;rpr&#x27;, &#x27;cabeza&#x27;, &#x27;antibio&#x27;, &#x27;acido&#x27;, &#x27;top_lab_count&#x27;, &#x27;diet&#x27;, &#x27;asintoma&#x27;, &#x27;keto&#x27;, &#x27;total_lab_count&#x27;, &#x27;serolo&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>Plan</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;que&#x27;, &#x27;el&#x27;, &#x27;en&#x27;, &#x27;y&#x27;, &#x27;a&#x27;, &#x27;los&#x27;,\n",
       "                            &#x27;del&#x27;, &#x27;se&#x27;, &#x27;las&#x27;, &#x27;por&#x27;, &#x27;un&#x27;, &#x27;para&#x27;, &#x27;con&#x27;,\n",
       "                            &#x27;no&#x27;, &#x27;una&#x27;, &#x27;su&#x27;, &#x27;al&#x27;, &#x27;lo&#x27;, &#x27;como&#x27;, &#x27;más&#x27;,\n",
       "                            &#x27;pero&#x27;, &#x27;sus&#x27;, &#x27;le&#x27;, &#x27;ya&#x27;, &#x27;o&#x27;, &#x27;este&#x27;, &#x27;sí&#x27;,\n",
       "                            &#x27;porque&#x27;, ...],\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_selector: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestRegressor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Genero', 'GrupoEtnico',\n",
       "                                                   'AreaResidencial',\n",
       "                                                   'EstadoCivil', 'TSangre',\n",
       "                                                   'Tipo', 'top_lab_code']),\n",
       "                                                 ('numerical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=['de',\n",
       "                                                                                               'la',\n",
       "                                                                                               'que',\n",
       "                                                                                               'el',\n",
       "                                                                                               'en',\n",
       "                                                                                               'y',\n",
       "                                                                                               'a',\n",
       "                                                                                               'los',\n",
       "                                                                                               'del',\n",
       "                                                                                               'se',\n",
       "                                                                                               'las',\n",
       "                                                                                               'por',\n",
       "                                                                                               'un',\n",
       "                                                                                               'para',\n",
       "                                                                                               'con',\n",
       "                                                                                               'no',\n",
       "                                                                                               'una',\n",
       "                                                                                               'su',\n",
       "                                                                                               'al',\n",
       "                                                                                               'lo',\n",
       "                                                                                               'como',\n",
       "                                                                                               'más',\n",
       "                                                                                               'pero',\n",
       "                                                                                               'sus',\n",
       "                                                                                               'le',\n",
       "                                                                                               'ya',\n",
       "                                                                                               'o',\n",
       "                                                                                               'este',\n",
       "                                                                                               'sí',\n",
       "                                                                                               'porque', ...],\n",
       "                                                                                   strip_accents='unicode')),\n",
       "                                                                  ('tfidf',\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  'Plan')])),\n",
       "                ('feature_selector',\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                ('estimator', RandomForestClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the GPU prediction if we are using a GPU model for predicting the data\n",
    "if 'GPU_prediction' in df_merge:\n",
    "    categorical_features.append('GPU_prediction')\n",
    "\n",
    "pipeline = PipelineManager(estimator=\"classifier\")\n",
    "pipeline.set_numerical_features(numerical_features)\n",
    "pipeline.set_categorical_features(categorical_features)\n",
    "pipeline.set_text_feature(text_feature)\n",
    "pipeline.set_basic_pipeline()\n",
    "\n",
    "# param_grid = {\n",
    "#     \"n_estimators\": np.linspace(1, 100, 10, dtype=int),\n",
    "#     \"max_depth\": list(np.linspace(1, 10, 5, dtype=int)) + [None],\n",
    "#     \"bootstrap\": [True, False],\n",
    "# }\n",
    "# estimator = RandomForestClassifier()\n",
    "# pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.linspace(1, 200, 10, dtype=int),\n",
    "    \"max_depth\": list(np.linspace(2, 10, 5, dtype=int)) + [None],\n",
    "    \"eta\": np.linspace(0.01, 0.5, 10, dtype=float),\n",
    "    \"min_child_weight\": np.linspace(0.5, 20, 5, dtype=float),\n",
    "    \"gamma\": np.linspace(0, 1, 5, dtype=float),\n",
    "    \"subsample\": np.linspace(0.1, 1, 5, dtype=float),\n",
    "    \"colsample_bytree\": np.linspace(0.2, 1, 5, dtype=float),\n",
    "    \"reg_lambda\": np.linspace(0, 10, 5, dtype=float),\n",
    "    \"reg_alpha\": np.linspace(0, 10, 5, dtype=float),\n",
    "    # \"scale_pos_weight\": np.linspace(0.1, 500, 100, dtype=float),\n",
    "}\n",
    "estimator = XGBClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "param_grid = {}\n",
    "estimator = PassiveAggressiveClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "estimator = SGDClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": np.linspace(0, 5, 20, dtype=float),\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"auto\", \"scale\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"coef0\": np.linspace(0, 5, 20, dtype=float),\n",
    "    \"degree\": np.linspace(1, 5, 10, dtype=int),\n",
    "}\n",
    "estimator = SVC()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "pipeline.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "21 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py\", line 673, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py\", line 604, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 414, in fit_transform\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 870, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/impute/_knn.py\", line 210, in fit\n",
      "    X = self._validate_data(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 577, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 856, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'Hombre'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.11111111        nan        nan 0.11111111\n",
      " 0.11111111 0.11111111        nan 0.18959436 0.33156966        nan\n",
      " 0.11111111 0.34303351 0.11111111 0.11111111 0.11111111 0.11111111\n",
      "        nan 0.29982363]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.02232143        nan        nan 0.02232143\n",
      " 0.02232143 0.02232143        nan 0.07530189 0.30073194        nan\n",
      " 0.02232143 0.33068355 0.02232143 0.02232143 0.02232143 0.02232143\n",
      "        nan 0.21529872]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample_weight = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=df_merge[target_feature])\n",
    "\n",
    "scoring = {\n",
    "    \"Accuracy\": \"balanced_accuracy\",\n",
    "    \"Weighted_F1\": make_scorer(f1_score, average='weighted'),\n",
    "    # 'roc_auc':make_scorer(roc_auc_score, average='weighted'),\n",
    "    }\n",
    "best_model = pipeline.find_best_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    n_iter=n_iter,\n",
    "    n_jobs=n_jobs,\n",
    "    scoring=scoring,\n",
    "    random_state=7,\n",
    "    refit='Weighted_F1',\n",
    "    verbose = 1,\n",
    "    # error_score='raise',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_code&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;s...\n",
       "                               eval_metric=None, gamma=0.75, gpu_id=-1,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.391111106, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=10, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                               n_estimators=133, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_code&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;s...\n",
       "                               eval_metric=None, gamma=0.75, gpu_id=-1,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.391111106, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=10, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                               n_estimators=133, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;,\n",
       "                                  &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;,\n",
       "                                  &#x27;top_lab_code&#x27;]),\n",
       "                                (&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, MinMaxScaler())]),\n",
       "                                 [&#x27;sable...\n",
       "                                  &#x27;serolo&#x27;]),\n",
       "                                (&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  CountVectorizer(ngram_range=(3,\n",
       "                                                                               3),\n",
       "                                                                  stop_words=[&#x27;de&#x27;,\n",
       "                                                                              &#x27;la&#x27;,\n",
       "                                                                              &#x27;que&#x27;,\n",
       "                                                                              &#x27;el&#x27;,\n",
       "                                                                              &#x27;en&#x27;,\n",
       "                                                                              &#x27;y&#x27;,\n",
       "                                                                              &#x27;a&#x27;,\n",
       "                                                                              &#x27;los&#x27;,\n",
       "                                                                              &#x27;del&#x27;,\n",
       "                                                                              &#x27;se&#x27;,\n",
       "                                                                              &#x27;las&#x27;,\n",
       "                                                                              &#x27;por&#x27;,\n",
       "                                                                              &#x27;un&#x27;,\n",
       "                                                                              &#x27;para&#x27;,\n",
       "                                                                              &#x27;con&#x27;,\n",
       "                                                                              &#x27;no&#x27;,\n",
       "                                                                              &#x27;una&#x27;,\n",
       "                                                                              &#x27;su&#x27;,\n",
       "                                                                              &#x27;al&#x27;,\n",
       "                                                                              &#x27;lo&#x27;,\n",
       "                                                                              &#x27;como&#x27;,\n",
       "                                                                              &#x27;más&#x27;,\n",
       "                                                                              &#x27;pero&#x27;,\n",
       "                                                                              &#x27;sus&#x27;,\n",
       "                                                                              &#x27;le&#x27;,\n",
       "                                                                              &#x27;ya&#x27;,\n",
       "                                                                              &#x27;o&#x27;,\n",
       "                                                                              &#x27;este&#x27;,\n",
       "                                                                              &#x27;sí&#x27;,\n",
       "                                                                              &#x27;porque&#x27;, ...],\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  TfidfTransformer(sublinear_tf=True))]),\n",
       "                                 &#x27;Plan&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;, &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;, &#x27;top_lab_code&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sable&#x27;, &#x27;test_reloj_orden&#x27;, &#x27;hepat&#x27;, &#x27;date_diff_mean&#x27;, &#x27;sifili&#x27;, &#x27;date_diff_max&#x27;, &#x27;top_lab_max_value&#x27;, &#x27;vih&#x27;, &#x27;preservativo&#x27;, &#x27;penici&#x27;, &#x27;insulin&#x27;, &#x27;Edad&#x27;, &#x27;top_lab_avg_value&#x27;, &#x27;gluco&#x27;, &#x27;diabet&#x27;, &#x27;rpr&#x27;, &#x27;cabeza&#x27;, &#x27;antibio&#x27;, &#x27;acido&#x27;, &#x27;top_lab_count&#x27;, &#x27;diet&#x27;, &#x27;asintoma&#x27;, &#x27;keto&#x27;, &#x27;total_lab_count&#x27;, &#x27;serolo&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>Plan</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(3, 3),\n",
       "                stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;que&#x27;, &#x27;el&#x27;, &#x27;en&#x27;, &#x27;y&#x27;, &#x27;a&#x27;, &#x27;los&#x27;,\n",
       "                            &#x27;del&#x27;, &#x27;se&#x27;, &#x27;las&#x27;, &#x27;por&#x27;, &#x27;un&#x27;, &#x27;para&#x27;, &#x27;con&#x27;,\n",
       "                            &#x27;no&#x27;, &#x27;una&#x27;, &#x27;su&#x27;, &#x27;al&#x27;, &#x27;lo&#x27;, &#x27;como&#x27;, &#x27;más&#x27;,\n",
       "                            &#x27;pero&#x27;, &#x27;sus&#x27;, &#x27;le&#x27;, &#x27;ya&#x27;, &#x27;o&#x27;, &#x27;este&#x27;, &#x27;sí&#x27;,\n",
       "                            &#x27;porque&#x27;, ...],\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer(sublinear_tf=True)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1,\n",
       "              colsample_bytree=0.6000000000000001, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.3911111111111111,\n",
       "              eval_metric=None, gamma=0.75, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.391111106, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0,\n",
       "              min_child_weight=0.5, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=133, n_jobs=0, num_parallel_tree=1,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Genero', 'GrupoEtnico',\n",
       "                                                   'AreaResidencial',\n",
       "                                                   'EstadoCivil', 'TSangre',\n",
       "                                                   'Tipo', 'top_lab_code']),\n",
       "                                                 ('numerical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('s...\n",
       "                               eval_metric=None, gamma=0.75, gpu_id=-1,\n",
       "                               grow_policy='depthwise', importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.391111106, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=10, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints='()',\n",
       "                               n_estimators=133, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, ...))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_preprocessor__text__vectorizer</th>\n",
       "      <th>param_preprocessor__text__tfidf</th>\n",
       "      <th>param_preprocessor__numerical__scaler</th>\n",
       "      <th>param_preprocessor__numerical__imputer</th>\n",
       "      <th>param_preprocessor__categorical__imputer</th>\n",
       "      <th>param_feature_selector</th>\n",
       "      <th>param_estimator__subsample</th>\n",
       "      <th>param_estimator__reg_lambda</th>\n",
       "      <th>param_estimator__reg_alpha</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "      <th>param_estimator__min_child_weight</th>\n",
       "      <th>param_estimator__max_depth</th>\n",
       "      <th>param_estimator__gamma</th>\n",
       "      <th>param_estimator__eta</th>\n",
       "      <th>param_estimator__colsample_bytree</th>\n",
       "      <th>param_estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>split1_test_Accuracy</th>\n",
       "      <th>split2_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>split0_test_Weighted_F1</th>\n",
       "      <th>split1_test_Weighted_F1</th>\n",
       "      <th>split2_test_Weighted_F1</th>\n",
       "      <th>mean_test_Weighted_F1</th>\n",
       "      <th>std_test_Weighted_F1</th>\n",
       "      <th>rank_test_Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.632093</td>\n",
       "      <td>0.843459</td>\n",
       "      <td>0.038732</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.55</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.304233</td>\n",
       "      <td>0.343034</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339349</td>\n",
       "      <td>0.345094</td>\n",
       "      <td>0.307608</td>\n",
       "      <td>0.330684</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.813593</td>\n",
       "      <td>0.251211</td>\n",
       "      <td>0.026581</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.335979</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.306878</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.018623</td>\n",
       "      <td>2</td>\n",
       "      <td>0.304435</td>\n",
       "      <td>0.344447</td>\n",
       "      <td>0.253314</td>\n",
       "      <td>0.300732</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.112955</td>\n",
       "      <td>0.662228</td>\n",
       "      <td>0.052836</td>\n",
       "      <td>0.022494</td>\n",
       "      <td>CountVectorizer(ngram_range=(4, 4),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200</td>\n",
       "      <td>5.375</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.320106</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.299824</td>\n",
       "      <td>0.042456</td>\n",
       "      <td>3</td>\n",
       "      <td>0.209339</td>\n",
       "      <td>0.293869</td>\n",
       "      <td>0.142688</td>\n",
       "      <td>0.215299</td>\n",
       "      <td>0.061863</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.148327</td>\n",
       "      <td>0.207243</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.216931</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.189594</td>\n",
       "      <td>0.020756</td>\n",
       "      <td>4</td>\n",
       "      <td>0.100668</td>\n",
       "      <td>0.071011</td>\n",
       "      <td>0.054226</td>\n",
       "      <td>0.075302</td>\n",
       "      <td>0.019201</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.153229</td>\n",
       "      <td>2.338633</td>\n",
       "      <td>0.049181</td>\n",
       "      <td>0.019123</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133</td>\n",
       "      <td>15.125</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.164445</td>\n",
       "      <td>0.454580</td>\n",
       "      <td>0.050981</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.877123</td>\n",
       "      <td>0.599843</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>155</td>\n",
       "      <td>5.375</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.569754</td>\n",
       "      <td>1.265770</td>\n",
       "      <td>0.031443</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>155</td>\n",
       "      <td>5.375</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.426156</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.045445</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.325</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.318975</td>\n",
       "      <td>0.132839</td>\n",
       "      <td>0.029914</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>23</td>\n",
       "      <td>15.125</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.919521</td>\n",
       "      <td>0.193923</td>\n",
       "      <td>0.033127</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.325</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>89</td>\n",
       "      <td>10.25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.026963</td>\n",
       "      <td>0.178143</td>\n",
       "      <td>0.042445</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.55</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.788139</td>\n",
       "      <td>1.825811</td>\n",
       "      <td>0.041234</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>200</td>\n",
       "      <td>5.375</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013107</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>177</td>\n",
       "      <td>5.375</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.775</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>89</td>\n",
       "      <td>5.375</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.445556</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007583</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>177</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010842</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.775</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "13       4.632093      0.843459         0.038732        0.008878   \n",
       "10       0.813593      0.251211         0.026581        0.003321   \n",
       "19       5.112955      0.662228         0.052836        0.022494   \n",
       "9        3.148327      0.207243         0.046763        0.004891   \n",
       "5        3.153229      2.338633         0.049181        0.019123   \n",
       "6        2.164445      0.454580         0.050981        0.018460   \n",
       "7        2.877123      0.599843         0.025126        0.004639   \n",
       "2        2.569754      1.265770         0.031443        0.008759   \n",
       "12       4.426156      0.635514         0.045445        0.015162   \n",
       "14       0.318975      0.132839         0.029914        0.004383   \n",
       "15       0.919521      0.193923         0.033127        0.008810   \n",
       "16       1.026963      0.178143         0.042445        0.003332   \n",
       "17       2.788139      1.825811         0.041234        0.005119   \n",
       "4        0.013107      0.002757         0.000000        0.000000   \n",
       "8        0.008773      0.006827         0.000000        0.000000   \n",
       "18       0.005977      0.000192         0.000000        0.000000   \n",
       "11       0.004702      0.000916         0.000000        0.000000   \n",
       "1        0.005168      0.000776         0.000000        0.000000   \n",
       "3        0.007583      0.001495         0.000000        0.000000   \n",
       "0        0.010842      0.007032         0.000000        0.000000   \n",
       "\n",
       "                 param_preprocessor__text__vectorizer  \\\n",
       "13  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "10  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "19  CountVectorizer(ngram_range=(4, 4),\\n         ...   \n",
       "9   CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "5   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "6   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "7   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "2   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "12  CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "14  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "15  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "16  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "17  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "4   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "8   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "18  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "11  CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "1   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "3   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "0   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "\n",
       "                   param_preprocessor__text__tfidf  \\\n",
       "13             TfidfTransformer(sublinear_tf=True)   \n",
       "10                              TfidfTransformer()   \n",
       "19  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "9   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "5                               TfidfTransformer()   \n",
       "6              TfidfTransformer(sublinear_tf=True)   \n",
       "7                      TfidfTransformer(norm='l1')   \n",
       "2              TfidfTransformer(sublinear_tf=True)   \n",
       "12                     TfidfTransformer(norm='l1')   \n",
       "14                              TfidfTransformer()   \n",
       "15             TfidfTransformer(sublinear_tf=True)   \n",
       "16                     TfidfTransformer(norm='l1')   \n",
       "17                              TfidfTransformer()   \n",
       "4              TfidfTransformer(sublinear_tf=True)   \n",
       "8                      TfidfTransformer(norm='l1')   \n",
       "18                              TfidfTransformer()   \n",
       "11  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "1   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "3              TfidfTransformer(sublinear_tf=True)   \n",
       "0   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "\n",
       "   param_preprocessor__numerical__scaler  \\\n",
       "13                        MinMaxScaler()   \n",
       "10                        MinMaxScaler()   \n",
       "19                        MinMaxScaler()   \n",
       "9                           Normalizer()   \n",
       "5                           Normalizer()   \n",
       "6                         RobustScaler()   \n",
       "7                         MinMaxScaler()   \n",
       "2                           Normalizer()   \n",
       "12                      StandardScaler()   \n",
       "14                        MinMaxScaler()   \n",
       "15                          Normalizer()   \n",
       "16                      StandardScaler()   \n",
       "17                      StandardScaler()   \n",
       "4                           Normalizer()   \n",
       "8                           Normalizer()   \n",
       "18                        RobustScaler()   \n",
       "11                      StandardScaler()   \n",
       "1                         RobustScaler()   \n",
       "3                         MinMaxScaler()   \n",
       "0                         RobustScaler()   \n",
       "\n",
       "     param_preprocessor__numerical__imputer  \\\n",
       "13                          SimpleImputer()   \n",
       "10                          SimpleImputer()   \n",
       "19                          SimpleImputer()   \n",
       "9                              KNNImputer()   \n",
       "5                              KNNImputer()   \n",
       "6   SimpleImputer(strategy='most_frequent')   \n",
       "7          SimpleImputer(strategy='median')   \n",
       "2   SimpleImputer(strategy='most_frequent')   \n",
       "12  SimpleImputer(strategy='most_frequent')   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "15         SimpleImputer(strategy='median')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "17                             KNNImputer()   \n",
       "4          SimpleImputer(strategy='median')   \n",
       "8   SimpleImputer(strategy='most_frequent')   \n",
       "18  SimpleImputer(strategy='most_frequent')   \n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "1   SimpleImputer(strategy='most_frequent')   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "0                           SimpleImputer()   \n",
       "\n",
       "   param_preprocessor__categorical__imputer  \\\n",
       "13  SimpleImputer(strategy='most_frequent')   \n",
       "10  SimpleImputer(strategy='most_frequent')   \n",
       "19  SimpleImputer(strategy='most_frequent')   \n",
       "9   SimpleImputer(strategy='most_frequent')   \n",
       "5   SimpleImputer(strategy='most_frequent')   \n",
       "6   SimpleImputer(strategy='most_frequent')   \n",
       "7   SimpleImputer(strategy='most_frequent')   \n",
       "2   SimpleImputer(strategy='most_frequent')   \n",
       "12  SimpleImputer(strategy='most_frequent')   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "15  SimpleImputer(strategy='most_frequent')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "17  SimpleImputer(strategy='most_frequent')   \n",
       "4                 KNNImputer(n_neighbors=1)   \n",
       "8                 KNNImputer(n_neighbors=1)   \n",
       "18                KNNImputer(n_neighbors=1)   \n",
       "11                KNNImputer(n_neighbors=1)   \n",
       "1                 KNNImputer(n_neighbors=1)   \n",
       "3                 KNNImputer(n_neighbors=1)   \n",
       "0                 KNNImputer(n_neighbors=1)   \n",
       "\n",
       "                     param_feature_selector param_estimator__subsample  \\\n",
       "13                      VarianceThreshold()                       0.55   \n",
       "10       SelectFromModel(estimator=Ridge())                      0.325   \n",
       "19                      VarianceThreshold()                        1.0   \n",
       "9                       VarianceThreshold()                        1.0   \n",
       "5        SelectFromModel(estimator=Ridge())                       0.55   \n",
       "6        SelectFromModel(estimator=Ridge())                        0.1   \n",
       "7                       VarianceThreshold()                        0.1   \n",
       "2        SelectFromModel(estimator=Ridge())                       0.55   \n",
       "12                      VarianceThreshold()                      0.325   \n",
       "14  SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "15                      VarianceThreshold()                      0.325   \n",
       "16                      VarianceThreshold()                       0.55   \n",
       "17       SelectFromModel(estimator=Ridge())                       0.55   \n",
       "4   SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "8                       VarianceThreshold()                      0.775   \n",
       "18                      VarianceThreshold()                        1.0   \n",
       "11  SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "1   SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "3   SelectFromModel(estimator=ElasticNet())                      0.325   \n",
       "0        SelectFromModel(estimator=Ridge())                      0.775   \n",
       "\n",
       "   param_estimator__reg_lambda param_estimator__reg_alpha  \\\n",
       "13                         7.5                        0.0   \n",
       "10                         0.0                        0.0   \n",
       "19                         2.5                        5.0   \n",
       "9                          2.5                        5.0   \n",
       "5                          7.5                        0.0   \n",
       "6                          0.0                        5.0   \n",
       "7                          2.5                        7.5   \n",
       "2                         10.0                        7.5   \n",
       "12                         7.5                       10.0   \n",
       "14                        10.0                        7.5   \n",
       "15                         2.5                       10.0   \n",
       "16                         7.5                       10.0   \n",
       "17                         0.0                       10.0   \n",
       "4                          2.5                        7.5   \n",
       "8                          2.5                        2.5   \n",
       "18                         7.5                        7.5   \n",
       "11                         5.0                        5.0   \n",
       "1                         10.0                        0.0   \n",
       "3                          0.0                       10.0   \n",
       "0                          7.5                       10.0   \n",
       "\n",
       "   param_estimator__n_estimators param_estimator__min_child_weight  \\\n",
       "13                           133                               0.5   \n",
       "10                            67                               0.5   \n",
       "19                           200                             5.375   \n",
       "9                            200                             5.375   \n",
       "5                            133                            15.125   \n",
       "6                             67                               0.5   \n",
       "7                            155                             5.375   \n",
       "2                            155                             5.375   \n",
       "12                           200                               0.5   \n",
       "14                            23                            15.125   \n",
       "15                            89                             10.25   \n",
       "16                           111                             5.375   \n",
       "17                           200                             5.375   \n",
       "4                            177                             5.375   \n",
       "8                            200                               0.5   \n",
       "18                            89                             5.375   \n",
       "11                           133                               0.5   \n",
       "1                             45                               0.5   \n",
       "3                            177                               0.5   \n",
       "0                            200                               0.5   \n",
       "\n",
       "   param_estimator__max_depth param_estimator__gamma param_estimator__eta  \\\n",
       "13                         10                   0.75             0.391111   \n",
       "10                          4                    0.0             0.391111   \n",
       "19                          4                    0.0             0.173333   \n",
       "9                           6                    0.5             0.064444   \n",
       "5                           6                    0.5             0.064444   \n",
       "6                           4                    0.5             0.391111   \n",
       "7                           8                   0.25             0.064444   \n",
       "2                           8                   0.75             0.336667   \n",
       "12                          2                    0.0                  0.5   \n",
       "14                          4                   0.25             0.391111   \n",
       "15                          6                    0.5             0.064444   \n",
       "16                          6                    0.0             0.118889   \n",
       "17                         10                   0.25             0.118889   \n",
       "4                        None                    0.0             0.391111   \n",
       "8                        None                   0.75             0.118889   \n",
       "18                          4                    1.0             0.445556   \n",
       "11                          4                   0.25             0.118889   \n",
       "1                           8                    1.0             0.173333   \n",
       "3                          10                   0.75                 0.01   \n",
       "0                           4                   0.25             0.064444   \n",
       "\n",
       "   param_estimator__colsample_bytree  \\\n",
       "13                               0.6   \n",
       "10                               0.8   \n",
       "19                               0.2   \n",
       "9                                0.8   \n",
       "5                                1.0   \n",
       "6                                0.8   \n",
       "7                                0.8   \n",
       "2                                0.8   \n",
       "12                               1.0   \n",
       "14                               0.2   \n",
       "15                               0.2   \n",
       "16                               1.0   \n",
       "17                               0.4   \n",
       "4                                0.4   \n",
       "8                                0.6   \n",
       "18                               0.6   \n",
       "11                               0.2   \n",
       "1                                0.8   \n",
       "3                                0.2   \n",
       "0                                0.4   \n",
       "\n",
       "                                      param_estimator  \\\n",
       "13  XGBClassifier(base_score=None, booster=None, c...   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...   \n",
       "5   XGBClassifier(base_score=None, booster=None, c...   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "2   XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...   \n",
       "4   XGBClassifier(base_score=None, booster=None, c...   \n",
       "8   XGBClassifier(base_score=None, booster=None, c...   \n",
       "18  XGBClassifier(base_score=None, booster=None, c...   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "1   XGBClassifier(base_score=None, booster=None, c...   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "0   XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                                               params  split0_test_Accuracy  \\\n",
       "13  {'preprocessor__text__vectorizer': CountVector...              0.373016   \n",
       "10  {'preprocessor__text__vectorizer': CountVector...              0.335979   \n",
       "19  {'preprocessor__text__vectorizer': CountVector...              0.320106   \n",
       "9   {'preprocessor__text__vectorizer': CountVector...              0.216931   \n",
       "5   {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "6   {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "7   {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "2   {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "12  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "14  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "15  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "16  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "17  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "4   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "8   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "18  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "11  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "1   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "3   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "0   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "\n",
       "    split1_test_Accuracy  split2_test_Accuracy  mean_test_Accuracy  \\\n",
       "13              0.351852              0.304233            0.343034   \n",
       "10              0.351852              0.306878            0.331570   \n",
       "19              0.338624              0.240741            0.299824   \n",
       "9               0.185185              0.166667            0.189594   \n",
       "5               0.111111              0.111111            0.111111   \n",
       "6               0.111111              0.111111            0.111111   \n",
       "7               0.111111              0.111111            0.111111   \n",
       "2               0.111111              0.111111            0.111111   \n",
       "12              0.111111              0.111111            0.111111   \n",
       "14              0.111111              0.111111            0.111111   \n",
       "15              0.111111              0.111111            0.111111   \n",
       "16              0.111111              0.111111            0.111111   \n",
       "17              0.111111              0.111111            0.111111   \n",
       "4                    NaN                   NaN                 NaN   \n",
       "8                    NaN                   NaN                 NaN   \n",
       "18                   NaN                   NaN                 NaN   \n",
       "11                   NaN                   NaN                 NaN   \n",
       "1                    NaN                   NaN                 NaN   \n",
       "3                    NaN                   NaN                 NaN   \n",
       "0                    NaN                   NaN                 NaN   \n",
       "\n",
       "    std_test_Accuracy  rank_test_Accuracy  split0_test_Weighted_F1  \\\n",
       "13           0.028765                   1                 0.339349   \n",
       "10           0.018623                   2                 0.304435   \n",
       "19           0.042456                   3                 0.209339   \n",
       "9            0.020756                   4                 0.100668   \n",
       "5            0.000000                   5                 0.020050   \n",
       "6            0.000000                   5                 0.026864   \n",
       "7            0.000000                   5                 0.026864   \n",
       "2            0.000000                   5                 0.026864   \n",
       "12           0.000000                   5                 0.026864   \n",
       "14           0.000000                   5                 0.026864   \n",
       "15           0.000000                   5                 0.026864   \n",
       "16           0.000000                   5                 0.026864   \n",
       "17           0.000000                   5                 0.026864   \n",
       "4                 NaN                  14                      NaN   \n",
       "8                 NaN                  15                      NaN   \n",
       "18                NaN                  16                      NaN   \n",
       "11                NaN                  17                      NaN   \n",
       "1                 NaN                  18                      NaN   \n",
       "3                 NaN                  19                      NaN   \n",
       "0                 NaN                  20                      NaN   \n",
       "\n",
       "    split1_test_Weighted_F1  split2_test_Weighted_F1  mean_test_Weighted_F1  \\\n",
       "13                 0.345094                 0.307608               0.330684   \n",
       "10                 0.344447                 0.253314               0.300732   \n",
       "19                 0.293869                 0.142688               0.215299   \n",
       "9                  0.071011                 0.054226               0.075302   \n",
       "5                  0.026864                 0.020050               0.022321   \n",
       "6                  0.020050                 0.020050               0.022321   \n",
       "7                  0.020050                 0.020050               0.022321   \n",
       "2                  0.020050                 0.020050               0.022321   \n",
       "12                 0.020050                 0.020050               0.022321   \n",
       "14                 0.020050                 0.020050               0.022321   \n",
       "15                 0.020050                 0.020050               0.022321   \n",
       "16                 0.020050                 0.020050               0.022321   \n",
       "17                 0.020050                 0.020050               0.022321   \n",
       "4                       NaN                      NaN                    NaN   \n",
       "8                       NaN                      NaN                    NaN   \n",
       "18                      NaN                      NaN                    NaN   \n",
       "11                      NaN                      NaN                    NaN   \n",
       "1                       NaN                      NaN                    NaN   \n",
       "3                       NaN                      NaN                    NaN   \n",
       "0                       NaN                      NaN                    NaN   \n",
       "\n",
       "    std_test_Weighted_F1  rank_test_Weighted_F1  \n",
       "13              0.016484                      1  \n",
       "10              0.037297                      2  \n",
       "19              0.061863                      3  \n",
       "9               0.019201                      4  \n",
       "5               0.003212                      5  \n",
       "6               0.003212                      5  \n",
       "7               0.003212                      5  \n",
       "2               0.003212                      5  \n",
       "12              0.003212                      5  \n",
       "14              0.003212                      5  \n",
       "15              0.003212                      5  \n",
       "16              0.003212                      5  \n",
       "17              0.003212                      5  \n",
       "4                    NaN                     14  \n",
       "8                    NaN                     15  \n",
       "18                   NaN                     16  \n",
       "11                   NaN                     17  \n",
       "1                    NaN                     18  \n",
       "3                    NaN                     19  \n",
       "0                    NaN                     20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"]).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_Weighted_F1</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_estimator</th>\n",
       "      <th>param_preprocessor__text__vectorizer</th>\n",
       "      <th>param_preprocessor__text__tfidf</th>\n",
       "      <th>param_preprocessor__numerical__scaler</th>\n",
       "      <th>param_preprocessor__numerical__imputer</th>\n",
       "      <th>param_feature_selector</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>mean_test_Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.632093</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.343034</td>\n",
       "      <td>0.330684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.813593</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.300732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.112955</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(4, 4),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.299824</td>\n",
       "      <td>0.215299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.148327</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.189594</td>\n",
       "      <td>0.075302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.153229</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.164445</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.877123</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.569754</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.426156</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.318975</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.919521</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.026963</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.788139</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.013107</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_Weighted_F1  rank_test_Accuracy  mean_fit_time  \\\n",
       "13                      1                   1       4.632093   \n",
       "10                      2                   2       0.813593   \n",
       "19                      3                   3       5.112955   \n",
       "9                       4                   4       3.148327   \n",
       "5                       5                   5       3.153229   \n",
       "6                       5                   5       2.164445   \n",
       "7                       5                   5       2.877123   \n",
       "2                       5                   5       2.569754   \n",
       "12                      5                   5       4.426156   \n",
       "14                      5                   5       0.318975   \n",
       "15                      5                   5       0.919521   \n",
       "16                      5                   5       1.026963   \n",
       "17                      5                   5       2.788139   \n",
       "4                      14                  14       0.013107   \n",
       "8                      15                  15       0.008773   \n",
       "18                     16                  16       0.005977   \n",
       "11                     17                  17       0.004702   \n",
       "1                      18                  18       0.005168   \n",
       "3                      19                  19       0.007583   \n",
       "0                      20                  20       0.010842   \n",
       "\n",
       "                                      param_estimator  \\\n",
       "13  XGBClassifier(base_score=None, booster=None, c...   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...   \n",
       "5   XGBClassifier(base_score=None, booster=None, c...   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "2   XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...   \n",
       "4   XGBClassifier(base_score=None, booster=None, c...   \n",
       "8   XGBClassifier(base_score=None, booster=None, c...   \n",
       "18  XGBClassifier(base_score=None, booster=None, c...   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "1   XGBClassifier(base_score=None, booster=None, c...   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "0   XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                 param_preprocessor__text__vectorizer  \\\n",
       "13  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "10  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "19  CountVectorizer(ngram_range=(4, 4),\\n         ...   \n",
       "9   CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "5   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "6   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "7   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "2   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "12  CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "14  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "15  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "16  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "17  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "4   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "8   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "18  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "11  CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "1   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "3   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "0   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "\n",
       "                   param_preprocessor__text__tfidf  \\\n",
       "13             TfidfTransformer(sublinear_tf=True)   \n",
       "10                              TfidfTransformer()   \n",
       "19  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "9   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "5                               TfidfTransformer()   \n",
       "6              TfidfTransformer(sublinear_tf=True)   \n",
       "7                      TfidfTransformer(norm='l1')   \n",
       "2              TfidfTransformer(sublinear_tf=True)   \n",
       "12                     TfidfTransformer(norm='l1')   \n",
       "14                              TfidfTransformer()   \n",
       "15             TfidfTransformer(sublinear_tf=True)   \n",
       "16                     TfidfTransformer(norm='l1')   \n",
       "17                              TfidfTransformer()   \n",
       "4              TfidfTransformer(sublinear_tf=True)   \n",
       "8                      TfidfTransformer(norm='l1')   \n",
       "18                              TfidfTransformer()   \n",
       "11  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "1   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "3              TfidfTransformer(sublinear_tf=True)   \n",
       "0   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "\n",
       "   param_preprocessor__numerical__scaler  \\\n",
       "13                        MinMaxScaler()   \n",
       "10                        MinMaxScaler()   \n",
       "19                        MinMaxScaler()   \n",
       "9                           Normalizer()   \n",
       "5                           Normalizer()   \n",
       "6                         RobustScaler()   \n",
       "7                         MinMaxScaler()   \n",
       "2                           Normalizer()   \n",
       "12                      StandardScaler()   \n",
       "14                        MinMaxScaler()   \n",
       "15                          Normalizer()   \n",
       "16                      StandardScaler()   \n",
       "17                      StandardScaler()   \n",
       "4                           Normalizer()   \n",
       "8                           Normalizer()   \n",
       "18                        RobustScaler()   \n",
       "11                      StandardScaler()   \n",
       "1                         RobustScaler()   \n",
       "3                         MinMaxScaler()   \n",
       "0                         RobustScaler()   \n",
       "\n",
       "     param_preprocessor__numerical__imputer  \\\n",
       "13                          SimpleImputer()   \n",
       "10                          SimpleImputer()   \n",
       "19                          SimpleImputer()   \n",
       "9                              KNNImputer()   \n",
       "5                              KNNImputer()   \n",
       "6   SimpleImputer(strategy='most_frequent')   \n",
       "7          SimpleImputer(strategy='median')   \n",
       "2   SimpleImputer(strategy='most_frequent')   \n",
       "12  SimpleImputer(strategy='most_frequent')   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "15         SimpleImputer(strategy='median')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "17                             KNNImputer()   \n",
       "4          SimpleImputer(strategy='median')   \n",
       "8   SimpleImputer(strategy='most_frequent')   \n",
       "18  SimpleImputer(strategy='most_frequent')   \n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "1   SimpleImputer(strategy='most_frequent')   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "0                           SimpleImputer()   \n",
       "\n",
       "                     param_feature_selector  mean_test_Accuracy  \\\n",
       "13                      VarianceThreshold()            0.343034   \n",
       "10       SelectFromModel(estimator=Ridge())            0.331570   \n",
       "19                      VarianceThreshold()            0.299824   \n",
       "9                       VarianceThreshold()            0.189594   \n",
       "5        SelectFromModel(estimator=Ridge())            0.111111   \n",
       "6        SelectFromModel(estimator=Ridge())            0.111111   \n",
       "7                       VarianceThreshold()            0.111111   \n",
       "2        SelectFromModel(estimator=Ridge())            0.111111   \n",
       "12                      VarianceThreshold()            0.111111   \n",
       "14  SelectFromModel(estimator=ElasticNet())            0.111111   \n",
       "15                      VarianceThreshold()            0.111111   \n",
       "16                      VarianceThreshold()            0.111111   \n",
       "17       SelectFromModel(estimator=Ridge())            0.111111   \n",
       "4   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "8                       VarianceThreshold()                 NaN   \n",
       "18                      VarianceThreshold()                 NaN   \n",
       "11  SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "1   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "3   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "0        SelectFromModel(estimator=Ridge())                 NaN   \n",
       "\n",
       "    mean_test_Weighted_F1  \n",
       "13               0.330684  \n",
       "10               0.300732  \n",
       "19               0.215299  \n",
       "9                0.075302  \n",
       "5                0.022321  \n",
       "6                0.022321  \n",
       "7                0.022321  \n",
       "2                0.022321  \n",
       "12               0.022321  \n",
       "14               0.022321  \n",
       "15               0.022321  \n",
       "16               0.022321  \n",
       "17               0.022321  \n",
       "4                     NaN  \n",
       "8                     NaN  \n",
       "18                    NaN  \n",
       "11                    NaN  \n",
       "1                     NaN  \n",
       "3                     NaN  \n",
       "0                     NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"])[[\n",
    "    'rank_test_Weighted_F1',\n",
    "    'rank_test_Accuracy',\n",
    "    'mean_fit_time',\n",
    "    'param_estimator',\n",
    "    'param_preprocessor__text__vectorizer',\n",
    "    'param_preprocessor__text__tfidf',\n",
    "    'param_preprocessor__numerical__scaler',\n",
    "    'param_preprocessor__numerical__imputer', 'param_feature_selector',\n",
    "    'mean_test_Accuracy',\n",
    "    'mean_test_Weighted_F1'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_Weighted_F1</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_estimator</th>\n",
       "      <th>param_preprocessor__text__vectorizer</th>\n",
       "      <th>param_preprocessor__text__tfidf</th>\n",
       "      <th>param_preprocessor__numerical__scaler</th>\n",
       "      <th>param_preprocessor__numerical__imputer</th>\n",
       "      <th>param_feature_selector</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>mean_test_Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.632093</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.343034</td>\n",
       "      <td>0.330684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.813593</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.300732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.112955</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(4, 4),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.299824</td>\n",
       "      <td>0.215299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.148327</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.189594</td>\n",
       "      <td>0.075302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.153229</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.164445</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.877123</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.569754</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.426156</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.318975</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.919521</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.026963</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.788139</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.013107</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_Weighted_F1  rank_test_Accuracy  mean_fit_time  \\\n",
       "13                      1                   1       4.632093   \n",
       "10                      2                   2       0.813593   \n",
       "19                      3                   3       5.112955   \n",
       "9                       4                   4       3.148327   \n",
       "5                       5                   5       3.153229   \n",
       "6                       5                   5       2.164445   \n",
       "7                       5                   5       2.877123   \n",
       "2                       5                   5       2.569754   \n",
       "12                      5                   5       4.426156   \n",
       "14                      5                   5       0.318975   \n",
       "15                      5                   5       0.919521   \n",
       "16                      5                   5       1.026963   \n",
       "17                      5                   5       2.788139   \n",
       "4                      14                  14       0.013107   \n",
       "8                      15                  15       0.008773   \n",
       "18                     16                  16       0.005977   \n",
       "11                     17                  17       0.004702   \n",
       "1                      18                  18       0.005168   \n",
       "3                      19                  19       0.007583   \n",
       "0                      20                  20       0.010842   \n",
       "\n",
       "                                      param_estimator  \\\n",
       "13  XGBClassifier(base_score=None, booster=None, c...   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...   \n",
       "5   XGBClassifier(base_score=None, booster=None, c...   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "2   XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...   \n",
       "4   XGBClassifier(base_score=None, booster=None, c...   \n",
       "8   XGBClassifier(base_score=None, booster=None, c...   \n",
       "18  XGBClassifier(base_score=None, booster=None, c...   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "1   XGBClassifier(base_score=None, booster=None, c...   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "0   XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                 param_preprocessor__text__vectorizer  \\\n",
       "13  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "10  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "19  CountVectorizer(ngram_range=(4, 4),\\n         ...   \n",
       "9   CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "5   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "6   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "7   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "2   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "12  CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "14  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "15  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "16  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "17  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "4   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "8   CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "18  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "11  CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "1   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "3   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "0   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "\n",
       "                   param_preprocessor__text__tfidf  \\\n",
       "13             TfidfTransformer(sublinear_tf=True)   \n",
       "10                              TfidfTransformer()   \n",
       "19  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "9   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "5                               TfidfTransformer()   \n",
       "6              TfidfTransformer(sublinear_tf=True)   \n",
       "7                      TfidfTransformer(norm='l1')   \n",
       "2              TfidfTransformer(sublinear_tf=True)   \n",
       "12                     TfidfTransformer(norm='l1')   \n",
       "14                              TfidfTransformer()   \n",
       "15             TfidfTransformer(sublinear_tf=True)   \n",
       "16                     TfidfTransformer(norm='l1')   \n",
       "17                              TfidfTransformer()   \n",
       "4              TfidfTransformer(sublinear_tf=True)   \n",
       "8                      TfidfTransformer(norm='l1')   \n",
       "18                              TfidfTransformer()   \n",
       "11  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "1   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "3              TfidfTransformer(sublinear_tf=True)   \n",
       "0   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "\n",
       "   param_preprocessor__numerical__scaler  \\\n",
       "13                        MinMaxScaler()   \n",
       "10                        MinMaxScaler()   \n",
       "19                        MinMaxScaler()   \n",
       "9                           Normalizer()   \n",
       "5                           Normalizer()   \n",
       "6                         RobustScaler()   \n",
       "7                         MinMaxScaler()   \n",
       "2                           Normalizer()   \n",
       "12                      StandardScaler()   \n",
       "14                        MinMaxScaler()   \n",
       "15                          Normalizer()   \n",
       "16                      StandardScaler()   \n",
       "17                      StandardScaler()   \n",
       "4                           Normalizer()   \n",
       "8                           Normalizer()   \n",
       "18                        RobustScaler()   \n",
       "11                      StandardScaler()   \n",
       "1                         RobustScaler()   \n",
       "3                         MinMaxScaler()   \n",
       "0                         RobustScaler()   \n",
       "\n",
       "     param_preprocessor__numerical__imputer  \\\n",
       "13                          SimpleImputer()   \n",
       "10                          SimpleImputer()   \n",
       "19                          SimpleImputer()   \n",
       "9                              KNNImputer()   \n",
       "5                              KNNImputer()   \n",
       "6   SimpleImputer(strategy='most_frequent')   \n",
       "7          SimpleImputer(strategy='median')   \n",
       "2   SimpleImputer(strategy='most_frequent')   \n",
       "12  SimpleImputer(strategy='most_frequent')   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "15         SimpleImputer(strategy='median')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "17                             KNNImputer()   \n",
       "4          SimpleImputer(strategy='median')   \n",
       "8   SimpleImputer(strategy='most_frequent')   \n",
       "18  SimpleImputer(strategy='most_frequent')   \n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "1   SimpleImputer(strategy='most_frequent')   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "0                           SimpleImputer()   \n",
       "\n",
       "                     param_feature_selector  mean_test_Accuracy  \\\n",
       "13                      VarianceThreshold()            0.343034   \n",
       "10       SelectFromModel(estimator=Ridge())            0.331570   \n",
       "19                      VarianceThreshold()            0.299824   \n",
       "9                       VarianceThreshold()            0.189594   \n",
       "5        SelectFromModel(estimator=Ridge())            0.111111   \n",
       "6        SelectFromModel(estimator=Ridge())            0.111111   \n",
       "7                       VarianceThreshold()            0.111111   \n",
       "2        SelectFromModel(estimator=Ridge())            0.111111   \n",
       "12                      VarianceThreshold()            0.111111   \n",
       "14  SelectFromModel(estimator=ElasticNet())            0.111111   \n",
       "15                      VarianceThreshold()            0.111111   \n",
       "16                      VarianceThreshold()            0.111111   \n",
       "17       SelectFromModel(estimator=Ridge())            0.111111   \n",
       "4   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "8                       VarianceThreshold()                 NaN   \n",
       "18                      VarianceThreshold()                 NaN   \n",
       "11  SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "1   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "3   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "0        SelectFromModel(estimator=Ridge())                 NaN   \n",
       "\n",
       "    mean_test_Weighted_F1  \n",
       "13               0.330684  \n",
       "10               0.300732  \n",
       "19               0.215299  \n",
       "9                0.075302  \n",
       "5                0.022321  \n",
       "6                0.022321  \n",
       "7                0.022321  \n",
       "2                0.022321  \n",
       "12               0.022321  \n",
       "14               0.022321  \n",
       "15               0.022321  \n",
       "16               0.022321  \n",
       "17               0.022321  \n",
       "4                     NaN  \n",
       "8                     NaN  \n",
       "18                    NaN  \n",
       "11                    NaN  \n",
       "1                     NaN  \n",
       "3                     NaN  \n",
       "0                     NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"])[[\n",
    "    'rank_test_Weighted_F1',\n",
    "    'rank_test_Accuracy',\n",
    "    'mean_fit_time',\n",
    "    'param_estimator',\n",
    "    'param_preprocessor__text__vectorizer',\n",
    "    'param_preprocessor__text__tfidf',\n",
    "    'param_preprocessor__numerical__scaler',\n",
    "    'param_preprocessor__numerical__imputer', 'param_feature_selector',\n",
    "    'mean_test_Accuracy',\n",
    "    'mean_test_Weighted_F1'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model using a sample-weighting mechanism to try to compensate for the dataset imbalance\n",
    "if retrain_with_class_weight:\n",
    "    sample_weights = compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_train,\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train, y_train, estimator__sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>macro_f1_score</th>\n",
       "      <th>weighted_f1_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>confusion_matrix_normalized</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.784998</td>\n",
       "      <td>0.204025</td>\n",
       "      <td>0.378417</td>\n",
       "      <td>0.204025</td>\n",
       "      <td>0.155408</td>\n",
       "      <td>0.239068</td>\n",
       "      <td>[[403, 3, 65, 74, 72, 95, 26, 29, 15], [0, 73,...</td>\n",
       "      <td>[[0.0035937862276837467, 2.6752751074568835e-0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROC_AUC  accuracy balanced_accuracy micro_f1_score macro_f1_score  \\\n",
       "0  0.784998  0.204025          0.378417       0.204025       0.155408   \n",
       "\n",
       "  weighted_f1_score                                   confusion_matrix  \\\n",
       "0          0.239068  [[403, 3, 65, 74, 72, 95, 26, 29, 15], [0, 73,...   \n",
       "\n",
       "                         confusion_matrix_normalized  \\\n",
       "0  [[0.0035937862276837467, 2.6752751074568835e-0...   \n",
       "\n",
       "                               classification_report  \n",
       "0                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pipeline.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_decoded = label_encoder.inverse_transform(best_model['estimator'].classes_)\n",
    "\n",
    "with sns.axes_style(\"dark\"):\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=score.loc[0,'confusion_matrix'],\n",
    "                                display_labels=labels_decoded)\n",
    "    disp.plot(ax=ax, cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A510</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A511</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A514</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A529</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A530</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>48469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A539</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.30</td>\n",
       "      <td>37927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E109</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E119</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E149</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.16</td>\n",
       "      <td>112138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>112138.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score   support\n",
       "A510               0.02    0.52      0.04     782.0\n",
       "A511               0.03    0.97      0.05      75.0\n",
       "A514               0.04    0.21      0.07    2091.0\n",
       "A529               0.03    0.24      0.05    1576.0\n",
       "A530               0.52    0.12      0.20   48469.0\n",
       "A539               0.48    0.21      0.30   37927.0\n",
       "E109               0.17    0.37      0.24    5022.0\n",
       "E119               0.28    0.34      0.30   13950.0\n",
       "E149               0.09    0.41      0.15    2246.0\n",
       "accuracy           0.20    0.20      0.20       0.2\n",
       "macro avg          0.18    0.38      0.16  112138.0\n",
       "weighted avg       0.43    0.20      0.24  112138.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.loc[0,'classification_report'].round(2).rename(index={str(class_label):label for class_label, label in zip(best_model['estimator'].classes_, labels_decoded)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['categorical__Genero_Hombre', 'categorical__Genero_Mujer',\n",
       "       'categorical__GrupoEtnico_Blanco', ...,\n",
       "       'text__zapatos suela antideslizante', 'text__zonas paso utilizar',\n",
       "       'text__zoster sarcoma kaposi'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.named_steps['feature_selector'].get_feature_names_out(best_model.named_steps['preprocessor'].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :['E149'], real: ['A539']\n"
     ]
    }
   ],
   "source": [
    "# Model test\n",
    "print(f'Predicted :{label_encoder.inverse_transform(best_model.predict(X_test.iloc[905].to_frame().T))}, real: {label_encoder.inverse_transform([y_test[905]])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the best performing model and pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/output/best_model_score.pickle']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dump(best_model, str(save_path))\n",
    "dump(score, str(save_path.parent / f'best_model_score{save_path.suffix}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save the full prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/output/prediction_pipeline.pickle']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline = PredictionPipeline(estimator=best_model, preprocessing_fn=clean_and_preprocess_datasets, label_encoder=label_encoder)\n",
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dump(\n",
    "    prediction_pipeline,\n",
    "    str(save_path.parent / f\"prediction_pipeline{save_path.suffix}\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E149', 'A529', 'A510', ..., 'E149', 'A530', 'A514'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline.predict(X_test, preprocess_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/app/scripts/train_ml.ipynb Cell 52'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000051vscode-remote?line=0'>1</a>\u001b[0m prediction_pipeline\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000051vscode-remote?line=1'>2</a>\u001b[0m     X\u001b[39m=\u001b[39;49m{\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000051vscode-remote?line=2'>3</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mdf_sociodemograficos\u001b[39;49m\u001b[39m\"\u001b[39;49m: pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata/sociodemografico.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000051vscode-remote?line=3'>4</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mdf_laboratorios\u001b[39;49m\u001b[39m\"\u001b[39;49m: pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata/laboratorios.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000051vscode-remote?line=4'>5</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mdf_notas\u001b[39;49m\u001b[39m\"\u001b[39;49m: pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata/notas.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000051vscode-remote?line=5'>6</a>\u001b[0m     }\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000051vscode-remote?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[0;32m/app/scripts/ml_model.py:75\u001b[0m, in \u001b[0;36mPredictionPipeline.predict\u001b[0;34m(self, X, preprocess_data, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     preprocessed_X \u001b[39m=\u001b[39m X\n\u001b[0;32m---> 75\u001b[0m prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49mpredict(preprocessed_X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_encoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_encoder\u001b[39m.\u001b[39minverse_transform(prediction)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py:457\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    455\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    456\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 457\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    458\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py:746\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     \u001b[39m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[39m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 746\u001b[0m Xs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(\n\u001b[1;32m    747\u001b[0m     X,\n\u001b[1;32m    748\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    749\u001b[0m     _transform_one,\n\u001b[1;32m    750\u001b[0m     fitted\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    751\u001b[0m     column_as_strings\u001b[39m=\u001b[39;49mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m    752\u001b[0m )\n\u001b[1;32m    753\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    755\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Xs:\n\u001b[1;32m    756\u001b[0m     \u001b[39m# All transformers are None\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py:604\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    598\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    599\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[1;32m    600\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    601\u001b[0m     )\n\u001b[1;32m    602\u001b[0m )\n\u001b[1;32m    603\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 604\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    605\u001b[0m         delayed(func)(\n\u001b[1;32m    606\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[1;32m    607\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m    608\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    609\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m    610\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    611\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[1;32m    612\u001b[0m         )\n\u001b[1;32m    613\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    614\u001b[0m     )\n\u001b[1;32m    615\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    616\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py:853\u001b[0m, in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m--> 853\u001b[0m     res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    854\u001b[0m     \u001b[39m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py:635\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    633\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    634\u001b[0m \u001b[39mfor\u001b[39;00m _, _, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter():\n\u001b[0;32m--> 635\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    636\u001b[0m \u001b[39mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_vocabulary()\n\u001b[1;32m   1386\u001b[0m \u001b[39m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[0;32m-> 1387\u001b[0m _, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, fixed_vocab\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1389\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:1209\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[1;32m   1208\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1209\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1210\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m     doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     doc \u001b[39m=\u001b[39m tokenizer(doc)\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m ngrams \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m stop_words \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prediction_pipeline.predict(\n",
    "    X={\n",
    "        \"df_sociodemograficos\": pd.read_csv(\"data/sociodemografico.csv\", sep=\";\"),\n",
    "        \"df_laboratorios\": pd.read_csv(\"data/laboratorios.csv\", sep=\";\"),\n",
    "        \"df_notas\": pd.read_csv(\"data/notas.csv\", sep=\";\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_and_preprocess_datasets({\n",
    "        \"df_sociodemograficos\": pd.read_csv(\"data/sociodemografico.csv\", sep=\";\"),\n",
    "        \"df_laboratorios\": pd.read_csv(\"data/laboratorios.csv\", sep=\";\"),\n",
    "        \"df_notas\": pd.read_csv(\"data/notas.csv\", sep=\";\"),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_csv('data/output/clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'preprocess_json' from 'utils.preprocessing_utils' (/app/scripts/utils/preprocessing_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/app/scripts/train_ml.ipynb Cell 55'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000052vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocess_json\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000052vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000052vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/app/scripts/utils/sample_example.json\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m in_file:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'preprocess_json' from 'utils.preprocessing_utils' (/app/scripts/utils/preprocessing_utils.py)"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing_utils import preprocess_json\n",
    "\n",
    "import json\n",
    "with open('/app/scripts/utils/sample_example.json') as in_file:\n",
    "    sample_data = json.load(in_file)\n",
    "sample_data\n",
    "\n",
    "preprocess_json(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['Código', 'Nombre']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/app/scripts/train_ml.ipynb Cell 55'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000058vscode-remote?line=0'>1</a>\u001b[0m prediction_pipeline\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22643a5c5c2e6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000058vscode-remote?line=1'>2</a>\u001b[0m     X\u001b[39m=\u001b[39;49mpreprocess_json(sample_data))\n",
      "File \u001b[0;32m/app/scripts/ml_model.py:72\u001b[0m, in \u001b[0;36mPredictionPipeline.predict\u001b[0;34m(self, X, preprocess_data, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X, preprocess_data\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m preprocess_data:\n\u001b[0;32m---> 72\u001b[0m         preprocessed_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess_data(X)\n\u001b[1;32m     73\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m         preprocessed_X \u001b[39m=\u001b[39m X\n",
      "File \u001b[0;32m/app/scripts/ml_model.py:66\u001b[0m, in \u001b[0;36mPredictionPipeline.preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_data\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessing_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocessing_fn(data)\n\u001b[1;32m     67\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/app/scripts/utils/preprocessing_utils.py:255\u001b[0m, in \u001b[0;36mclean_and_preprocess_datasets\u001b[0;34m(data_dict)\u001b[0m\n\u001b[1;32m    253\u001b[0m df_socio \u001b[39m=\u001b[39m clean_sociodemograficos(df_socio)\n\u001b[1;32m    254\u001b[0m df_labs \u001b[39m=\u001b[39m clean_labs(df_labs)\n\u001b[0;32m--> 255\u001b[0m df_notes \u001b[39m=\u001b[39m clean_notas(df_notes)\n\u001b[1;32m    257\u001b[0m \u001b[39m# Preprocess the datasets, add engineered features\u001b[39;00m\n\u001b[1;32m    258\u001b[0m df_merge \u001b[39m=\u001b[39m df_socio\u001b[39m.\u001b[39mmerge(df_notes, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIDRecord\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/app/scripts/utils/preprocessing_utils.py:219\u001b[0m, in \u001b[0;36mclean_notas\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    216\u001b[0m notas\u001b[39m.\u001b[39mdropna(subset\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mIDRecord\u001b[39m\u001b[39m\"\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    218\u001b[0m \u001b[39m# Drop samples where both Code and Name are null\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m notas\u001b[39m.\u001b[39;49mdropna(how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mall\u001b[39;49m\u001b[39m\"\u001b[39;49m, subset\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mCódigo\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mNombre\u001b[39;49m\u001b[39m\"\u001b[39;49m], inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    221\u001b[0m \u001b[39m# Drop bad data form IDRecord\u001b[39;00m\n\u001b[1;32m    222\u001b[0m notas[\u001b[39m\"\u001b[39m\u001b[39mIDRecord\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(notas[\u001b[39m\"\u001b[39m\u001b[39mIDRecord\u001b[39m\u001b[39m\"\u001b[39m], errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:6002\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[0;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[1;32m   6000\u001b[0m     check \u001b[39m=\u001b[39m indices \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   6001\u001b[0m     \u001b[39mif\u001b[39;00m check\u001b[39m.\u001b[39many():\n\u001b[0;32m-> 6002\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(np\u001b[39m.\u001b[39marray(subset)[check]\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m   6003\u001b[0m     agg_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indices, axis\u001b[39m=\u001b[39magg_axis)\n\u001b[1;32m   6005\u001b[0m \u001b[39mif\u001b[39;00m thresh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: ['Código', 'Nombre']"
     ]
    }
   ],
   "source": [
    "prediction_pipeline.predict(\n",
    "    X=preprocess_json(sample_data))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
