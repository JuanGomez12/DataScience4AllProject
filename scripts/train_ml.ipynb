{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2022-06-25 04:39:55.580384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-25 04:39:55.580445: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from IPython.display import display\n",
    "from joblib import dump\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
    "                             f1_score, make_scorer, roc_auc_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from ml_model import PipelineManager, PredictionPipeline\n",
    "from utils.GPU_models import KerasClassifierModel, gpu_model_hub\n",
    "from utils.preprocessing_utils import (clean_and_preprocess_datasets,\n",
    "                                       clean_labs, clean_notas,\n",
    "                                       clean_sociodemograficos, merge_classes,\n",
    "                                       merge_labs_notas,\n",
    "                                       word_count_feat_engineering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"diagram\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "as_dual_class=False\n",
    "target_feature = 'Código'\n",
    "text_feature = 'Plan'\n",
    "retrain_with_class_weight=False\n",
    "add_gpu_prediction = False\n",
    "consolidate_classes = False\n",
    "cv = 3\n",
    "n_iter = 20\n",
    "n_jobs = -2\n",
    "\n",
    "# False, 'oversample', or 'undersample'\n",
    "balance_classes = 'oversample'\n",
    "save_path = Path('data') / 'output' / 'best_model.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas = pd.read_csv('data/notas.csv', sep=';')\n",
    "df_laboratorios = pd.read_csv('data/laboratorios.csv', sep=';')\n",
    "df_sociodemografico = pd.read_csv('data/sociodemografico.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44600</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45038</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40391</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>usuaria la cual se ve pertinente seguimiento d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106350</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105840</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>EDUCACIÓN  Se brinda retroalimentación con rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IDRecord Código                                             Nombre  \\\n",
       "0    44600   A539                           SIFILIS, NO ESPECIFICADA   \n",
       "1    45038   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "2    40391   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "3   106350   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "4   105840   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "\n",
       "                  Tipo                                               Plan  \n",
       "0  Confirmado Repetido  - ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...  \n",
       "1  Confirmado Repetido  - TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...  \n",
       "2  Confirmado Repetido  usuaria la cual se ve pertinente seguimiento d...  \n",
       "3  Confirmado Repetido  1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...  \n",
       "4  Confirmado Repetido  EDUCACIÓN  Se brinda retroalimentación con rel...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Codigo</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95627</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>22/02/2022 18:43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125572</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>17/02/2022 13:41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55788</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>22/06/2021 12:50</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113766</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>5/08/2021 12:11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44596</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>5/08/2021 13:15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Codigo                      Nombre             Fecha Valor\n",
       "0     95627  902045  TIEMPO DE PROTROMBINA (PT)  22/02/2022 18:43   NaN\n",
       "1    125572  902045  TIEMPO DE PROTROMBINA (PT)  17/02/2022 13:41   NaN\n",
       "2     55788  902045  TIEMPO DE PROTROMBINA (PT)  22/06/2021 12:50  1.05\n",
       "3    113766  902045  TIEMPO DE PROTROMBINA (PT)   5/08/2021 12:11   NaN\n",
       "4     44596  902045  TIEMPO DE PROTROMBINA (PT)   5/08/2021 13:15   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_laboratorios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>No reportado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325</td>\n",
       "      <td>94</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Rural</td>\n",
       "      <td>Viudo/a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0         5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1       292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3       307    88  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "4       325    94  Hombre  Ninguno de los anteriores      Zona Rural   \n",
       "\n",
       "    EstadoCivil TSangre  \n",
       "0      Separado     NaN  \n",
       "1        Casado     NaN  \n",
       "2       Soltero      O+  \n",
       "3  No reportado     NaN  \n",
       "4       Viudo/a     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sociodemografico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44600</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45038</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40391</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>usuaria la cual se ve pertinente seguimiento d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106350</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105840</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>EDUCACIÓN  Se brinda retroalimentación con rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IDRecord Código                                             Nombre  \\\n",
       "0    44600   A539                           SIFILIS, NO ESPECIFICADA   \n",
       "1    45038   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "2    40391   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "3   106350   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "4   105840   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "\n",
       "                  Tipo                                               Plan  \n",
       "0  Confirmado Repetido  - ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...  \n",
       "1  Confirmado Repetido  - TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...  \n",
       "2  Confirmado Repetido  usuaria la cual se ve pertinente seguimiento d...  \n",
       "3  Confirmado Repetido  1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...  \n",
       "4  Confirmado Repetido  EDUCACIÓN  Se brinda retroalimentación con rel...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sociodemografico = clean_sociodemograficos(df_sociodemografico)\n",
    "df_laboratorios = clean_labs(df_laboratorios)\n",
    "df_notas = clean_notas(df_notas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the sociodemographic data with the medical notes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA PROGRAMA CRONICOS.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Nuevo</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140167</th>\n",
       "      <td>205218</td>\n",
       "      <td>28</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>explica acerca programa, recomienda adherencia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140168</th>\n",
       "      <td>205227</td>\n",
       "      <td>24</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>Elaboracion duelo frente diagnostico.   Reforz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140169</th>\n",
       "      <td>205253</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>FUROATO MOMETASONA 1 SPRY NASAL CADA FOSA NASA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140170</th>\n",
       "      <td>205577</td>\n",
       "      <td>62</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Impresión Diagnóstica</td>\n",
       "      <td>CONTROL MEICO MES-INFECTOLOGIA  VALORACIOJN IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140171</th>\n",
       "      <td>206307</td>\n",
       "      <td>57</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E149</td>\n",
       "      <td>DIABETES MELLITUS, NO ESPECIFICADA SIN MENCION...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA SEGUIMIENTO PROGRAMA NEFROPROTECCION ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140172 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0              5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1            292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "4            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "...          ...   ...     ...                        ...             ...   \n",
       "140167    205218    28  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "140168    205227    24  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "140169    205253    84  Hombre                    Mestizo     Zona Urbana   \n",
       "140170    205577    62  Hombre                    Mestizo     Zona Urbana   \n",
       "140171    206307    57  Hombre                    Mestizo     Zona Urbana   \n",
       "\n",
       "        EstadoCivil TSangre Código  \\\n",
       "0          Separado     NaN   E109   \n",
       "1            Casado     NaN   E119   \n",
       "2           Soltero      O+   E119   \n",
       "3           Soltero      O+   E109   \n",
       "4           Soltero      O+   E119   \n",
       "...             ...     ...    ...   \n",
       "140167          NaN     NaN   A539   \n",
       "140168      Soltero      O+   A530   \n",
       "140169       Casado     NaN   E109   \n",
       "140170  Desconocido     NaN   E119   \n",
       "140171  Desconocido     NaN   E149   \n",
       "\n",
       "                                                   Nombre  \\\n",
       "0       DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "1       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "2       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "3       DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "4       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "...                                                   ...   \n",
       "140167                           SIFILIS, NO ESPECIFICADA   \n",
       "140168  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "140169  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "140170  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "140171  DIABETES MELLITUS, NO ESPECIFICADA SIN MENCION...   \n",
       "\n",
       "                         Tipo  \\\n",
       "0         Confirmado Repetido   \n",
       "1         Confirmado Repetido   \n",
       "2         Confirmado Repetido   \n",
       "3         Confirmado Repetido   \n",
       "4            Confirmado Nuevo   \n",
       "...                       ...   \n",
       "140167    Confirmado Repetido   \n",
       "140168    Confirmado Repetido   \n",
       "140169    Confirmado Repetido   \n",
       "140170  Impresión Diagnóstica   \n",
       "140171    Confirmado Repetido   \n",
       "\n",
       "                                                     Plan  \n",
       "0       PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...  \n",
       "1                            CONTINUA PROGRAMA CRONICOS.   \n",
       "2       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "3       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "4       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "...                                                   ...  \n",
       "140167  explica acerca programa, recomienda adherencia...  \n",
       "140168  Elaboracion duelo frente diagnostico.   Reforz...  \n",
       "140169  FUROATO MOMETASONA 1 SPRY NASAL CADA FOSA NASA...  \n",
       "140170  CONTROL MEICO MES-INFECTOLOGIA  VALORACIOJN IN...  \n",
       "140171  CONTINUA SEGUIMIENTO PROGRAMA NEFROPROTECCION ...  \n",
       "\n",
       "[140172 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = df_sociodemografico.merge(df_notas, how='inner', on='IDRecord')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "      <th>acido</th>\n",
       "      <th>antibio</th>\n",
       "      <th>asintoma</th>\n",
       "      <th>cabeza</th>\n",
       "      <th>diabet</th>\n",
       "      <th>diet</th>\n",
       "      <th>gluco</th>\n",
       "      <th>hepat</th>\n",
       "      <th>insulin</th>\n",
       "      <th>keto</th>\n",
       "      <th>penici</th>\n",
       "      <th>preservativo</th>\n",
       "      <th>rpr</th>\n",
       "      <th>sable</th>\n",
       "      <th>serolo</th>\n",
       "      <th>sifili</th>\n",
       "      <th>test_reloj_orden</th>\n",
       "      <th>vih</th>\n",
       "      <th>top_lab_name</th>\n",
       "      <th>top_lab_avg_value</th>\n",
       "      <th>top_lab_max_value</th>\n",
       "      <th>top_lab_count</th>\n",
       "      <th>total_lab_count</th>\n",
       "      <th>date_diff_mean</th>\n",
       "      <th>date_diff_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CALCIO POR COLORIMETRÍA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA PROGRAMA CRONICOS.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Nuevo</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0         5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1       292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "4       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "\n",
       "  EstadoCivil TSangre Código  \\\n",
       "0    Separado     NaN   E109   \n",
       "1      Casado     NaN   E119   \n",
       "2     Soltero      O+   E119   \n",
       "3     Soltero      O+   E109   \n",
       "4     Soltero      O+   E119   \n",
       "\n",
       "                                              Nombre                 Tipo  \\\n",
       "0  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...  Confirmado Repetido   \n",
       "1  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...  Confirmado Repetido   \n",
       "2  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...  Confirmado Repetido   \n",
       "3  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...  Confirmado Repetido   \n",
       "4  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...     Confirmado Nuevo   \n",
       "\n",
       "                                                Plan  acido  antibio  \\\n",
       "0  PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...      0        0   \n",
       "1                       CONTINUA PROGRAMA CRONICOS.       0        0   \n",
       "2  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "3  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "4  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "\n",
       "   asintoma  cabeza  diabet  diet  gluco  hepat  insulin  keto  penici  \\\n",
       "0         0       0       0     0      0      0        0     0       0   \n",
       "1         0       0       0     0      0      0        0     0       0   \n",
       "2         0       0       0     1      0      0        0     0       0   \n",
       "3         0       0       0     1      0      0        0     0       0   \n",
       "4         0       0       0     1      0      0        0     0       0   \n",
       "\n",
       "   preservativo  rpr  sable  serolo  sifili  test_reloj_orden  vih  \\\n",
       "0             0    0      0       0       0                 0    0   \n",
       "1             0    0      0       0       0                 0    0   \n",
       "2             0    0      0       0       0                 0    0   \n",
       "3             0    0      0       0       0                 0    0   \n",
       "4             0    0      0       0       0                 0    0   \n",
       "\n",
       "               top_lab_name  top_lab_avg_value  top_lab_max_value  \\\n",
       "0  CALCIO POR COLORIMETRÍA                 8.0                8.0   \n",
       "1                       NaN                NaN                NaN   \n",
       "2                       NaN                NaN                NaN   \n",
       "3                       NaN                NaN                NaN   \n",
       "4                       NaN                NaN                NaN   \n",
       "\n",
       "   top_lab_count  total_lab_count  date_diff_mean  date_diff_max  \n",
       "0            1.0              8.0             0.0            0.0  \n",
       "1            NaN              NaN             NaN            NaN  \n",
       "2            NaN              NaN             NaN            NaN  \n",
       "3            NaN              NaN             NaN            NaN  \n",
       "4            NaN              NaN             NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Consolidate the classes\n",
    "if consolidate_classes:\n",
    "    df_merge = merge_classes(df_merge)\n",
    "\n",
    "# Perform word count feature engineering\n",
    "df_merge = word_count_feat_engineering(df_merge)\n",
    "\n",
    "# Preprocess the lab data and merge it with the sociodemographic data\n",
    "df_merge = merge_labs_notas(df_laboratorios, df_merge)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_merge.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([  977,    94,  2614,  1970, 60586, 47408,  6278, 17437,  2808]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_merge.drop(labels=[target_feature], axis=1)\n",
    "y = df_merge[target_feature]\n",
    "if as_dual_class:\n",
    "    y = y.str[:2]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform(y)\n",
    "\n",
    "np.unique(y_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([  195,    19,   523,   394, 12117,  9481,  1256,  3487,   562]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labels, train_size=0.2, random_state=42, stratify=y_labels)\n",
    "np.unique(y_train, return_counts=True) # Let's check the number of samples per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([12117, 12117, 12117, 12117, 12117, 12117, 12117, 12117, 12117]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if balance_classes == 'oversample':\n",
    "    # Using a naive oversampling approach\n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "elif balance_classes == 'undersample':\n",
    "    # Using a naive oversampling approach\n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "np.unique(y_train, return_counts=True) # Let's check the number of samples per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = \"nnlm-es-dim128\"\n",
    "embedding = \"nnlm-es-dim128-with-normalization\"\n",
    "# embedding = \"universal\"\n",
    "\n",
    "if add_gpu_prediction:\n",
    "    model_function = gpu_model_hub\n",
    "    clf = KerasClassifierModel(\n",
    "        build_fn=model_function,\n",
    "        class_number=len(df_notas[target_feature].unique()),\n",
    "        embedding = embedding,\n",
    "        epochs=400,\n",
    "        batch_size=400,\n",
    "        verbose=10,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train[text_feature], y_train)\n",
    "    clf.plot_learning_curves('data/output/gpu_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gpu_prediction:\n",
    "    y_pred = clf.predict(X_test[text_feature])\n",
    "    display(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gpu_prediction:\n",
    "    X_pred = clf.predict(df_merge[text_feature])\n",
    "    df_merge['GPU_prediction'] = X_pred\n",
    "    df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the numerical features that will be used in the model\n",
    "numerical_features = list(\n",
    "    set(\n",
    "        [\n",
    "            \"Edad\",\n",
    "            \"top_lab_avg_value\",\n",
    "            \"top_lab_max_value\",\n",
    "            \"top_lab_count\",\n",
    "            \"total_lab_count\",\n",
    "            \"date_diff_mean\",\n",
    "            \"date_diff_max\",\n",
    "        ]\n",
    "        + list(df_merge.drop(columns=\"IDRecord\").select_dtypes(include=\"int64\").columns)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Now define the categorical features\n",
    "categorical_features = [\n",
    "    \"Genero\",\n",
    "    \"GrupoEtnico\",\n",
    "    \"AreaResidencial\",\n",
    "    \"EstadoCivil\",\n",
    "    \"TSangre\",\n",
    "    \"Tipo\",\n",
    "    \"top_lab_name\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                                               &#x27;la&#x27;,\n",
       "                                                                                               &#x27;que&#x27;,\n",
       "                                                                                               &#x27;el&#x27;,\n",
       "                                                                                               &#x27;en&#x27;,\n",
       "                                                                                               &#x27;y&#x27;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;los&#x27;,\n",
       "                                                                                               &#x27;del&#x27;,\n",
       "                                                                                               &#x27;se&#x27;,\n",
       "                                                                                               &#x27;las&#x27;,\n",
       "                                                                                               &#x27;por&#x27;,\n",
       "                                                                                               &#x27;un&#x27;,\n",
       "                                                                                               &#x27;para&#x27;,\n",
       "                                                                                               &#x27;con&#x27;,\n",
       "                                                                                               &#x27;no&#x27;,\n",
       "                                                                                               &#x27;una&#x27;,\n",
       "                                                                                               &#x27;su&#x27;,\n",
       "                                                                                               &#x27;al&#x27;,\n",
       "                                                                                               &#x27;lo&#x27;,\n",
       "                                                                                               &#x27;como&#x27;,\n",
       "                                                                                               &#x27;más&#x27;,\n",
       "                                                                                               &#x27;pero&#x27;,\n",
       "                                                                                               &#x27;sus&#x27;,\n",
       "                                                                                               &#x27;le&#x27;,\n",
       "                                                                                               &#x27;ya&#x27;,\n",
       "                                                                                               &#x27;o&#x27;,\n",
       "                                                                                               &#x27;este&#x27;,\n",
       "                                                                                               &#x27;sí&#x27;,\n",
       "                                                                                               &#x27;porque&#x27;, ...],\n",
       "                                                                                   strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                                  (&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  &#x27;Plan&#x27;)])),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                (&#x27;estimator&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                                               &#x27;la&#x27;,\n",
       "                                                                                               &#x27;que&#x27;,\n",
       "                                                                                               &#x27;el&#x27;,\n",
       "                                                                                               &#x27;en&#x27;,\n",
       "                                                                                               &#x27;y&#x27;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;los&#x27;,\n",
       "                                                                                               &#x27;del&#x27;,\n",
       "                                                                                               &#x27;se&#x27;,\n",
       "                                                                                               &#x27;las&#x27;,\n",
       "                                                                                               &#x27;por&#x27;,\n",
       "                                                                                               &#x27;un&#x27;,\n",
       "                                                                                               &#x27;para&#x27;,\n",
       "                                                                                               &#x27;con&#x27;,\n",
       "                                                                                               &#x27;no&#x27;,\n",
       "                                                                                               &#x27;una&#x27;,\n",
       "                                                                                               &#x27;su&#x27;,\n",
       "                                                                                               &#x27;al&#x27;,\n",
       "                                                                                               &#x27;lo&#x27;,\n",
       "                                                                                               &#x27;como&#x27;,\n",
       "                                                                                               &#x27;más&#x27;,\n",
       "                                                                                               &#x27;pero&#x27;,\n",
       "                                                                                               &#x27;sus&#x27;,\n",
       "                                                                                               &#x27;le&#x27;,\n",
       "                                                                                               &#x27;ya&#x27;,\n",
       "                                                                                               &#x27;o&#x27;,\n",
       "                                                                                               &#x27;este&#x27;,\n",
       "                                                                                               &#x27;sí&#x27;,\n",
       "                                                                                               &#x27;porque&#x27;, ...],\n",
       "                                                                                   strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                                  (&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  &#x27;Plan&#x27;)])),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                (&#x27;estimator&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;,\n",
       "                                  &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;,\n",
       "                                  &#x27;top_lab_name&#x27;]),\n",
       "                                (&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardS...\n",
       "                                  &#x27;vih&#x27;, &#x27;penici&#x27;, &#x27;sable&#x27;, &#x27;top_lab_avg_value&#x27;,\n",
       "                                  &#x27;diet&#x27;, &#x27;preservativo&#x27;]),\n",
       "                                (&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                              &#x27;la&#x27;,\n",
       "                                                                              &#x27;que&#x27;,\n",
       "                                                                              &#x27;el&#x27;,\n",
       "                                                                              &#x27;en&#x27;,\n",
       "                                                                              &#x27;y&#x27;,\n",
       "                                                                              &#x27;a&#x27;,\n",
       "                                                                              &#x27;los&#x27;,\n",
       "                                                                              &#x27;del&#x27;,\n",
       "                                                                              &#x27;se&#x27;,\n",
       "                                                                              &#x27;las&#x27;,\n",
       "                                                                              &#x27;por&#x27;,\n",
       "                                                                              &#x27;un&#x27;,\n",
       "                                                                              &#x27;para&#x27;,\n",
       "                                                                              &#x27;con&#x27;,\n",
       "                                                                              &#x27;no&#x27;,\n",
       "                                                                              &#x27;una&#x27;,\n",
       "                                                                              &#x27;su&#x27;,\n",
       "                                                                              &#x27;al&#x27;,\n",
       "                                                                              &#x27;lo&#x27;,\n",
       "                                                                              &#x27;como&#x27;,\n",
       "                                                                              &#x27;más&#x27;,\n",
       "                                                                              &#x27;pero&#x27;,\n",
       "                                                                              &#x27;sus&#x27;,\n",
       "                                                                              &#x27;le&#x27;,\n",
       "                                                                              &#x27;ya&#x27;,\n",
       "                                                                              &#x27;o&#x27;,\n",
       "                                                                              &#x27;este&#x27;,\n",
       "                                                                              &#x27;sí&#x27;,\n",
       "                                                                              &#x27;porque&#x27;, ...],\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  TfidfTransformer())]),\n",
       "                                 &#x27;Plan&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;, &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;date_diff_max&#x27;, &#x27;acido&#x27;, &#x27;sifili&#x27;, &#x27;top_lab_max_value&#x27;, &#x27;date_diff_mean&#x27;, &#x27;cabeza&#x27;, &#x27;diabet&#x27;, &#x27;hepat&#x27;, &#x27;total_lab_count&#x27;, &#x27;antibio&#x27;, &#x27;insulin&#x27;, &#x27;serolo&#x27;, &#x27;top_lab_count&#x27;, &#x27;keto&#x27;, &#x27;asintoma&#x27;, &#x27;Edad&#x27;, &#x27;test_reloj_orden&#x27;, &#x27;gluco&#x27;, &#x27;rpr&#x27;, &#x27;vih&#x27;, &#x27;penici&#x27;, &#x27;sable&#x27;, &#x27;top_lab_avg_value&#x27;, &#x27;diet&#x27;, &#x27;preservativo&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>Plan</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;que&#x27;, &#x27;el&#x27;, &#x27;en&#x27;, &#x27;y&#x27;, &#x27;a&#x27;, &#x27;los&#x27;,\n",
       "                            &#x27;del&#x27;, &#x27;se&#x27;, &#x27;las&#x27;, &#x27;por&#x27;, &#x27;un&#x27;, &#x27;para&#x27;, &#x27;con&#x27;,\n",
       "                            &#x27;no&#x27;, &#x27;una&#x27;, &#x27;su&#x27;, &#x27;al&#x27;, &#x27;lo&#x27;, &#x27;como&#x27;, &#x27;más&#x27;,\n",
       "                            &#x27;pero&#x27;, &#x27;sus&#x27;, &#x27;le&#x27;, &#x27;ya&#x27;, &#x27;o&#x27;, &#x27;este&#x27;, &#x27;sí&#x27;,\n",
       "                            &#x27;porque&#x27;, ...],\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_selector: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestRegressor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Genero', 'GrupoEtnico',\n",
       "                                                   'AreaResidencial',\n",
       "                                                   'EstadoCivil', 'TSangre',\n",
       "                                                   'Tipo', 'top_lab_name']),\n",
       "                                                 ('numerical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=['de',\n",
       "                                                                                               'la',\n",
       "                                                                                               'que',\n",
       "                                                                                               'el',\n",
       "                                                                                               'en',\n",
       "                                                                                               'y',\n",
       "                                                                                               'a',\n",
       "                                                                                               'los',\n",
       "                                                                                               'del',\n",
       "                                                                                               'se',\n",
       "                                                                                               'las',\n",
       "                                                                                               'por',\n",
       "                                                                                               'un',\n",
       "                                                                                               'para',\n",
       "                                                                                               'con',\n",
       "                                                                                               'no',\n",
       "                                                                                               'una',\n",
       "                                                                                               'su',\n",
       "                                                                                               'al',\n",
       "                                                                                               'lo',\n",
       "                                                                                               'como',\n",
       "                                                                                               'más',\n",
       "                                                                                               'pero',\n",
       "                                                                                               'sus',\n",
       "                                                                                               'le',\n",
       "                                                                                               'ya',\n",
       "                                                                                               'o',\n",
       "                                                                                               'este',\n",
       "                                                                                               'sí',\n",
       "                                                                                               'porque', ...],\n",
       "                                                                                   strip_accents='unicode')),\n",
       "                                                                  ('tfidf',\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  'Plan')])),\n",
       "                ('feature_selector',\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                ('estimator', RandomForestClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the GPU prediction if we are using a GPU model for predicting the data\n",
    "if 'GPU_prediction' in df_merge:\n",
    "    categorical_features.append('GPU_prediction')\n",
    "\n",
    "pipeline = PipelineManager(estimator=\"classifier\")\n",
    "pipeline.set_numerical_features(numerical_features)\n",
    "pipeline.set_categorical_features(categorical_features)\n",
    "pipeline.set_text_feature(text_feature)\n",
    "pipeline.set_basic_pipeline()\n",
    "\n",
    "# param_grid = {\n",
    "#     \"n_estimators\": np.linspace(1, 100, 10, dtype=int),\n",
    "#     \"max_depth\": list(np.linspace(1, 10, 5, dtype=int)) + [None],\n",
    "#     \"bootstrap\": [True, False],\n",
    "# }\n",
    "# estimator = RandomForestClassifier()\n",
    "# pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.linspace(1, 200, 10, dtype=int),\n",
    "    \"max_depth\": list(np.linspace(2, 10, 5, dtype=int)) + [None],\n",
    "    \"eta\": np.linspace(0.01, 0.5, 10, dtype=float),\n",
    "    \"min_child_weight\": np.linspace(0.5, 20, 5, dtype=float),\n",
    "    \"gamma\": np.linspace(0, 1, 5, dtype=float),\n",
    "    \"subsample\": np.linspace(0.1, 1, 5, dtype=float),\n",
    "    \"colsample_bytree\": np.linspace(0.2, 1, 5, dtype=float),\n",
    "    \"reg_lambda\": np.linspace(0, 12, 10, dtype=float),\n",
    "    \"reg_alpha\": np.linspace(0, 12, 10, dtype=float),\n",
    "    # \"scale_pos_weight\": np.linspace(0.1, 500, 100, dtype=float),\n",
    "}\n",
    "estimator = XGBClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "param_grid = {}\n",
    "estimator = PassiveAggressiveClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "estimator = SGDClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": np.linspace(0, 2, 10, dtype=float),\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"auto\", \"scale\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"coef0\": np.linspace(0, 2, 10, dtype=float),\n",
    "    \"degree\": np.linspace(1, 5, 5, dtype=int),\n",
    "}\n",
    "estimator = SVC()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "\n",
    "pipeline.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "24 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py\", line 673, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py\", line 604, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 414, in fit_transform\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 870, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/impute/_knn.py\", line 210, in fit\n",
      "    X = self._validate_data(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 577, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 856, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'Hombre'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.92518317 0.64474155 0.64855621        nan\n",
      " 0.41131376 0.77310115        nan 0.91788396 0.84401163 0.94191815\n",
      "        nan        nan 0.28951977 0.82336112 0.78839647        nan\n",
      "        nan 0.62645686]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.92309762 0.61984815 0.6381244         nan\n",
      " 0.36932391 0.76737175        nan 0.91603028 0.83684564 0.94083287\n",
      "        nan        nan 0.28999153 0.81750669 0.77805419        nan\n",
      "        nan 0.61432526]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample_weight = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=df_merge[target_feature])\n",
    "\n",
    "scoring = {\n",
    "    \"Accuracy\": \"balanced_accuracy\",\n",
    "    \"Weighted_F1\": make_scorer(f1_score, average='weighted'),\n",
    "    # 'roc_auc':make_scorer(roc_auc_score, average='weighted'),\n",
    "    }\n",
    "best_model = pipeline.find_best_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    n_iter=n_iter,\n",
    "    n_jobs=n_jobs,\n",
    "    scoring=scoring,\n",
    "    random_state=7,\n",
    "    refit='Weighted_F1',\n",
    "    verbose = 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strate...\n",
       "                               gamma=0.25, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "                               importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.336666673, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=8, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                               n_estimators=67, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strate...\n",
       "                               gamma=0.25, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "                               importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.336666673, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=8, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                               n_estimators=67, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;,\n",
       "                                  &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;,\n",
       "                                  &#x27;top_lab_name&#x27;]),\n",
       "                                (&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, N...\n",
       "                                  &#x27;vih&#x27;, &#x27;penici&#x27;, &#x27;sable&#x27;, &#x27;top_lab_avg_value&#x27;,\n",
       "                                  &#x27;diet&#x27;, &#x27;preservativo&#x27;]),\n",
       "                                (&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  CountVectorizer(ngram_range=(2,\n",
       "                                                                               3),\n",
       "                                                                  stop_words=[&#x27;de&#x27;,\n",
       "                                                                              &#x27;la&#x27;,\n",
       "                                                                              &#x27;que&#x27;,\n",
       "                                                                              &#x27;el&#x27;,\n",
       "                                                                              &#x27;en&#x27;,\n",
       "                                                                              &#x27;y&#x27;,\n",
       "                                                                              &#x27;a&#x27;,\n",
       "                                                                              &#x27;los&#x27;,\n",
       "                                                                              &#x27;del&#x27;,\n",
       "                                                                              &#x27;se&#x27;,\n",
       "                                                                              &#x27;las&#x27;,\n",
       "                                                                              &#x27;por&#x27;,\n",
       "                                                                              &#x27;un&#x27;,\n",
       "                                                                              &#x27;para&#x27;,\n",
       "                                                                              &#x27;con&#x27;,\n",
       "                                                                              &#x27;no&#x27;,\n",
       "                                                                              &#x27;una&#x27;,\n",
       "                                                                              &#x27;su&#x27;,\n",
       "                                                                              &#x27;al&#x27;,\n",
       "                                                                              &#x27;lo&#x27;,\n",
       "                                                                              &#x27;como&#x27;,\n",
       "                                                                              &#x27;más&#x27;,\n",
       "                                                                              &#x27;pero&#x27;,\n",
       "                                                                              &#x27;sus&#x27;,\n",
       "                                                                              &#x27;le&#x27;,\n",
       "                                                                              &#x27;ya&#x27;,\n",
       "                                                                              &#x27;o&#x27;,\n",
       "                                                                              &#x27;este&#x27;,\n",
       "                                                                              &#x27;sí&#x27;,\n",
       "                                                                              &#x27;porque&#x27;, ...],\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  TfidfTransformer())]),\n",
       "                                 &#x27;Plan&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;, &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;date_diff_max&#x27;, &#x27;acido&#x27;, &#x27;sifili&#x27;, &#x27;top_lab_max_value&#x27;, &#x27;date_diff_mean&#x27;, &#x27;cabeza&#x27;, &#x27;diabet&#x27;, &#x27;hepat&#x27;, &#x27;total_lab_count&#x27;, &#x27;antibio&#x27;, &#x27;insulin&#x27;, &#x27;serolo&#x27;, &#x27;top_lab_count&#x27;, &#x27;keto&#x27;, &#x27;asintoma&#x27;, &#x27;Edad&#x27;, &#x27;test_reloj_orden&#x27;, &#x27;gluco&#x27;, &#x27;rpr&#x27;, &#x27;vih&#x27;, &#x27;penici&#x27;, &#x27;sable&#x27;, &#x27;top_lab_avg_value&#x27;, &#x27;diet&#x27;, &#x27;preservativo&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Normalizer</label><div class=\"sk-toggleable__content\"><pre>Normalizer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>Plan</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(2, 3),\n",
       "                stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;que&#x27;, &#x27;el&#x27;, &#x27;en&#x27;, &#x27;y&#x27;, &#x27;a&#x27;, &#x27;los&#x27;,\n",
       "                            &#x27;del&#x27;, &#x27;se&#x27;, &#x27;las&#x27;, &#x27;por&#x27;, &#x27;un&#x27;, &#x27;para&#x27;, &#x27;con&#x27;,\n",
       "                            &#x27;no&#x27;, &#x27;una&#x27;, &#x27;su&#x27;, &#x27;al&#x27;, &#x27;lo&#x27;, &#x27;como&#x27;, &#x27;más&#x27;,\n",
       "                            &#x27;pero&#x27;, &#x27;sus&#x27;, &#x27;le&#x27;, &#x27;ya&#x27;, &#x27;o&#x27;, &#x27;este&#x27;, &#x27;sí&#x27;,\n",
       "                            &#x27;porque&#x27;, ...],\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_selector: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=ElasticNet())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1,\n",
       "              colsample_bytree=0.6000000000000001, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.33666666666666667,\n",
       "              eval_metric=None, gamma=0.25, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.336666673, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=0.5,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=67, n_jobs=0,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Genero', 'GrupoEtnico',\n",
       "                                                   'AreaResidencial',\n",
       "                                                   'EstadoCivil', 'TSangre',\n",
       "                                                   'Tipo', 'top_lab_name']),\n",
       "                                                 ('numerical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strate...\n",
       "                               gamma=0.25, gpu_id=-1, grow_policy='depthwise',\n",
       "                               importance_type=None, interaction_constraints='',\n",
       "                               learning_rate=0.336666673, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=8, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints='()',\n",
       "                               n_estimators=67, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, ...))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_preprocessor__text__vectorizer</th>\n",
       "      <th>param_preprocessor__text__tfidf</th>\n",
       "      <th>param_preprocessor__numerical__scaler</th>\n",
       "      <th>param_preprocessor__numerical__imputer</th>\n",
       "      <th>param_preprocessor__categorical__imputer</th>\n",
       "      <th>param_feature_selector</th>\n",
       "      <th>param_estimator__subsample</th>\n",
       "      <th>param_estimator__reg_lambda</th>\n",
       "      <th>param_estimator__reg_alpha</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "      <th>param_estimator__min_child_weight</th>\n",
       "      <th>param_estimator__max_depth</th>\n",
       "      <th>param_estimator__gamma</th>\n",
       "      <th>param_estimator__eta</th>\n",
       "      <th>param_estimator__colsample_bytree</th>\n",
       "      <th>param_estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>split1_test_Accuracy</th>\n",
       "      <th>split2_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>split0_test_Weighted_F1</th>\n",
       "      <th>split1_test_Weighted_F1</th>\n",
       "      <th>split2_test_Weighted_F1</th>\n",
       "      <th>mean_test_Weighted_F1</th>\n",
       "      <th>std_test_Weighted_F1</th>\n",
       "      <th>rank_test_Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2086.405911</td>\n",
       "      <td>110.460207</td>\n",
       "      <td>23.320806</td>\n",
       "      <td>0.538092</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.940469</td>\n",
       "      <td>0.939066</td>\n",
       "      <td>0.946219</td>\n",
       "      <td>0.941918</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939337</td>\n",
       "      <td>0.937869</td>\n",
       "      <td>0.945292</td>\n",
       "      <td>0.940833</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6322.255277</td>\n",
       "      <td>182.352127</td>\n",
       "      <td>688.631166</td>\n",
       "      <td>57.692860</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.922313</td>\n",
       "      <td>0.922616</td>\n",
       "      <td>0.930621</td>\n",
       "      <td>0.925183</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>2</td>\n",
       "      <td>0.920189</td>\n",
       "      <td>0.920280</td>\n",
       "      <td>0.928824</td>\n",
       "      <td>0.923098</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1793.480509</td>\n",
       "      <td>84.120466</td>\n",
       "      <td>527.867998</td>\n",
       "      <td>130.318664</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.325</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>155</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.227778</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.914060</td>\n",
       "      <td>0.919920</td>\n",
       "      <td>0.919672</td>\n",
       "      <td>0.917884</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>3</td>\n",
       "      <td>0.912172</td>\n",
       "      <td>0.917949</td>\n",
       "      <td>0.917970</td>\n",
       "      <td>0.916030</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2795.903014</td>\n",
       "      <td>185.151898</td>\n",
       "      <td>26.854598</td>\n",
       "      <td>5.107030</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>111</td>\n",
       "      <td>15.125</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.847294</td>\n",
       "      <td>0.842948</td>\n",
       "      <td>0.841793</td>\n",
       "      <td>0.844012</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>4</td>\n",
       "      <td>0.840496</td>\n",
       "      <td>0.835423</td>\n",
       "      <td>0.834617</td>\n",
       "      <td>0.836846</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>419.681727</td>\n",
       "      <td>190.239817</td>\n",
       "      <td>26.928435</td>\n",
       "      <td>2.727870</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>133</td>\n",
       "      <td>5.375</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.824847</td>\n",
       "      <td>0.825644</td>\n",
       "      <td>0.819592</td>\n",
       "      <td>0.823361</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>5</td>\n",
       "      <td>0.818581</td>\n",
       "      <td>0.819897</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>0.817507</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1449.093999</td>\n",
       "      <td>65.088983</td>\n",
       "      <td>42.212125</td>\n",
       "      <td>9.897408</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>177</td>\n",
       "      <td>10.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.793376</td>\n",
       "      <td>0.788782</td>\n",
       "      <td>0.783032</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>6</td>\n",
       "      <td>0.782637</td>\n",
       "      <td>0.778697</td>\n",
       "      <td>0.772829</td>\n",
       "      <td>0.778054</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1945.239315</td>\n",
       "      <td>181.142762</td>\n",
       "      <td>444.639534</td>\n",
       "      <td>41.674772</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.770020</td>\n",
       "      <td>0.776402</td>\n",
       "      <td>0.772881</td>\n",
       "      <td>0.773101</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>7</td>\n",
       "      <td>0.764471</td>\n",
       "      <td>0.770137</td>\n",
       "      <td>0.767507</td>\n",
       "      <td>0.767372</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186.995847</td>\n",
       "      <td>7.711513</td>\n",
       "      <td>9.879736</td>\n",
       "      <td>1.029489</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>45</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.644934</td>\n",
       "      <td>0.651371</td>\n",
       "      <td>0.649363</td>\n",
       "      <td>0.648556</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>8</td>\n",
       "      <td>0.635096</td>\n",
       "      <td>0.640189</td>\n",
       "      <td>0.639089</td>\n",
       "      <td>0.638124</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352.852078</td>\n",
       "      <td>236.349376</td>\n",
       "      <td>13.529567</td>\n",
       "      <td>2.288608</td>\n",
       "      <td>CountVectorizer(ngram_range=(4, 4),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>45</td>\n",
       "      <td>15.125</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.645649</td>\n",
       "      <td>0.644934</td>\n",
       "      <td>0.643641</td>\n",
       "      <td>0.644742</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>9</td>\n",
       "      <td>0.621078</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.618748</td>\n",
       "      <td>0.619848</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>979.689895</td>\n",
       "      <td>88.316680</td>\n",
       "      <td>256.363902</td>\n",
       "      <td>24.132587</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>8.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.624219</td>\n",
       "      <td>0.624027</td>\n",
       "      <td>0.631124</td>\n",
       "      <td>0.626457</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>10</td>\n",
       "      <td>0.611728</td>\n",
       "      <td>0.612125</td>\n",
       "      <td>0.619122</td>\n",
       "      <td>0.614325</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1398.238305</td>\n",
       "      <td>9.583583</td>\n",
       "      <td>446.163390</td>\n",
       "      <td>13.266501</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>133</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.410250</td>\n",
       "      <td>0.410910</td>\n",
       "      <td>0.412781</td>\n",
       "      <td>0.411314</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>11</td>\n",
       "      <td>0.368440</td>\n",
       "      <td>0.368187</td>\n",
       "      <td>0.371345</td>\n",
       "      <td>0.369324</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>49.080199</td>\n",
       "      <td>2.515928</td>\n",
       "      <td>11.178227</td>\n",
       "      <td>0.933115</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>10.25</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.329014</td>\n",
       "      <td>0.273307</td>\n",
       "      <td>0.266238</td>\n",
       "      <td>0.289520</td>\n",
       "      <td>0.028076</td>\n",
       "      <td>12</td>\n",
       "      <td>0.320047</td>\n",
       "      <td>0.277252</td>\n",
       "      <td>0.272675</td>\n",
       "      <td>0.289992</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.069877</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.084452</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.775</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>177</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.091457</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.775</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.104496</td>\n",
       "      <td>0.028106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.325</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>200</td>\n",
       "      <td>10.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166586</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.445556</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.072201</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.775</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>111</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.067110</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>133</td>\n",
       "      <td>5.375</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131648</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>23</td>\n",
       "      <td>5.375</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11    2086.405911    110.460207        23.320806        0.538092   \n",
       "2     6322.255277    182.352127       688.631166       57.692860   \n",
       "9     1793.480509     84.120466       527.867998      130.318664   \n",
       "10    2795.903014    185.151898        26.854598        5.107030   \n",
       "15     419.681727    190.239817        26.928435        2.727870   \n",
       "16    1449.093999     65.088983        42.212125        9.897408   \n",
       "7     1945.239315    181.142762       444.639534       41.674772   \n",
       "4      186.995847      7.711513         9.879736        1.029489   \n",
       "3      352.852078    236.349376        13.529567        2.288608   \n",
       "19     979.689895     88.316680       256.363902       24.132587   \n",
       "6     1398.238305      9.583583       446.163390       13.266501   \n",
       "14      49.080199      2.515928        11.178227        0.933115   \n",
       "8        0.069877      0.003474         0.000000        0.000000   \n",
       "12       0.084452      0.004147         0.000000        0.000000   \n",
       "13       0.091457      0.015107         0.000000        0.000000   \n",
       "5        0.104496      0.028106         0.000000        0.000000   \n",
       "1        0.166586      0.026757         0.000000        0.000000   \n",
       "17       0.072201      0.004186         0.000000        0.000000   \n",
       "18       0.067110      0.004997         0.000000        0.000000   \n",
       "0        0.131648      0.029250         0.000000        0.000000   \n",
       "\n",
       "                 param_preprocessor__text__vectorizer  \\\n",
       "11  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "2   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "9   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "10  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "15  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "16  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "7   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "4   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "3   CountVectorizer(ngram_range=(4, 4),\\n         ...   \n",
       "19  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "6   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "14  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "8   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "12  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "13  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "5   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "1   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "17  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "18  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "0   CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "\n",
       "                   param_preprocessor__text__tfidf  \\\n",
       "11                              TfidfTransformer()   \n",
       "2   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "9                      TfidfTransformer(norm='l1')   \n",
       "10             TfidfTransformer(sublinear_tf=True)   \n",
       "15  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "16                     TfidfTransformer(norm='l1')   \n",
       "7                               TfidfTransformer()   \n",
       "4              TfidfTransformer(sublinear_tf=True)   \n",
       "3   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "19             TfidfTransformer(sublinear_tf=True)   \n",
       "6   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "14                              TfidfTransformer()   \n",
       "8                               TfidfTransformer()   \n",
       "12  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "13  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "5   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "1   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "17                              TfidfTransformer()   \n",
       "18                              TfidfTransformer()   \n",
       "0   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "\n",
       "   param_preprocessor__numerical__scaler  \\\n",
       "11                          Normalizer()   \n",
       "2                       StandardScaler()   \n",
       "9                           Normalizer()   \n",
       "10                        MinMaxScaler()   \n",
       "15                        RobustScaler()   \n",
       "16                      StandardScaler()   \n",
       "7                           Normalizer()   \n",
       "4                           Normalizer()   \n",
       "3                         RobustScaler()   \n",
       "19                      StandardScaler()   \n",
       "6                       StandardScaler()   \n",
       "14                        MinMaxScaler()   \n",
       "8                         MinMaxScaler()   \n",
       "12                      StandardScaler()   \n",
       "13                        MinMaxScaler()   \n",
       "5                           Normalizer()   \n",
       "1                         RobustScaler()   \n",
       "17                        RobustScaler()   \n",
       "18                        RobustScaler()   \n",
       "0                         RobustScaler()   \n",
       "\n",
       "     param_preprocessor__numerical__imputer  \\\n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "2                              KNNImputer()   \n",
       "9                              KNNImputer()   \n",
       "10                          SimpleImputer()   \n",
       "15         SimpleImputer(strategy='median')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "7                              KNNImputer()   \n",
       "4                           SimpleImputer()   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "19                             KNNImputer()   \n",
       "6                              KNNImputer()   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "8                           SimpleImputer()   \n",
       "12  SimpleImputer(strategy='most_frequent')   \n",
       "13  SimpleImputer(strategy='most_frequent')   \n",
       "5                           SimpleImputer()   \n",
       "1   SimpleImputer(strategy='most_frequent')   \n",
       "17         SimpleImputer(strategy='median')   \n",
       "18  SimpleImputer(strategy='most_frequent')   \n",
       "0                              KNNImputer()   \n",
       "\n",
       "   param_preprocessor__categorical__imputer  \\\n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "2   SimpleImputer(strategy='most_frequent')   \n",
       "9   SimpleImputer(strategy='most_frequent')   \n",
       "10  SimpleImputer(strategy='most_frequent')   \n",
       "15  SimpleImputer(strategy='most_frequent')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "7   SimpleImputer(strategy='most_frequent')   \n",
       "4   SimpleImputer(strategy='most_frequent')   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "19  SimpleImputer(strategy='most_frequent')   \n",
       "6   SimpleImputer(strategy='most_frequent')   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "8                 KNNImputer(n_neighbors=1)   \n",
       "12                KNNImputer(n_neighbors=1)   \n",
       "13                KNNImputer(n_neighbors=1)   \n",
       "5                 KNNImputer(n_neighbors=1)   \n",
       "1                 KNNImputer(n_neighbors=1)   \n",
       "17                KNNImputer(n_neighbors=1)   \n",
       "18                KNNImputer(n_neighbors=1)   \n",
       "0                 KNNImputer(n_neighbors=1)   \n",
       "\n",
       "                     param_feature_selector param_estimator__subsample  \\\n",
       "11  SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "2        SelectFromModel(estimator=Ridge())                        1.0   \n",
       "9        SelectFromModel(estimator=Ridge())                      0.325   \n",
       "10       SelectFromModel(estimator=Ridge())                      0.325   \n",
       "15  SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "16                      VarianceThreshold()                       0.55   \n",
       "7        SelectFromModel(estimator=Ridge())                       0.55   \n",
       "4   SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "3   SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "19       SelectFromModel(estimator=Ridge())                        0.1   \n",
       "6   SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "14  SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "8   SelectFromModel(estimator=ElasticNet())                      0.325   \n",
       "12       SelectFromModel(estimator=Ridge())                      0.775   \n",
       "13  SelectFromModel(estimator=ElasticNet())                      0.775   \n",
       "5                       VarianceThreshold()                      0.325   \n",
       "1   SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "17  SelectFromModel(estimator=ElasticNet())                      0.775   \n",
       "18                      VarianceThreshold()                        1.0   \n",
       "0        SelectFromModel(estimator=Ridge())                        0.1   \n",
       "\n",
       "   param_estimator__reg_lambda param_estimator__reg_alpha  \\\n",
       "11                         4.0                   6.666667   \n",
       "2                     9.333333                        0.0   \n",
       "9                         12.0                   1.333333   \n",
       "10                         4.0                   5.333333   \n",
       "15                    6.666667                   2.666667   \n",
       "16                   10.666667                       12.0   \n",
       "7                          4.0                        0.0   \n",
       "4                    10.666667                   5.333333   \n",
       "3                    10.666667                   5.333333   \n",
       "19                    6.666667                        8.0   \n",
       "6                     9.333333                   1.333333   \n",
       "14                    5.333333                   5.333333   \n",
       "8                          4.0                        8.0   \n",
       "12                    6.666667                   9.333333   \n",
       "13                    5.333333                        0.0   \n",
       "5                     1.333333                   5.333333   \n",
       "1                     5.333333                        0.0   \n",
       "17                         4.0                   2.666667   \n",
       "18                   10.666667                   1.333333   \n",
       "0                          0.0                   5.333333   \n",
       "\n",
       "   param_estimator__n_estimators param_estimator__min_child_weight  \\\n",
       "11                            67                               0.5   \n",
       "2                            133                               0.5   \n",
       "9                            155                               0.5   \n",
       "10                           111                            15.125   \n",
       "15                           133                             5.375   \n",
       "16                           177                             10.25   \n",
       "7                            200                               0.5   \n",
       "4                             45                              20.0   \n",
       "3                             45                            15.125   \n",
       "19                           155                               0.5   \n",
       "6                            133                               0.5   \n",
       "14                             1                             10.25   \n",
       "8                             67                               0.5   \n",
       "12                           177                              20.0   \n",
       "13                           177                               0.5   \n",
       "5                            200                             10.25   \n",
       "1                             67                             5.375   \n",
       "17                           111                              20.0   \n",
       "18                           133                             5.375   \n",
       "0                             23                             5.375   \n",
       "\n",
       "   param_estimator__max_depth param_estimator__gamma param_estimator__eta  \\\n",
       "11                          8                   0.25             0.336667   \n",
       "2                        None                    1.0                  0.5   \n",
       "9                           6                    1.0             0.227778   \n",
       "10                         10                    1.0             0.064444   \n",
       "15                          8                    0.5             0.064444   \n",
       "16                          8                    0.5                 0.01   \n",
       "7                        None                   0.25                 0.01   \n",
       "4                           2                   0.25             0.391111   \n",
       "3                        None                   0.25                 0.01   \n",
       "19                          2                    1.0             0.391111   \n",
       "6                           4                    0.0             0.336667   \n",
       "14                          2                    1.0             0.064444   \n",
       "8                           2                    0.5             0.336667   \n",
       "12                          2                   0.75             0.118889   \n",
       "13                         10                   0.25             0.336667   \n",
       "5                           8                   0.75                 0.01   \n",
       "1                           6                    0.5             0.445556   \n",
       "17                          8                    0.0                 0.01   \n",
       "18                          2                   0.25             0.391111   \n",
       "0                           4                    0.5             0.118889   \n",
       "\n",
       "   param_estimator__colsample_bytree  \\\n",
       "11                               0.6   \n",
       "2                                1.0   \n",
       "9                                0.6   \n",
       "10                               1.0   \n",
       "15                               0.8   \n",
       "16                               0.4   \n",
       "7                                0.4   \n",
       "4                                0.4   \n",
       "3                                0.8   \n",
       "19                               0.4   \n",
       "6                                0.4   \n",
       "14                               0.2   \n",
       "8                                0.6   \n",
       "12                               0.4   \n",
       "13                               1.0   \n",
       "5                                0.8   \n",
       "1                                0.2   \n",
       "17                               0.6   \n",
       "18                               0.2   \n",
       "0                                0.8   \n",
       "\n",
       "                                      param_estimator  \\\n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "2   XGBClassifier(base_score=None, booster=None, c...   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...   \n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "4   XGBClassifier(base_score=None, booster=None, c...   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...   \n",
       "8   XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...   \n",
       "13  XGBClassifier(base_score=None, booster=None, c...   \n",
       "5   XGBClassifier(base_score=None, booster=None, c...   \n",
       "1   XGBClassifier(base_score=None, booster=None, c...   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...   \n",
       "18  XGBClassifier(base_score=None, booster=None, c...   \n",
       "0   XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                                               params  split0_test_Accuracy  \\\n",
       "11  {'preprocessor__text__vectorizer': CountVector...              0.940469   \n",
       "2   {'preprocessor__text__vectorizer': CountVector...              0.922313   \n",
       "9   {'preprocessor__text__vectorizer': CountVector...              0.914060   \n",
       "10  {'preprocessor__text__vectorizer': CountVector...              0.847294   \n",
       "15  {'preprocessor__text__vectorizer': CountVector...              0.824847   \n",
       "16  {'preprocessor__text__vectorizer': CountVector...              0.793376   \n",
       "7   {'preprocessor__text__vectorizer': CountVector...              0.770020   \n",
       "4   {'preprocessor__text__vectorizer': CountVector...              0.644934   \n",
       "3   {'preprocessor__text__vectorizer': CountVector...              0.645649   \n",
       "19  {'preprocessor__text__vectorizer': CountVector...              0.624219   \n",
       "6   {'preprocessor__text__vectorizer': CountVector...              0.410250   \n",
       "14  {'preprocessor__text__vectorizer': CountVector...              0.329014   \n",
       "8   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "12  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "13  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "5   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "1   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "17  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "18  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "0   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "\n",
       "    split1_test_Accuracy  split2_test_Accuracy  mean_test_Accuracy  \\\n",
       "11              0.939066              0.946219            0.941918   \n",
       "2               0.922616              0.930621            0.925183   \n",
       "9               0.919920              0.919672            0.917884   \n",
       "10              0.842948              0.841793            0.844012   \n",
       "15              0.825644              0.819592            0.823361   \n",
       "16              0.788782              0.783032            0.788396   \n",
       "7               0.776402              0.772881            0.773101   \n",
       "4               0.651371              0.649363            0.648556   \n",
       "3               0.644934              0.643641            0.644742   \n",
       "19              0.624027              0.631124            0.626457   \n",
       "6               0.410910              0.412781            0.411314   \n",
       "14              0.273307              0.266238            0.289520   \n",
       "8                    NaN                   NaN                 NaN   \n",
       "12                   NaN                   NaN                 NaN   \n",
       "13                   NaN                   NaN                 NaN   \n",
       "5                    NaN                   NaN                 NaN   \n",
       "1                    NaN                   NaN                 NaN   \n",
       "17                   NaN                   NaN                 NaN   \n",
       "18                   NaN                   NaN                 NaN   \n",
       "0                    NaN                   NaN                 NaN   \n",
       "\n",
       "    std_test_Accuracy  rank_test_Accuracy  split0_test_Weighted_F1  \\\n",
       "11           0.003094                   1                 0.939337   \n",
       "2            0.003847                   2                 0.920189   \n",
       "9            0.002706                   3                 0.912172   \n",
       "10           0.002369                   4                 0.840496   \n",
       "15           0.002685                   5                 0.818581   \n",
       "16           0.004232                   6                 0.782637   \n",
       "7            0.002610                   7                 0.764471   \n",
       "4            0.002689                   8                 0.635096   \n",
       "3            0.000831                   9                 0.621078   \n",
       "19           0.003301                  10                 0.611728   \n",
       "6            0.001072                  11                 0.368440   \n",
       "14           0.028076                  12                 0.320047   \n",
       "8                 NaN                  13                      NaN   \n",
       "12                NaN                  14                      NaN   \n",
       "13                NaN                  15                      NaN   \n",
       "5                 NaN                  16                      NaN   \n",
       "1                 NaN                  17                      NaN   \n",
       "17                NaN                  18                      NaN   \n",
       "18                NaN                  19                      NaN   \n",
       "0                 NaN                  20                      NaN   \n",
       "\n",
       "    split1_test_Weighted_F1  split2_test_Weighted_F1  mean_test_Weighted_F1  \\\n",
       "11                 0.937869                 0.945292               0.940833   \n",
       "2                  0.920280                 0.928824               0.923098   \n",
       "9                  0.917949                 0.917970               0.916030   \n",
       "10                 0.835423                 0.834617               0.836846   \n",
       "15                 0.819897                 0.814041               0.817507   \n",
       "16                 0.778697                 0.772829               0.778054   \n",
       "7                  0.770137                 0.767507               0.767372   \n",
       "4                  0.640189                 0.639089               0.638124   \n",
       "3                  0.619718                 0.618748               0.619848   \n",
       "19                 0.612125                 0.619122               0.614325   \n",
       "6                  0.368187                 0.371345               0.369324   \n",
       "14                 0.277252                 0.272675               0.289992   \n",
       "8                       NaN                      NaN                    NaN   \n",
       "12                      NaN                      NaN                    NaN   \n",
       "13                      NaN                      NaN                    NaN   \n",
       "5                       NaN                      NaN                    NaN   \n",
       "1                       NaN                      NaN                    NaN   \n",
       "17                      NaN                      NaN                    NaN   \n",
       "18                      NaN                      NaN                    NaN   \n",
       "0                       NaN                      NaN                    NaN   \n",
       "\n",
       "    std_test_Weighted_F1  rank_test_Weighted_F1  \n",
       "11              0.003210                      1  \n",
       "2               0.004049                      2  \n",
       "9               0.002728                      3  \n",
       "10              0.002602                      4  \n",
       "15              0.002509                      5  \n",
       "16              0.004030                      6  \n",
       "7               0.002315                      7  \n",
       "4               0.002188                      8  \n",
       "3               0.000956                      9  \n",
       "19              0.003396                     10  \n",
       "6               0.001433                     11  \n",
       "14              0.021335                     12  \n",
       "8                    NaN                     13  \n",
       "12                   NaN                     14  \n",
       "13                   NaN                     15  \n",
       "5                    NaN                     16  \n",
       "1                    NaN                     17  \n",
       "17                   NaN                     18  \n",
       "18                   NaN                     19  \n",
       "0                    NaN                     20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"]).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_Weighted_F1</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_estimator</th>\n",
       "      <th>param_preprocessor__text__vectorizer</th>\n",
       "      <th>param_preprocessor__text__tfidf</th>\n",
       "      <th>param_preprocessor__numerical__scaler</th>\n",
       "      <th>param_preprocessor__numerical__imputer</th>\n",
       "      <th>param_feature_selector</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>mean_test_Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2086.405911</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.941918</td>\n",
       "      <td>0.940833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6322.255277</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.925183</td>\n",
       "      <td>0.923098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1793.480509</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.917884</td>\n",
       "      <td>0.916030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2795.903014</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.844012</td>\n",
       "      <td>0.836846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>419.681727</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.823361</td>\n",
       "      <td>0.817507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1449.093999</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.778054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1945.239315</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.773101</td>\n",
       "      <td>0.767372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>186.995847</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.648556</td>\n",
       "      <td>0.638124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>352.852078</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(4, 4),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.644742</td>\n",
       "      <td>0.619848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>979.689895</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.626457</td>\n",
       "      <td>0.614325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1398.238305</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.411314</td>\n",
       "      <td>0.369324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>49.080199</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.289520</td>\n",
       "      <td>0.289992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.069877</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.084452</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.091457</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.104496</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.166586</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.072201</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.067110</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.131648</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_Weighted_F1  rank_test_Accuracy  mean_fit_time  \\\n",
       "11                      1                   1    2086.405911   \n",
       "2                       2                   2    6322.255277   \n",
       "9                       3                   3    1793.480509   \n",
       "10                      4                   4    2795.903014   \n",
       "15                      5                   5     419.681727   \n",
       "16                      6                   6    1449.093999   \n",
       "7                       7                   7    1945.239315   \n",
       "4                       8                   8     186.995847   \n",
       "3                       9                   9     352.852078   \n",
       "19                     10                  10     979.689895   \n",
       "6                      11                  11    1398.238305   \n",
       "14                     12                  12      49.080199   \n",
       "8                      13                  13       0.069877   \n",
       "12                     14                  14       0.084452   \n",
       "13                     15                  15       0.091457   \n",
       "5                      16                  16       0.104496   \n",
       "1                      17                  17       0.166586   \n",
       "17                     18                  18       0.072201   \n",
       "18                     19                  19       0.067110   \n",
       "0                      20                  20       0.131648   \n",
       "\n",
       "                                      param_estimator  \\\n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "2   XGBClassifier(base_score=None, booster=None, c...   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...   \n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "4   XGBClassifier(base_score=None, booster=None, c...   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...   \n",
       "8   XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...   \n",
       "13  XGBClassifier(base_score=None, booster=None, c...   \n",
       "5   XGBClassifier(base_score=None, booster=None, c...   \n",
       "1   XGBClassifier(base_score=None, booster=None, c...   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...   \n",
       "18  XGBClassifier(base_score=None, booster=None, c...   \n",
       "0   XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                 param_preprocessor__text__vectorizer  \\\n",
       "11  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "2   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "9   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "10  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "15  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "16  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "7   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "4   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "3   CountVectorizer(ngram_range=(4, 4),\\n         ...   \n",
       "19  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "6   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "14  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "8   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "12  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "13  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "5   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "1   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "17  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "18  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "0   CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "\n",
       "                   param_preprocessor__text__tfidf  \\\n",
       "11                              TfidfTransformer()   \n",
       "2   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "9                      TfidfTransformer(norm='l1')   \n",
       "10             TfidfTransformer(sublinear_tf=True)   \n",
       "15  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "16                     TfidfTransformer(norm='l1')   \n",
       "7                               TfidfTransformer()   \n",
       "4              TfidfTransformer(sublinear_tf=True)   \n",
       "3   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "19             TfidfTransformer(sublinear_tf=True)   \n",
       "6   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "14                              TfidfTransformer()   \n",
       "8                               TfidfTransformer()   \n",
       "12  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "13  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "5   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "1   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "17                              TfidfTransformer()   \n",
       "18                              TfidfTransformer()   \n",
       "0   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "\n",
       "   param_preprocessor__numerical__scaler  \\\n",
       "11                          Normalizer()   \n",
       "2                       StandardScaler()   \n",
       "9                           Normalizer()   \n",
       "10                        MinMaxScaler()   \n",
       "15                        RobustScaler()   \n",
       "16                      StandardScaler()   \n",
       "7                           Normalizer()   \n",
       "4                           Normalizer()   \n",
       "3                         RobustScaler()   \n",
       "19                      StandardScaler()   \n",
       "6                       StandardScaler()   \n",
       "14                        MinMaxScaler()   \n",
       "8                         MinMaxScaler()   \n",
       "12                      StandardScaler()   \n",
       "13                        MinMaxScaler()   \n",
       "5                           Normalizer()   \n",
       "1                         RobustScaler()   \n",
       "17                        RobustScaler()   \n",
       "18                        RobustScaler()   \n",
       "0                         RobustScaler()   \n",
       "\n",
       "     param_preprocessor__numerical__imputer  \\\n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "2                              KNNImputer()   \n",
       "9                              KNNImputer()   \n",
       "10                          SimpleImputer()   \n",
       "15         SimpleImputer(strategy='median')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "7                              KNNImputer()   \n",
       "4                           SimpleImputer()   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "19                             KNNImputer()   \n",
       "6                              KNNImputer()   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "8                           SimpleImputer()   \n",
       "12  SimpleImputer(strategy='most_frequent')   \n",
       "13  SimpleImputer(strategy='most_frequent')   \n",
       "5                           SimpleImputer()   \n",
       "1   SimpleImputer(strategy='most_frequent')   \n",
       "17         SimpleImputer(strategy='median')   \n",
       "18  SimpleImputer(strategy='most_frequent')   \n",
       "0                              KNNImputer()   \n",
       "\n",
       "                     param_feature_selector  mean_test_Accuracy  \\\n",
       "11  SelectFromModel(estimator=ElasticNet())            0.941918   \n",
       "2        SelectFromModel(estimator=Ridge())            0.925183   \n",
       "9        SelectFromModel(estimator=Ridge())            0.917884   \n",
       "10       SelectFromModel(estimator=Ridge())            0.844012   \n",
       "15  SelectFromModel(estimator=ElasticNet())            0.823361   \n",
       "16                      VarianceThreshold()            0.788396   \n",
       "7        SelectFromModel(estimator=Ridge())            0.773101   \n",
       "4   SelectFromModel(estimator=ElasticNet())            0.648556   \n",
       "3   SelectFromModel(estimator=ElasticNet())            0.644742   \n",
       "19       SelectFromModel(estimator=Ridge())            0.626457   \n",
       "6   SelectFromModel(estimator=ElasticNet())            0.411314   \n",
       "14  SelectFromModel(estimator=ElasticNet())            0.289520   \n",
       "8   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "12       SelectFromModel(estimator=Ridge())                 NaN   \n",
       "13  SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "5                       VarianceThreshold()                 NaN   \n",
       "1   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "17  SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "18                      VarianceThreshold()                 NaN   \n",
       "0        SelectFromModel(estimator=Ridge())                 NaN   \n",
       "\n",
       "    mean_test_Weighted_F1  \n",
       "11               0.940833  \n",
       "2                0.923098  \n",
       "9                0.916030  \n",
       "10               0.836846  \n",
       "15               0.817507  \n",
       "16               0.778054  \n",
       "7                0.767372  \n",
       "4                0.638124  \n",
       "3                0.619848  \n",
       "19               0.614325  \n",
       "6                0.369324  \n",
       "14               0.289992  \n",
       "8                     NaN  \n",
       "12                    NaN  \n",
       "13                    NaN  \n",
       "5                     NaN  \n",
       "1                     NaN  \n",
       "17                    NaN  \n",
       "18                    NaN  \n",
       "0                     NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"])[[\n",
    "    'rank_test_Weighted_F1',\n",
    "    'rank_test_Accuracy',\n",
    "    'mean_fit_time',\n",
    "    'param_estimator',\n",
    "    'param_preprocessor__text__vectorizer',\n",
    "    'param_preprocessor__text__tfidf',\n",
    "    'param_preprocessor__numerical__scaler',\n",
    "    'param_preprocessor__numerical__imputer', 'param_feature_selector',\n",
    "    'mean_test_Accuracy',\n",
    "    'mean_test_Weighted_F1'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model using a sample-weighting mechanism to try to compensate for the dataset imbalance\n",
    "if retrain_with_class_weight:\n",
    "    sample_weights = compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_train,\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train, y_train, estimator__sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>macro_f1_score</th>\n",
       "      <th>weighted_f1_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>confusion_matrix_normalized</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.97693</td>\n",
       "      <td>0.803626</td>\n",
       "      <td>0.820253</td>\n",
       "      <td>0.803626</td>\n",
       "      <td>0.786483</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>[[620, 3, 7, 1, 98, 51, 0, 2, 0], [0, 74, 0, 0...</td>\n",
       "      <td>[[0.005528901888744226, 2.6752751074568835e-05...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROC_AUC  accuracy balanced_accuracy micro_f1_score macro_f1_score  \\\n",
       "0  0.97693  0.803626          0.820253       0.803626       0.786483   \n",
       "\n",
       "  weighted_f1_score                                   confusion_matrix  \\\n",
       "0          0.804762  [[620, 3, 7, 1, 98, 51, 0, 2, 0], [0, 74, 0, 0...   \n",
       "\n",
       "                         confusion_matrix_normalized  \\\n",
       "0  [[0.005528901888744226, 2.6752751074568835e-05...   \n",
       "\n",
       "                               classification_report  \n",
       "0                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pipeline.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_decoded = label_encoder.inverse_transform(best_model['estimator'].classes_)\n",
    "\n",
    "with sns.axes_style(\"dark\"):\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=score.loc[0,'confusion_matrix'],\n",
    "                                display_labels=labels_decoded)\n",
    "    disp.plot(ax=ax, cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A510</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A511</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A514</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A529</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A530</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>48469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A539</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>37927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E109</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>5022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E119</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E149</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>112138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>112138.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score   support\n",
       "A510               0.82    0.79      0.80     782.0\n",
       "A511               0.95    0.99      0.97      75.0\n",
       "A514               0.49    0.78      0.60    2091.0\n",
       "A529               0.68    0.77      0.72    1576.0\n",
       "A530               0.83    0.82      0.83   48469.0\n",
       "A539               0.83    0.77      0.79   37927.0\n",
       "E109               0.74    0.83      0.78    5022.0\n",
       "E119               0.79    0.85      0.82   13950.0\n",
       "E149               0.74    0.79      0.76    2246.0\n",
       "accuracy           0.80    0.80      0.80       0.8\n",
       "macro avg          0.76    0.82      0.79  112138.0\n",
       "weighted avg       0.81    0.80      0.80  112138.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.loc[0,'classification_report'].round(2).rename(index={str(class_label):label for class_label, label in zip(best_model['estimator'].classes_, labels_decoded)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['categorical__Genero_Hombre', 'categorical__Genero_Mujer',\n",
       "       'categorical__GrupoEtnico_Blanco', ...,\n",
       "       'text__zumbidos oidos prevenir', 'text__zumos frutas',\n",
       "       'text__zumos frutas platanos'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.named_steps['feature_selector'].get_feature_names_out(best_model.named_steps['preprocessor'].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :['A530'], real: ['A539']\n"
     ]
    }
   ],
   "source": [
    "# Model test\n",
    "print(f'Predicted :{label_encoder.inverse_transform(best_model.predict(X_test.iloc[905].to_frame().T))}, real: {label_encoder.inverse_transform([y_test[905]])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/output/best_model_score.pickle']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dump(best_model, str(save_path))\n",
    "dump(score, str(save_path.parent / f'best_model_score{save_path.suffix}'))\n",
    "\n",
    "# class model_predictor():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the full prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PredictionPipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/app/scripts/train_ml.ipynb Cell 45'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f647334612d70726f6a6563742d6370752d31222c22637764223a22653a5c5c6465765c5c445334412d50726f6a656374227d/app/scripts/train_ml.ipynb#ch0000044vscode-remote?line=0'>1</a>\u001b[0m prediction_pipeline \u001b[39m=\u001b[39m PredictionPipeline(estimator\u001b[39m=\u001b[39mbest_model, preprocessing_fn\u001b[39m=\u001b[39mclean_and_preprocess_datasets, label_encoder\u001b[39m=\u001b[39mlabel_encoder)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PredictionPipeline' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_pipeline = PredictionPipeline(estimator=best_model, preprocessing_fn=clean_and_preprocess_datasets, label_encoder=label_encoder)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
