{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2022-06-25 06:17:11.098847: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-25 06:17:11.098923: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from IPython.display import display\n",
    "from joblib import dump\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
    "                             f1_score, make_scorer, roc_auc_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from ml_model import PipelineManager, PredictionPipeline\n",
    "from utils.GPU_models import KerasClassifierModel, gpu_model_hub\n",
    "from utils.preprocessing_utils import (clean_and_preprocess_datasets,\n",
    "                                       clean_labs, clean_notas,\n",
    "                                       clean_sociodemograficos, merge_classes,\n",
    "                                       merge_labs_notas,\n",
    "                                       word_count_feat_engineering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"diagram\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "as_dual_class=False\n",
    "target_feature = 'Código'\n",
    "text_feature = 'Plan'\n",
    "retrain_with_class_weight=False\n",
    "add_gpu_prediction = False\n",
    "consolidate_classes = False\n",
    "cv = 3\n",
    "n_iter = 20\n",
    "n_jobs = -2\n",
    "\n",
    "# False, 'oversample', or 'undersample'\n",
    "balance_classes = 'oversample'\n",
    "save_path = Path('data') / 'output' / 'best_model.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas = pd.read_csv('data/notas.csv', sep=';')\n",
    "df_laboratorios = pd.read_csv('data/laboratorios.csv', sep=';')\n",
    "df_sociodemografico = pd.read_csv('data/sociodemografico.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44600</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45038</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40391</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>usuaria la cual se ve pertinente seguimiento d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106350</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105840</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>EDUCACIÓN  Se brinda retroalimentación con rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IDRecord Código                                             Nombre  \\\n",
       "0    44600   A539                           SIFILIS, NO ESPECIFICADA   \n",
       "1    45038   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "2    40391   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "3   106350   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "4   105840   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "\n",
       "                  Tipo                                               Plan  \n",
       "0  Confirmado Repetido  - ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...  \n",
       "1  Confirmado Repetido  - TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...  \n",
       "2  Confirmado Repetido  usuaria la cual se ve pertinente seguimiento d...  \n",
       "3  Confirmado Repetido  1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...  \n",
       "4  Confirmado Repetido  EDUCACIÓN  Se brinda retroalimentación con rel...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Codigo</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95627</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>22/02/2022 18:43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125572</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>17/02/2022 13:41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55788</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>22/06/2021 12:50</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113766</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>5/08/2021 12:11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44596</td>\n",
       "      <td>902045</td>\n",
       "      <td>TIEMPO DE PROTROMBINA (PT)</td>\n",
       "      <td>5/08/2021 13:15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Codigo                      Nombre             Fecha Valor\n",
       "0     95627  902045  TIEMPO DE PROTROMBINA (PT)  22/02/2022 18:43   NaN\n",
       "1    125572  902045  TIEMPO DE PROTROMBINA (PT)  17/02/2022 13:41   NaN\n",
       "2     55788  902045  TIEMPO DE PROTROMBINA (PT)  22/06/2021 12:50  1.05\n",
       "3    113766  902045  TIEMPO DE PROTROMBINA (PT)   5/08/2021 12:11   NaN\n",
       "4     44596  902045  TIEMPO DE PROTROMBINA (PT)   5/08/2021 13:15   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_laboratorios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>No reportado</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325</td>\n",
       "      <td>94</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Rural</td>\n",
       "      <td>Viudo/a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0         5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1       292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3       307    88  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "4       325    94  Hombre  Ninguno de los anteriores      Zona Rural   \n",
       "\n",
       "    EstadoCivil TSangre  \n",
       "0      Separado     NaN  \n",
       "1        Casado     NaN  \n",
       "2       Soltero      O+  \n",
       "3  No reportado     NaN  \n",
       "4       Viudo/a     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sociodemografico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44600</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45038</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>- TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40391</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>usuaria la cual se ve pertinente seguimiento d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106350</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105840</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>EDUCACIÓN  Se brinda retroalimentación con rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IDRecord Código                                             Nombre  \\\n",
       "0    44600   A539                           SIFILIS, NO ESPECIFICADA   \n",
       "1    45038   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "2    40391   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "3   106350   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "4   105840   A530  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "\n",
       "                  Tipo                                               Plan  \n",
       "0  Confirmado Repetido  - ORDENO TAR ABC +3TC +ATV/r  - PROFILAXIS NO ...  \n",
       "1  Confirmado Repetido  - TAF/FTC/EVG/C MIPRES POR 2 MESES 20200602158...  \n",
       "2  Confirmado Repetido  usuaria la cual se ve pertinente seguimiento d...  \n",
       "3  Confirmado Repetido  1. Se formula TAR (TDF/FTC+EFV)  2. S/S Paracl...  \n",
       "4  Confirmado Repetido  EDUCACIÓN  Se brinda retroalimentación con rel...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sociodemografico = clean_sociodemograficos(df_sociodemografico)\n",
    "df_laboratorios = clean_labs(df_laboratorios)\n",
    "df_notas = clean_notas(df_notas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the sociodemographic data with the medical notes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA PROGRAMA CRONICOS.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Nuevo</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140167</th>\n",
       "      <td>205218</td>\n",
       "      <td>28</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A539</td>\n",
       "      <td>SIFILIS, NO ESPECIFICADA</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>explica acerca programa, recomienda adherencia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140168</th>\n",
       "      <td>205227</td>\n",
       "      <td>24</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>A530</td>\n",
       "      <td>SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>Elaboracion duelo frente diagnostico.   Reforz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140169</th>\n",
       "      <td>205253</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>FUROATO MOMETASONA 1 SPRY NASAL CADA FOSA NASA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140170</th>\n",
       "      <td>205577</td>\n",
       "      <td>62</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Impresión Diagnóstica</td>\n",
       "      <td>CONTROL MEICO MES-INFECTOLOGIA  VALORACIOJN IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140171</th>\n",
       "      <td>206307</td>\n",
       "      <td>57</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E149</td>\n",
       "      <td>DIABETES MELLITUS, NO ESPECIFICADA SIN MENCION...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA SEGUIMIENTO PROGRAMA NEFROPROTECCION ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140172 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0              5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1            292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "4            300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "...          ...   ...     ...                        ...             ...   \n",
       "140167    205218    28  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "140168    205227    24  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "140169    205253    84  Hombre                    Mestizo     Zona Urbana   \n",
       "140170    205577    62  Hombre                    Mestizo     Zona Urbana   \n",
       "140171    206307    57  Hombre                    Mestizo     Zona Urbana   \n",
       "\n",
       "        EstadoCivil TSangre Código  \\\n",
       "0          Separado     NaN   E109   \n",
       "1            Casado     NaN   E119   \n",
       "2           Soltero      O+   E119   \n",
       "3           Soltero      O+   E109   \n",
       "4           Soltero      O+   E119   \n",
       "...             ...     ...    ...   \n",
       "140167          NaN     NaN   A539   \n",
       "140168      Soltero      O+   A530   \n",
       "140169       Casado     NaN   E109   \n",
       "140170  Desconocido     NaN   E119   \n",
       "140171  Desconocido     NaN   E149   \n",
       "\n",
       "                                                   Nombre  \\\n",
       "0       DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "1       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "2       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "3       DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "4       DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "...                                                   ...   \n",
       "140167                           SIFILIS, NO ESPECIFICADA   \n",
       "140168  SIFILIS LATENTE, NO ESPECIFICADA COMO PRECOZ O...   \n",
       "140169  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...   \n",
       "140170  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...   \n",
       "140171  DIABETES MELLITUS, NO ESPECIFICADA SIN MENCION...   \n",
       "\n",
       "                         Tipo  \\\n",
       "0         Confirmado Repetido   \n",
       "1         Confirmado Repetido   \n",
       "2         Confirmado Repetido   \n",
       "3         Confirmado Repetido   \n",
       "4            Confirmado Nuevo   \n",
       "...                       ...   \n",
       "140167    Confirmado Repetido   \n",
       "140168    Confirmado Repetido   \n",
       "140169    Confirmado Repetido   \n",
       "140170  Impresión Diagnóstica   \n",
       "140171    Confirmado Repetido   \n",
       "\n",
       "                                                     Plan  \n",
       "0       PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...  \n",
       "1                            CONTINUA PROGRAMA CRONICOS.   \n",
       "2       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "3       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "4       1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...  \n",
       "...                                                   ...  \n",
       "140167  explica acerca programa, recomienda adherencia...  \n",
       "140168  Elaboracion duelo frente diagnostico.   Reforz...  \n",
       "140169  FUROATO MOMETASONA 1 SPRY NASAL CADA FOSA NASA...  \n",
       "140170  CONTROL MEICO MES-INFECTOLOGIA  VALORACIOJN IN...  \n",
       "140171  CONTINUA SEGUIMIENTO PROGRAMA NEFROPROTECCION ...  \n",
       "\n",
       "[140172 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = df_sociodemografico.merge(df_notas, how='inner', on='IDRecord')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRecord</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>GrupoEtnico</th>\n",
       "      <th>AreaResidencial</th>\n",
       "      <th>EstadoCivil</th>\n",
       "      <th>TSangre</th>\n",
       "      <th>Código</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Plan</th>\n",
       "      <th>acido</th>\n",
       "      <th>antibio</th>\n",
       "      <th>asintoma</th>\n",
       "      <th>cabeza</th>\n",
       "      <th>diabet</th>\n",
       "      <th>diet</th>\n",
       "      <th>gluco</th>\n",
       "      <th>hepat</th>\n",
       "      <th>insulin</th>\n",
       "      <th>keto</th>\n",
       "      <th>penici</th>\n",
       "      <th>preservativo</th>\n",
       "      <th>rpr</th>\n",
       "      <th>sable</th>\n",
       "      <th>serolo</th>\n",
       "      <th>sifili</th>\n",
       "      <th>test_reloj_orden</th>\n",
       "      <th>vih</th>\n",
       "      <th>top_lab_name</th>\n",
       "      <th>top_lab_avg_value</th>\n",
       "      <th>top_lab_max_value</th>\n",
       "      <th>top_lab_count</th>\n",
       "      <th>total_lab_count</th>\n",
       "      <th>date_diff_mean</th>\n",
       "      <th>date_diff_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Separado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CALCIO POR COLORIMETRÍA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292</td>\n",
       "      <td>84</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Ninguno de los anteriores</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Casado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>CONTINUA PROGRAMA CRONICOS.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E109</td>\n",
       "      <td>DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...</td>\n",
       "      <td>Confirmado Repetido</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>88</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>Mestizo</td>\n",
       "      <td>Zona Urbana</td>\n",
       "      <td>Soltero</td>\n",
       "      <td>O+</td>\n",
       "      <td>E119</td>\n",
       "      <td>DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...</td>\n",
       "      <td>Confirmado Nuevo</td>\n",
       "      <td>1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRecord  Edad  Genero                GrupoEtnico AreaResidencial  \\\n",
       "0         5    39   Mujer                    Mestizo     Zona Urbana   \n",
       "1       292    84  Hombre  Ninguno de los anteriores     Zona Urbana   \n",
       "2       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "3       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "4       300    88  Hombre                    Mestizo     Zona Urbana   \n",
       "\n",
       "  EstadoCivil TSangre Código  \\\n",
       "0    Separado     NaN   E109   \n",
       "1      Casado     NaN   E119   \n",
       "2     Soltero      O+   E119   \n",
       "3     Soltero      O+   E109   \n",
       "4     Soltero      O+   E119   \n",
       "\n",
       "                                              Nombre                 Tipo  \\\n",
       "0  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...  Confirmado Repetido   \n",
       "1  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...  Confirmado Repetido   \n",
       "2  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...  Confirmado Repetido   \n",
       "3  DIABETES MELLITUSINSULINODEPENDIENTE SIN MENCI...  Confirmado Repetido   \n",
       "4  DIABETES MELLITUS NOINSULINODEPENDIENTE SIN ME...     Confirmado Nuevo   \n",
       "\n",
       "                                                Plan  acido  antibio  \\\n",
       "0  PACIENTE CONTINUA PROGRAMA NEFROPROTECCION   S...      0        0   \n",
       "1                       CONTINUA PROGRAMA CRONICOS.       0        0   \n",
       "2  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "3  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "4  1- CONTINUAR PAD 2 - RECOMENDACIONES DIETA HIP...      0        0   \n",
       "\n",
       "   asintoma  cabeza  diabet  diet  gluco  hepat  insulin  keto  penici  \\\n",
       "0         0       0       0     0      0      0        0     0       0   \n",
       "1         0       0       0     0      0      0        0     0       0   \n",
       "2         0       0       0     1      0      0        0     0       0   \n",
       "3         0       0       0     1      0      0        0     0       0   \n",
       "4         0       0       0     1      0      0        0     0       0   \n",
       "\n",
       "   preservativo  rpr  sable  serolo  sifili  test_reloj_orden  vih  \\\n",
       "0             0    0      0       0       0                 0    0   \n",
       "1             0    0      0       0       0                 0    0   \n",
       "2             0    0      0       0       0                 0    0   \n",
       "3             0    0      0       0       0                 0    0   \n",
       "4             0    0      0       0       0                 0    0   \n",
       "\n",
       "               top_lab_name  top_lab_avg_value  top_lab_max_value  \\\n",
       "0  CALCIO POR COLORIMETRÍA                 8.0                8.0   \n",
       "1                       NaN                NaN                NaN   \n",
       "2                       NaN                NaN                NaN   \n",
       "3                       NaN                NaN                NaN   \n",
       "4                       NaN                NaN                NaN   \n",
       "\n",
       "   top_lab_count  total_lab_count  date_diff_mean  date_diff_max  \n",
       "0            1.0              8.0             0.0            0.0  \n",
       "1            NaN              NaN             NaN            NaN  \n",
       "2            NaN              NaN             NaN            NaN  \n",
       "3            NaN              NaN             NaN            NaN  \n",
       "4            NaN              NaN             NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Consolidate the classes\n",
    "if consolidate_classes:\n",
    "    df_merge = merge_classes(df_merge)\n",
    "\n",
    "# Perform word count feature engineering\n",
    "df_merge = word_count_feat_engineering(df_merge)\n",
    "\n",
    "# Preprocess the lab data and merge it with the sociodemographic data\n",
    "df_merge = merge_labs_notas(df_laboratorios, df_merge)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_merge.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([  977,    94,  2614,  1970, 60586, 47408,  6278, 17437,  2808]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_merge.drop(labels=[target_feature], axis=1)\n",
    "y = df_merge[target_feature]\n",
    "if as_dual_class:\n",
    "    y = y.str[:2]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform(y)\n",
    "\n",
    "np.unique(y_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([  195,    19,   523,   394, 12117,  9481,  1256,  3487,   562]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labels, train_size=0.2, random_state=42, stratify=y_labels)\n",
    "np.unique(y_train, return_counts=True) # Let's check the number of samples per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([19, 19, 19, 19, 19, 19, 19, 19, 19]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if balance_classes == 'oversample':\n",
    "    # Using a naive oversampling approach\n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "elif balance_classes == 'undersample':\n",
    "    # Using a naive oversampling approach\n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "np.unique(y_train, return_counts=True) # Let's check the number of samples per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = \"nnlm-es-dim128\"\n",
    "embedding = \"nnlm-es-dim128-with-normalization\"\n",
    "# embedding = \"universal\"\n",
    "\n",
    "if add_gpu_prediction:\n",
    "    model_function = gpu_model_hub\n",
    "    clf = KerasClassifierModel(\n",
    "        build_fn=model_function,\n",
    "        class_number=len(df_notas[target_feature].unique()),\n",
    "        embedding = embedding,\n",
    "        epochs=400,\n",
    "        batch_size=400,\n",
    "        verbose=10,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train[text_feature], y_train)\n",
    "    clf.plot_learning_curves('data/output/gpu_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gpu_prediction:\n",
    "    y_pred = clf.predict(X_test[text_feature])\n",
    "    display(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gpu_prediction:\n",
    "    X_pred = clf.predict(df_merge[text_feature])\n",
    "    df_merge['GPU_prediction'] = X_pred\n",
    "    df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the numerical features that will be used in the model\n",
    "numerical_features = list(\n",
    "    set(\n",
    "        [\n",
    "            \"Edad\",\n",
    "            \"top_lab_avg_value\",\n",
    "            \"top_lab_max_value\",\n",
    "            \"top_lab_count\",\n",
    "            \"total_lab_count\",\n",
    "            \"date_diff_mean\",\n",
    "            \"date_diff_max\",\n",
    "        ]\n",
    "        + list(df_merge.drop(columns=\"IDRecord\").select_dtypes(include=\"int64\").columns)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Now define the categorical features\n",
    "categorical_features = [\n",
    "    \"Genero\",\n",
    "    \"GrupoEtnico\",\n",
    "    \"AreaResidencial\",\n",
    "    \"EstadoCivil\",\n",
    "    \"TSangre\",\n",
    "    \"Tipo\",\n",
    "    \"top_lab_name\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                                               &#x27;la&#x27;,\n",
       "                                                                                               &#x27;que&#x27;,\n",
       "                                                                                               &#x27;el&#x27;,\n",
       "                                                                                               &#x27;en&#x27;,\n",
       "                                                                                               &#x27;y&#x27;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;los&#x27;,\n",
       "                                                                                               &#x27;del&#x27;,\n",
       "                                                                                               &#x27;se&#x27;,\n",
       "                                                                                               &#x27;las&#x27;,\n",
       "                                                                                               &#x27;por&#x27;,\n",
       "                                                                                               &#x27;un&#x27;,\n",
       "                                                                                               &#x27;para&#x27;,\n",
       "                                                                                               &#x27;con&#x27;,\n",
       "                                                                                               &#x27;no&#x27;,\n",
       "                                                                                               &#x27;una&#x27;,\n",
       "                                                                                               &#x27;su&#x27;,\n",
       "                                                                                               &#x27;al&#x27;,\n",
       "                                                                                               &#x27;lo&#x27;,\n",
       "                                                                                               &#x27;como&#x27;,\n",
       "                                                                                               &#x27;más&#x27;,\n",
       "                                                                                               &#x27;pero&#x27;,\n",
       "                                                                                               &#x27;sus&#x27;,\n",
       "                                                                                               &#x27;le&#x27;,\n",
       "                                                                                               &#x27;ya&#x27;,\n",
       "                                                                                               &#x27;o&#x27;,\n",
       "                                                                                               &#x27;este&#x27;,\n",
       "                                                                                               &#x27;sí&#x27;,\n",
       "                                                                                               &#x27;porque&#x27;, ...],\n",
       "                                                                                   strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                                  (&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  &#x27;Plan&#x27;)])),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                (&#x27;estimator&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                                               &#x27;la&#x27;,\n",
       "                                                                                               &#x27;que&#x27;,\n",
       "                                                                                               &#x27;el&#x27;,\n",
       "                                                                                               &#x27;en&#x27;,\n",
       "                                                                                               &#x27;y&#x27;,\n",
       "                                                                                               &#x27;a&#x27;,\n",
       "                                                                                               &#x27;los&#x27;,\n",
       "                                                                                               &#x27;del&#x27;,\n",
       "                                                                                               &#x27;se&#x27;,\n",
       "                                                                                               &#x27;las&#x27;,\n",
       "                                                                                               &#x27;por&#x27;,\n",
       "                                                                                               &#x27;un&#x27;,\n",
       "                                                                                               &#x27;para&#x27;,\n",
       "                                                                                               &#x27;con&#x27;,\n",
       "                                                                                               &#x27;no&#x27;,\n",
       "                                                                                               &#x27;una&#x27;,\n",
       "                                                                                               &#x27;su&#x27;,\n",
       "                                                                                               &#x27;al&#x27;,\n",
       "                                                                                               &#x27;lo&#x27;,\n",
       "                                                                                               &#x27;como&#x27;,\n",
       "                                                                                               &#x27;más&#x27;,\n",
       "                                                                                               &#x27;pero&#x27;,\n",
       "                                                                                               &#x27;sus&#x27;,\n",
       "                                                                                               &#x27;le&#x27;,\n",
       "                                                                                               &#x27;ya&#x27;,\n",
       "                                                                                               &#x27;o&#x27;,\n",
       "                                                                                               &#x27;este&#x27;,\n",
       "                                                                                               &#x27;sí&#x27;,\n",
       "                                                                                               &#x27;porque&#x27;, ...],\n",
       "                                                                                   strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                                  (&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  &#x27;Plan&#x27;)])),\n",
       "                (&#x27;feature_selector&#x27;,\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                (&#x27;estimator&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;,\n",
       "                                  &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;,\n",
       "                                  &#x27;top_lab_name&#x27;]),\n",
       "                                (&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardS...\n",
       "                                  &#x27;top_lab_avg_value&#x27;, &#x27;total_lab_count&#x27;,\n",
       "                                  &#x27;insulin&#x27;]),\n",
       "                                (&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  CountVectorizer(stop_words=[&#x27;de&#x27;,\n",
       "                                                                              &#x27;la&#x27;,\n",
       "                                                                              &#x27;que&#x27;,\n",
       "                                                                              &#x27;el&#x27;,\n",
       "                                                                              &#x27;en&#x27;,\n",
       "                                                                              &#x27;y&#x27;,\n",
       "                                                                              &#x27;a&#x27;,\n",
       "                                                                              &#x27;los&#x27;,\n",
       "                                                                              &#x27;del&#x27;,\n",
       "                                                                              &#x27;se&#x27;,\n",
       "                                                                              &#x27;las&#x27;,\n",
       "                                                                              &#x27;por&#x27;,\n",
       "                                                                              &#x27;un&#x27;,\n",
       "                                                                              &#x27;para&#x27;,\n",
       "                                                                              &#x27;con&#x27;,\n",
       "                                                                              &#x27;no&#x27;,\n",
       "                                                                              &#x27;una&#x27;,\n",
       "                                                                              &#x27;su&#x27;,\n",
       "                                                                              &#x27;al&#x27;,\n",
       "                                                                              &#x27;lo&#x27;,\n",
       "                                                                              &#x27;como&#x27;,\n",
       "                                                                              &#x27;más&#x27;,\n",
       "                                                                              &#x27;pero&#x27;,\n",
       "                                                                              &#x27;sus&#x27;,\n",
       "                                                                              &#x27;le&#x27;,\n",
       "                                                                              &#x27;ya&#x27;,\n",
       "                                                                              &#x27;o&#x27;,\n",
       "                                                                              &#x27;este&#x27;,\n",
       "                                                                              &#x27;sí&#x27;,\n",
       "                                                                              &#x27;porque&#x27;, ...],\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  TfidfTransformer())]),\n",
       "                                 &#x27;Plan&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;, &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;vih&#x27;, &#x27;acido&#x27;, &#x27;gluco&#x27;, &#x27;test_reloj_orden&#x27;, &#x27;cabeza&#x27;, &#x27;date_diff_mean&#x27;, &#x27;penici&#x27;, &#x27;diet&#x27;, &#x27;rpr&#x27;, &#x27;diabet&#x27;, &#x27;Edad&#x27;, &#x27;date_diff_max&#x27;, &#x27;keto&#x27;, &#x27;hepat&#x27;, &#x27;top_lab_count&#x27;, &#x27;sifili&#x27;, &#x27;asintoma&#x27;, &#x27;antibio&#x27;, &#x27;sable&#x27;, &#x27;top_lab_max_value&#x27;, &#x27;serolo&#x27;, &#x27;preservativo&#x27;, &#x27;top_lab_avg_value&#x27;, &#x27;total_lab_count&#x27;, &#x27;insulin&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>Plan</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;que&#x27;, &#x27;el&#x27;, &#x27;en&#x27;, &#x27;y&#x27;, &#x27;a&#x27;, &#x27;los&#x27;,\n",
       "                            &#x27;del&#x27;, &#x27;se&#x27;, &#x27;las&#x27;, &#x27;por&#x27;, &#x27;un&#x27;, &#x27;para&#x27;, &#x27;con&#x27;,\n",
       "                            &#x27;no&#x27;, &#x27;una&#x27;, &#x27;su&#x27;, &#x27;al&#x27;, &#x27;lo&#x27;, &#x27;como&#x27;, &#x27;más&#x27;,\n",
       "                            &#x27;pero&#x27;, &#x27;sus&#x27;, &#x27;le&#x27;, &#x27;ya&#x27;, &#x27;o&#x27;, &#x27;este&#x27;, &#x27;sí&#x27;,\n",
       "                            &#x27;porque&#x27;, ...],\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_selector: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestRegressor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Genero', 'GrupoEtnico',\n",
       "                                                   'AreaResidencial',\n",
       "                                                   'EstadoCivil', 'TSangre',\n",
       "                                                   'Tipo', 'top_lab_name']),\n",
       "                                                 ('numerical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   Simp...\n",
       "                                                                   CountVectorizer(stop_words=['de',\n",
       "                                                                                               'la',\n",
       "                                                                                               'que',\n",
       "                                                                                               'el',\n",
       "                                                                                               'en',\n",
       "                                                                                               'y',\n",
       "                                                                                               'a',\n",
       "                                                                                               'los',\n",
       "                                                                                               'del',\n",
       "                                                                                               'se',\n",
       "                                                                                               'las',\n",
       "                                                                                               'por',\n",
       "                                                                                               'un',\n",
       "                                                                                               'para',\n",
       "                                                                                               'con',\n",
       "                                                                                               'no',\n",
       "                                                                                               'una',\n",
       "                                                                                               'su',\n",
       "                                                                                               'al',\n",
       "                                                                                               'lo',\n",
       "                                                                                               'como',\n",
       "                                                                                               'más',\n",
       "                                                                                               'pero',\n",
       "                                                                                               'sus',\n",
       "                                                                                               'le',\n",
       "                                                                                               'ya',\n",
       "                                                                                               'o',\n",
       "                                                                                               'este',\n",
       "                                                                                               'sí',\n",
       "                                                                                               'porque', ...],\n",
       "                                                                                   strip_accents='unicode')),\n",
       "                                                                  ('tfidf',\n",
       "                                                                   TfidfTransformer())]),\n",
       "                                                  'Plan')])),\n",
       "                ('feature_selector',\n",
       "                 SelectFromModel(estimator=RandomForestRegressor())),\n",
       "                ('estimator', RandomForestClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the GPU prediction if we are using a GPU model for predicting the data\n",
    "if 'GPU_prediction' in df_merge:\n",
    "    categorical_features.append('GPU_prediction')\n",
    "\n",
    "pipeline = PipelineManager(estimator=\"classifier\")\n",
    "pipeline.set_numerical_features(numerical_features)\n",
    "pipeline.set_categorical_features(categorical_features)\n",
    "pipeline.set_text_feature(text_feature)\n",
    "pipeline.set_basic_pipeline()\n",
    "\n",
    "# param_grid = {\n",
    "#     \"n_estimators\": np.linspace(1, 100, 10, dtype=int),\n",
    "#     \"max_depth\": list(np.linspace(1, 10, 5, dtype=int)) + [None],\n",
    "#     \"bootstrap\": [True, False],\n",
    "# }\n",
    "# estimator = RandomForestClassifier()\n",
    "# pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.linspace(1, 200, 10, dtype=int),\n",
    "    \"max_depth\": list(np.linspace(2, 10, 5, dtype=int)) + [None],\n",
    "    \"eta\": np.linspace(0.01, 0.5, 10, dtype=float),\n",
    "    \"min_child_weight\": np.linspace(0.5, 20, 5, dtype=float),\n",
    "    \"gamma\": np.linspace(0, 1, 5, dtype=float),\n",
    "    \"subsample\": np.linspace(0.1, 1, 5, dtype=float),\n",
    "    \"colsample_bytree\": np.linspace(0.2, 1, 5, dtype=float),\n",
    "    \"reg_lambda\": np.linspace(0, 12, 10, dtype=float),\n",
    "    \"reg_alpha\": np.linspace(0, 12, 10, dtype=float),\n",
    "    # \"scale_pos_weight\": np.linspace(0.1, 500, 100, dtype=float),\n",
    "}\n",
    "estimator = XGBClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "param_grid = {}\n",
    "estimator = PassiveAggressiveClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "estimator = SGDClassifier()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": np.linspace(0, 2, 10, dtype=float),\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"auto\", \"scale\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"coef0\": np.linspace(0, 2, 10, dtype=float),\n",
    "    \"degree\": np.linspace(1, 5, 5, dtype=int),\n",
    "}\n",
    "estimator = SVC()\n",
    "pipeline.add_estimator(estimator, param_grid)\n",
    "\n",
    "\n",
    "\n",
    "pipeline.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "24 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py\", line 673, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py\", line 604, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 414, in fit_transform\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 870, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/impute/_knn.py\", line 210, in fit\n",
      "    X = self._validate_data(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 577, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 856, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\", line 2064, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'Hombre'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.29012346 0.11111111 0.11111111        nan\n",
      " 0.31834215 0.31481481        nan 0.18606702 0.11111111 0.14285714\n",
      "        nan        nan 0.11111111 0.25396825 0.11111111        nan\n",
      "        nan 0.11111111]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.27094906 0.02232143 0.02232143        nan\n",
      " 0.27483449 0.29768741        nan 0.08580317 0.02232143 0.04112503\n",
      "        nan        nan 0.02232143 0.14682465 0.02232143        nan\n",
      "        nan 0.02232143]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample_weight = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=df_merge[target_feature])\n",
    "\n",
    "scoring = {\n",
    "    \"Accuracy\": \"balanced_accuracy\",\n",
    "    \"Weighted_F1\": make_scorer(f1_score, average='weighted'),\n",
    "    # 'roc_auc':make_scorer(roc_auc_score, average='weighted'),\n",
    "    }\n",
    "best_model = pipeline.find_best_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    n_iter=n_iter,\n",
    "    n_jobs=n_jobs,\n",
    "    scoring=scoring,\n",
    "    random_state=7,\n",
    "    refit='Weighted_F1',\n",
    "    verbose = 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;scal...\n",
       "                               eval_metric=None, gamma=0.25, gpu_id=-1,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.00999999978, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=6, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                               n_estimators=200, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;,\n",
       "                                                   &#x27;AreaResidencial&#x27;,\n",
       "                                                   &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;,\n",
       "                                                   &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]),\n",
       "                                                 (&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;scal...\n",
       "                               eval_metric=None, gamma=0.25, gpu_id=-1,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.00999999978, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=6, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                               n_estimators=200, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;,\n",
       "                                  &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;,\n",
       "                                  &#x27;top_lab_name&#x27;]),\n",
       "                                (&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, Normalizer())]),\n",
       "                                 [&#x27;vih&#x27;, &#x27;acid...\n",
       "                                  &#x27;top_lab_avg_value&#x27;, &#x27;total_lab_count&#x27;,\n",
       "                                  &#x27;insulin&#x27;]),\n",
       "                                (&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  CountVectorizer(ngram_range=(3,\n",
       "                                                                               3),\n",
       "                                                                  stop_words=[&#x27;de&#x27;,\n",
       "                                                                              &#x27;la&#x27;,\n",
       "                                                                              &#x27;que&#x27;,\n",
       "                                                                              &#x27;el&#x27;,\n",
       "                                                                              &#x27;en&#x27;,\n",
       "                                                                              &#x27;y&#x27;,\n",
       "                                                                              &#x27;a&#x27;,\n",
       "                                                                              &#x27;los&#x27;,\n",
       "                                                                              &#x27;del&#x27;,\n",
       "                                                                              &#x27;se&#x27;,\n",
       "                                                                              &#x27;las&#x27;,\n",
       "                                                                              &#x27;por&#x27;,\n",
       "                                                                              &#x27;un&#x27;,\n",
       "                                                                              &#x27;para&#x27;,\n",
       "                                                                              &#x27;con&#x27;,\n",
       "                                                                              &#x27;no&#x27;,\n",
       "                                                                              &#x27;una&#x27;,\n",
       "                                                                              &#x27;su&#x27;,\n",
       "                                                                              &#x27;al&#x27;,\n",
       "                                                                              &#x27;lo&#x27;,\n",
       "                                                                              &#x27;como&#x27;,\n",
       "                                                                              &#x27;más&#x27;,\n",
       "                                                                              &#x27;pero&#x27;,\n",
       "                                                                              &#x27;sus&#x27;,\n",
       "                                                                              &#x27;le&#x27;,\n",
       "                                                                              &#x27;ya&#x27;,\n",
       "                                                                              &#x27;o&#x27;,\n",
       "                                                                              &#x27;este&#x27;,\n",
       "                                                                              &#x27;sí&#x27;,\n",
       "                                                                              &#x27;porque&#x27;, ...],\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;)),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  TfidfTransformer())]),\n",
       "                                 &#x27;Plan&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Genero&#x27;, &#x27;GrupoEtnico&#x27;, &#x27;AreaResidencial&#x27;, &#x27;EstadoCivil&#x27;, &#x27;TSangre&#x27;, &#x27;Tipo&#x27;, &#x27;top_lab_name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;vih&#x27;, &#x27;acido&#x27;, &#x27;gluco&#x27;, &#x27;test_reloj_orden&#x27;, &#x27;cabeza&#x27;, &#x27;date_diff_mean&#x27;, &#x27;penici&#x27;, &#x27;diet&#x27;, &#x27;rpr&#x27;, &#x27;diabet&#x27;, &#x27;Edad&#x27;, &#x27;date_diff_max&#x27;, &#x27;keto&#x27;, &#x27;hepat&#x27;, &#x27;top_lab_count&#x27;, &#x27;sifili&#x27;, &#x27;asintoma&#x27;, &#x27;antibio&#x27;, &#x27;sable&#x27;, &#x27;top_lab_max_value&#x27;, &#x27;serolo&#x27;, &#x27;preservativo&#x27;, &#x27;top_lab_avg_value&#x27;, &#x27;total_lab_count&#x27;, &#x27;insulin&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Normalizer</label><div class=\"sk-toggleable__content\"><pre>Normalizer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>Plan</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(3, 3),\n",
       "                stop_words=[&#x27;de&#x27;, &#x27;la&#x27;, &#x27;que&#x27;, &#x27;el&#x27;, &#x27;en&#x27;, &#x27;y&#x27;, &#x27;a&#x27;, &#x27;los&#x27;,\n",
       "                            &#x27;del&#x27;, &#x27;se&#x27;, &#x27;las&#x27;, &#x27;por&#x27;, &#x27;un&#x27;, &#x27;para&#x27;, &#x27;con&#x27;,\n",
       "                            &#x27;no&#x27;, &#x27;una&#x27;, &#x27;su&#x27;, &#x27;al&#x27;, &#x27;lo&#x27;, &#x27;como&#x27;, &#x27;más&#x27;,\n",
       "                            &#x27;pero&#x27;, &#x27;sus&#x27;, &#x27;le&#x27;, &#x27;ya&#x27;, &#x27;o&#x27;, &#x27;este&#x27;, &#x27;sí&#x27;,\n",
       "                            &#x27;porque&#x27;, ...],\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_selector: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=Ridge())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False, eta=0.01,\n",
       "              eval_metric=None, gamma=0.25, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.00999999978, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=0.5,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=200,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Genero', 'GrupoEtnico',\n",
       "                                                   'AreaResidencial',\n",
       "                                                   'EstadoCivil', 'TSangre',\n",
       "                                                   'Tipo', 'top_lab_name']),\n",
       "                                                 ('numerical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('scal...\n",
       "                               eval_metric=None, gamma=0.25, gpu_id=-1,\n",
       "                               grow_policy='depthwise', importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.00999999978, max_bin=256,\n",
       "                               max_cat_to_onehot=4, max_delta_step=0,\n",
       "                               max_depth=6, max_leaves=0, min_child_weight=0.5,\n",
       "                               missing=nan, monotone_constraints='()',\n",
       "                               n_estimators=200, n_jobs=0, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, ...))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_preprocessor__text__vectorizer</th>\n",
       "      <th>param_preprocessor__text__tfidf</th>\n",
       "      <th>param_preprocessor__numerical__scaler</th>\n",
       "      <th>param_preprocessor__numerical__imputer</th>\n",
       "      <th>param_preprocessor__categorical__imputer</th>\n",
       "      <th>param_feature_selector</th>\n",
       "      <th>param_estimator__subsample</th>\n",
       "      <th>param_estimator__reg_lambda</th>\n",
       "      <th>param_estimator__reg_alpha</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "      <th>param_estimator__min_child_weight</th>\n",
       "      <th>param_estimator__max_depth</th>\n",
       "      <th>param_estimator__gamma</th>\n",
       "      <th>param_estimator__eta</th>\n",
       "      <th>param_estimator__colsample_bytree</th>\n",
       "      <th>param_estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>split1_test_Accuracy</th>\n",
       "      <th>split2_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>split0_test_Weighted_F1</th>\n",
       "      <th>split1_test_Weighted_F1</th>\n",
       "      <th>split2_test_Weighted_F1</th>\n",
       "      <th>mean_test_Weighted_F1</th>\n",
       "      <th>std_test_Weighted_F1</th>\n",
       "      <th>rank_test_Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.467427</td>\n",
       "      <td>0.061672</td>\n",
       "      <td>0.048651</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.325397</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.009899</td>\n",
       "      <td>2</td>\n",
       "      <td>0.287912</td>\n",
       "      <td>0.315538</td>\n",
       "      <td>0.289612</td>\n",
       "      <td>0.297687</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.792286</td>\n",
       "      <td>0.014043</td>\n",
       "      <td>0.045499</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>133</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.328042</td>\n",
       "      <td>0.318342</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278133</td>\n",
       "      <td>0.296567</td>\n",
       "      <td>0.249804</td>\n",
       "      <td>0.274834</td>\n",
       "      <td>0.019233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.616956</td>\n",
       "      <td>0.404827</td>\n",
       "      <td>0.048820</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.293651</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.041117</td>\n",
       "      <td>3</td>\n",
       "      <td>0.226892</td>\n",
       "      <td>0.247841</td>\n",
       "      <td>0.338115</td>\n",
       "      <td>0.270949</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.834035</td>\n",
       "      <td>0.027496</td>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>133</td>\n",
       "      <td>5.375</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.304233</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.041041</td>\n",
       "      <td>4</td>\n",
       "      <td>0.096380</td>\n",
       "      <td>0.208533</td>\n",
       "      <td>0.135561</td>\n",
       "      <td>0.146825</td>\n",
       "      <td>0.046474</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.619482</td>\n",
       "      <td>0.077292</td>\n",
       "      <td>0.042142</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.325</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>155</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.227778</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.186067</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059347</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.070243</td>\n",
       "      <td>0.085803</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.826409</td>\n",
       "      <td>0.462338</td>\n",
       "      <td>0.038613</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.044896</td>\n",
       "      <td>6</td>\n",
       "      <td>0.083275</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.041125</td>\n",
       "      <td>0.029804</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.327260</td>\n",
       "      <td>0.071091</td>\n",
       "      <td>0.029632</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>177</td>\n",
       "      <td>10.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.116242</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>0.034954</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>10.25</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.122244</td>\n",
       "      <td>0.081794</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>111</td>\n",
       "      <td>15.125</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.936100</td>\n",
       "      <td>0.025425</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>8.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.138804</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>45</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.392187</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.033727</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>CountVectorizer(ngram_range=(4, 4),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>45</td>\n",
       "      <td>15.125</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008128</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.325</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>200</td>\n",
       "      <td>10.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.775</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>177</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.4</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.775</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.445556</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.007428</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.775</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>111</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.009833</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>133</td>\n",
       "      <td>5.375</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>KNNImputer(n_neighbors=1)</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>23</td>\n",
       "      <td>5.375</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.8</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'preprocessor__text__vectorizer': CountVector...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7        2.467427      0.061672         0.048651        0.007329   \n",
       "6        0.792286      0.014043         0.045499        0.004542   \n",
       "2        5.616956      0.404827         0.048820        0.001319   \n",
       "15       0.834035      0.027496         0.035172        0.003062   \n",
       "9        1.619482      0.077292         0.042142        0.005875   \n",
       "11       0.826409      0.462338         0.038613        0.005127   \n",
       "16       1.327260      0.071091         0.029632        0.001626   \n",
       "14       0.116242      0.008909         0.034954        0.004489   \n",
       "10       1.122244      0.081794         0.041197        0.002859   \n",
       "19       0.936100      0.025425         0.030249        0.002282   \n",
       "4        0.396875      0.138804         0.032667        0.003748   \n",
       "3        0.392187      0.005388         0.033727        0.000443   \n",
       "8        0.009289      0.003092         0.000000        0.000000   \n",
       "5        0.008128      0.002713         0.000000        0.000000   \n",
       "12       0.007308      0.001220         0.000000        0.000000   \n",
       "13       0.005617      0.000642         0.000000        0.000000   \n",
       "1        0.009892      0.000426         0.000000        0.000000   \n",
       "17       0.007428      0.001777         0.000000        0.000000   \n",
       "18       0.009833      0.004825         0.000000        0.000000   \n",
       "0        0.010212      0.002313         0.000000        0.000000   \n",
       "\n",
       "                 param_preprocessor__text__vectorizer  \\\n",
       "7   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "6   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "2   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "15  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "9   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "11  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "16  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "14  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "10  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "19  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "4   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "3   CountVectorizer(ngram_range=(4, 4),\\n         ...   \n",
       "8   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "5   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "12  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "13  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "1   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "17  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "18  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "0   CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "\n",
       "                   param_preprocessor__text__tfidf  \\\n",
       "7                               TfidfTransformer()   \n",
       "6   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "2   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "15  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "9                      TfidfTransformer(norm='l1')   \n",
       "11                              TfidfTransformer()   \n",
       "16                     TfidfTransformer(norm='l1')   \n",
       "14                              TfidfTransformer()   \n",
       "10             TfidfTransformer(sublinear_tf=True)   \n",
       "19             TfidfTransformer(sublinear_tf=True)   \n",
       "4              TfidfTransformer(sublinear_tf=True)   \n",
       "3   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "8                               TfidfTransformer()   \n",
       "5   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "12  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "13  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "1   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "17                              TfidfTransformer()   \n",
       "18                              TfidfTransformer()   \n",
       "0   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "\n",
       "   param_preprocessor__numerical__scaler  \\\n",
       "7                           Normalizer()   \n",
       "6                       StandardScaler()   \n",
       "2                       StandardScaler()   \n",
       "15                        RobustScaler()   \n",
       "9                           Normalizer()   \n",
       "11                          Normalizer()   \n",
       "16                      StandardScaler()   \n",
       "14                        MinMaxScaler()   \n",
       "10                        MinMaxScaler()   \n",
       "19                      StandardScaler()   \n",
       "4                           Normalizer()   \n",
       "3                         RobustScaler()   \n",
       "8                         MinMaxScaler()   \n",
       "5                           Normalizer()   \n",
       "12                      StandardScaler()   \n",
       "13                        MinMaxScaler()   \n",
       "1                         RobustScaler()   \n",
       "17                        RobustScaler()   \n",
       "18                        RobustScaler()   \n",
       "0                         RobustScaler()   \n",
       "\n",
       "     param_preprocessor__numerical__imputer  \\\n",
       "7                              KNNImputer()   \n",
       "6                              KNNImputer()   \n",
       "2                              KNNImputer()   \n",
       "15         SimpleImputer(strategy='median')   \n",
       "9                              KNNImputer()   \n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "10                          SimpleImputer()   \n",
       "19                             KNNImputer()   \n",
       "4                           SimpleImputer()   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "8                           SimpleImputer()   \n",
       "5                           SimpleImputer()   \n",
       "12  SimpleImputer(strategy='most_frequent')   \n",
       "13  SimpleImputer(strategy='most_frequent')   \n",
       "1   SimpleImputer(strategy='most_frequent')   \n",
       "17         SimpleImputer(strategy='median')   \n",
       "18  SimpleImputer(strategy='most_frequent')   \n",
       "0                              KNNImputer()   \n",
       "\n",
       "   param_preprocessor__categorical__imputer  \\\n",
       "7   SimpleImputer(strategy='most_frequent')   \n",
       "6   SimpleImputer(strategy='most_frequent')   \n",
       "2   SimpleImputer(strategy='most_frequent')   \n",
       "15  SimpleImputer(strategy='most_frequent')   \n",
       "9   SimpleImputer(strategy='most_frequent')   \n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "10  SimpleImputer(strategy='most_frequent')   \n",
       "19  SimpleImputer(strategy='most_frequent')   \n",
       "4   SimpleImputer(strategy='most_frequent')   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "8                 KNNImputer(n_neighbors=1)   \n",
       "5                 KNNImputer(n_neighbors=1)   \n",
       "12                KNNImputer(n_neighbors=1)   \n",
       "13                KNNImputer(n_neighbors=1)   \n",
       "1                 KNNImputer(n_neighbors=1)   \n",
       "17                KNNImputer(n_neighbors=1)   \n",
       "18                KNNImputer(n_neighbors=1)   \n",
       "0                 KNNImputer(n_neighbors=1)   \n",
       "\n",
       "                     param_feature_selector param_estimator__subsample  \\\n",
       "7        SelectFromModel(estimator=Ridge())                       0.55   \n",
       "6   SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "2        SelectFromModel(estimator=Ridge())                        1.0   \n",
       "15  SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "9        SelectFromModel(estimator=Ridge())                      0.325   \n",
       "11  SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "16                      VarianceThreshold()                       0.55   \n",
       "14  SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "10       SelectFromModel(estimator=Ridge())                      0.325   \n",
       "19       SelectFromModel(estimator=Ridge())                        0.1   \n",
       "4   SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "3   SelectFromModel(estimator=ElasticNet())                       0.55   \n",
       "8   SelectFromModel(estimator=ElasticNet())                      0.325   \n",
       "5                       VarianceThreshold()                      0.325   \n",
       "12       SelectFromModel(estimator=Ridge())                      0.775   \n",
       "13  SelectFromModel(estimator=ElasticNet())                      0.775   \n",
       "1   SelectFromModel(estimator=ElasticNet())                        1.0   \n",
       "17  SelectFromModel(estimator=ElasticNet())                      0.775   \n",
       "18                      VarianceThreshold()                        1.0   \n",
       "0        SelectFromModel(estimator=Ridge())                        0.1   \n",
       "\n",
       "   param_estimator__reg_lambda param_estimator__reg_alpha  \\\n",
       "7                          4.0                        0.0   \n",
       "6                     9.333333                   1.333333   \n",
       "2                     9.333333                        0.0   \n",
       "15                    6.666667                   2.666667   \n",
       "9                         12.0                   1.333333   \n",
       "11                         4.0                   6.666667   \n",
       "16                   10.666667                       12.0   \n",
       "14                    5.333333                   5.333333   \n",
       "10                         4.0                   5.333333   \n",
       "19                    6.666667                        8.0   \n",
       "4                    10.666667                   5.333333   \n",
       "3                    10.666667                   5.333333   \n",
       "8                          4.0                        8.0   \n",
       "5                     1.333333                   5.333333   \n",
       "12                    6.666667                   9.333333   \n",
       "13                    5.333333                        0.0   \n",
       "1                     5.333333                        0.0   \n",
       "17                         4.0                   2.666667   \n",
       "18                   10.666667                   1.333333   \n",
       "0                          0.0                   5.333333   \n",
       "\n",
       "   param_estimator__n_estimators param_estimator__min_child_weight  \\\n",
       "7                            200                               0.5   \n",
       "6                            133                               0.5   \n",
       "2                            133                               0.5   \n",
       "15                           133                             5.375   \n",
       "9                            155                               0.5   \n",
       "11                            67                               0.5   \n",
       "16                           177                             10.25   \n",
       "14                             1                             10.25   \n",
       "10                           111                            15.125   \n",
       "19                           155                               0.5   \n",
       "4                             45                              20.0   \n",
       "3                             45                            15.125   \n",
       "8                             67                               0.5   \n",
       "5                            200                             10.25   \n",
       "12                           177                              20.0   \n",
       "13                           177                               0.5   \n",
       "1                             67                             5.375   \n",
       "17                           111                              20.0   \n",
       "18                           133                             5.375   \n",
       "0                             23                             5.375   \n",
       "\n",
       "   param_estimator__max_depth param_estimator__gamma param_estimator__eta  \\\n",
       "7                        None                   0.25                 0.01   \n",
       "6                           4                    0.0             0.336667   \n",
       "2                        None                    1.0                  0.5   \n",
       "15                          8                    0.5             0.064444   \n",
       "9                           6                    1.0             0.227778   \n",
       "11                          8                   0.25             0.336667   \n",
       "16                          8                    0.5                 0.01   \n",
       "14                          2                    1.0             0.064444   \n",
       "10                         10                    1.0             0.064444   \n",
       "19                          2                    1.0             0.391111   \n",
       "4                           2                   0.25             0.391111   \n",
       "3                        None                   0.25                 0.01   \n",
       "8                           2                    0.5             0.336667   \n",
       "5                           8                   0.75                 0.01   \n",
       "12                          2                   0.75             0.118889   \n",
       "13                         10                   0.25             0.336667   \n",
       "1                           6                    0.5             0.445556   \n",
       "17                          8                    0.0                 0.01   \n",
       "18                          2                   0.25             0.391111   \n",
       "0                           4                    0.5             0.118889   \n",
       "\n",
       "   param_estimator__colsample_bytree  \\\n",
       "7                                0.4   \n",
       "6                                0.4   \n",
       "2                                1.0   \n",
       "15                               0.8   \n",
       "9                                0.6   \n",
       "11                               0.6   \n",
       "16                               0.4   \n",
       "14                               0.2   \n",
       "10                               1.0   \n",
       "19                               0.4   \n",
       "4                                0.4   \n",
       "3                                0.8   \n",
       "8                                0.6   \n",
       "5                                0.8   \n",
       "12                               0.4   \n",
       "13                               1.0   \n",
       "1                                0.2   \n",
       "17                               0.6   \n",
       "18                               0.2   \n",
       "0                                0.8   \n",
       "\n",
       "                                      param_estimator  \\\n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "2   XGBClassifier(base_score=None, booster=None, c...   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "4   XGBClassifier(base_score=None, booster=None, c...   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "8   XGBClassifier(base_score=None, booster=None, c...   \n",
       "5   XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...   \n",
       "13  XGBClassifier(base_score=None, booster=None, c...   \n",
       "1   XGBClassifier(base_score=None, booster=None, c...   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...   \n",
       "18  XGBClassifier(base_score=None, booster=None, c...   \n",
       "0   XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                                               params  split0_test_Accuracy  \\\n",
       "7   {'preprocessor__text__vectorizer': CountVector...              0.301587   \n",
       "6   {'preprocessor__text__vectorizer': CountVector...              0.317460   \n",
       "2   {'preprocessor__text__vectorizer': CountVector...              0.293651   \n",
       "15  {'preprocessor__text__vectorizer': CountVector...              0.203704   \n",
       "9   {'preprocessor__text__vectorizer': CountVector...              0.166667   \n",
       "11  {'preprocessor__text__vectorizer': CountVector...              0.206349   \n",
       "16  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "14  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "10  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "19  {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "4   {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "3   {'preprocessor__text__vectorizer': CountVector...              0.111111   \n",
       "8   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "5   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "12  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "13  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "1   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "17  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "18  {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "0   {'preprocessor__text__vectorizer': CountVector...                   NaN   \n",
       "\n",
       "    split1_test_Accuracy  split2_test_Accuracy  mean_test_Accuracy  \\\n",
       "7               0.317460              0.325397            0.314815   \n",
       "6               0.309524              0.328042            0.318342   \n",
       "2               0.238095              0.338624            0.290123   \n",
       "15              0.304233              0.253968            0.253968   \n",
       "9               0.206349              0.185185            0.186067   \n",
       "11              0.111111              0.111111            0.142857   \n",
       "16              0.111111              0.111111            0.111111   \n",
       "14              0.111111              0.111111            0.111111   \n",
       "10              0.111111              0.111111            0.111111   \n",
       "19              0.111111              0.111111            0.111111   \n",
       "4               0.111111              0.111111            0.111111   \n",
       "3               0.111111              0.111111            0.111111   \n",
       "8                    NaN                   NaN                 NaN   \n",
       "5                    NaN                   NaN                 NaN   \n",
       "12                   NaN                   NaN                 NaN   \n",
       "13                   NaN                   NaN                 NaN   \n",
       "1                    NaN                   NaN                 NaN   \n",
       "17                   NaN                   NaN                 NaN   \n",
       "18                   NaN                   NaN                 NaN   \n",
       "0                    NaN                   NaN                 NaN   \n",
       "\n",
       "    std_test_Accuracy  rank_test_Accuracy  split0_test_Weighted_F1  \\\n",
       "7            0.009899                   2                 0.287912   \n",
       "6            0.007586                   1                 0.278133   \n",
       "2            0.041117                   3                 0.226892   \n",
       "15           0.041041                   4                 0.096380   \n",
       "9            0.016212                   5                 0.059347   \n",
       "11           0.044896                   6                 0.083275   \n",
       "16           0.000000                   7                 0.026864   \n",
       "14           0.000000                   7                 0.026864   \n",
       "10           0.000000                   7                 0.026864   \n",
       "19           0.000000                   7                 0.026864   \n",
       "4            0.000000                   7                 0.026864   \n",
       "3            0.000000                   7                 0.026864   \n",
       "8                 NaN                  13                      NaN   \n",
       "5                 NaN                  14                      NaN   \n",
       "12                NaN                  15                      NaN   \n",
       "13                NaN                  16                      NaN   \n",
       "1                 NaN                  17                      NaN   \n",
       "17                NaN                  18                      NaN   \n",
       "18                NaN                  19                      NaN   \n",
       "0                 NaN                  20                      NaN   \n",
       "\n",
       "    split1_test_Weighted_F1  split2_test_Weighted_F1  mean_test_Weighted_F1  \\\n",
       "7                  0.315538                 0.289612               0.297687   \n",
       "6                  0.296567                 0.249804               0.274834   \n",
       "2                  0.247841                 0.338115               0.270949   \n",
       "15                 0.208533                 0.135561               0.146825   \n",
       "9                  0.127820                 0.070243               0.085803   \n",
       "11                 0.020050                 0.020050               0.041125   \n",
       "16                 0.020050                 0.020050               0.022321   \n",
       "14                 0.020050                 0.020050               0.022321   \n",
       "10                 0.020050                 0.020050               0.022321   \n",
       "19                 0.020050                 0.020050               0.022321   \n",
       "4                  0.020050                 0.020050               0.022321   \n",
       "3                  0.020050                 0.020050               0.022321   \n",
       "8                       NaN                      NaN                    NaN   \n",
       "5                       NaN                      NaN                    NaN   \n",
       "12                      NaN                      NaN                    NaN   \n",
       "13                      NaN                      NaN                    NaN   \n",
       "1                       NaN                      NaN                    NaN   \n",
       "17                      NaN                      NaN                    NaN   \n",
       "18                      NaN                      NaN                    NaN   \n",
       "0                       NaN                      NaN                    NaN   \n",
       "\n",
       "    std_test_Weighted_F1  rank_test_Weighted_F1  \n",
       "7               0.012641                      1  \n",
       "6               0.019233                      2  \n",
       "2               0.048257                      3  \n",
       "15              0.046474                      4  \n",
       "9               0.030041                      5  \n",
       "11              0.029804                      6  \n",
       "16              0.003212                      7  \n",
       "14              0.003212                      7  \n",
       "10              0.003212                      7  \n",
       "19              0.003212                      7  \n",
       "4               0.003212                      7  \n",
       "3               0.003212                      7  \n",
       "8                    NaN                     13  \n",
       "5                    NaN                     14  \n",
       "12                   NaN                     15  \n",
       "13                   NaN                     16  \n",
       "1                    NaN                     17  \n",
       "17                   NaN                     18  \n",
       "18                   NaN                     19  \n",
       "0                    NaN                     20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"]).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_Weighted_F1</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_estimator</th>\n",
       "      <th>param_preprocessor__text__vectorizer</th>\n",
       "      <th>param_preprocessor__text__tfidf</th>\n",
       "      <th>param_preprocessor__numerical__scaler</th>\n",
       "      <th>param_preprocessor__numerical__imputer</th>\n",
       "      <th>param_feature_selector</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>mean_test_Weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.467427</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.297687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792286</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.318342</td>\n",
       "      <td>0.274834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.616956</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.270949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834035</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.146825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.619482</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.186067</td>\n",
       "      <td>0.085803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.826409</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.327260</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer(norm='l1')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.116242</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.122244</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.936100</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.392187</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(4, 4),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.008128</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>Normalizer()</td>\n",
       "      <td>SimpleImputer()</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3),\\n         ...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='median')</td>\n",
       "      <td>SelectFromModel(estimator=ElasticNet())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(stop_words=['de', 'la', 'que',...</td>\n",
       "      <td>TfidfTransformer()</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>VarianceThreshold()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2),\\n         ...</td>\n",
       "      <td>TfidfTransformer(norm='l1', sublinear_tf=True)</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>KNNImputer()</td>\n",
       "      <td>SelectFromModel(estimator=Ridge())</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_Weighted_F1  rank_test_Accuracy  mean_fit_time  \\\n",
       "7                       1                   2       2.467427   \n",
       "6                       2                   1       0.792286   \n",
       "2                       3                   3       5.616956   \n",
       "15                      4                   4       0.834035   \n",
       "9                       5                   5       1.619482   \n",
       "11                      6                   6       0.826409   \n",
       "16                      7                   7       1.327260   \n",
       "14                      7                   7       0.116242   \n",
       "10                      7                   7       1.122244   \n",
       "19                      7                   7       0.936100   \n",
       "4                       7                   7       0.396875   \n",
       "3                       7                   7       0.392187   \n",
       "8                      13                  13       0.009289   \n",
       "5                      14                  14       0.008128   \n",
       "12                     15                  15       0.007308   \n",
       "13                     16                  16       0.005617   \n",
       "1                      17                  17       0.009892   \n",
       "17                     18                  18       0.007428   \n",
       "18                     19                  19       0.009833   \n",
       "0                      20                  20       0.010212   \n",
       "\n",
       "                                      param_estimator  \\\n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "2   XGBClassifier(base_score=None, booster=None, c...   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "4   XGBClassifier(base_score=None, booster=None, c...   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "8   XGBClassifier(base_score=None, booster=None, c...   \n",
       "5   XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...   \n",
       "13  XGBClassifier(base_score=None, booster=None, c...   \n",
       "1   XGBClassifier(base_score=None, booster=None, c...   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...   \n",
       "18  XGBClassifier(base_score=None, booster=None, c...   \n",
       "0   XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                 param_preprocessor__text__vectorizer  \\\n",
       "7   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "6   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "2   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "15  CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "9   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "11  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "16  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "14  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "10  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "19  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "4   CountVectorizer(ngram_range=(3, 3),\\n         ...   \n",
       "3   CountVectorizer(ngram_range=(4, 4),\\n         ...   \n",
       "8   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "5   CountVectorizer(ngram_range=(1, 2),\\n         ...   \n",
       "12  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "13  CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "1   CountVectorizer(ngram_range=(1, 3),\\n         ...   \n",
       "17  CountVectorizer(ngram_range=(2, 3),\\n         ...   \n",
       "18  CountVectorizer(stop_words=['de', 'la', 'que',...   \n",
       "0   CountVectorizer(ngram_range=(2, 2),\\n         ...   \n",
       "\n",
       "                   param_preprocessor__text__tfidf  \\\n",
       "7                               TfidfTransformer()   \n",
       "6   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "2   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "15  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "9                      TfidfTransformer(norm='l1')   \n",
       "11                              TfidfTransformer()   \n",
       "16                     TfidfTransformer(norm='l1')   \n",
       "14                              TfidfTransformer()   \n",
       "10             TfidfTransformer(sublinear_tf=True)   \n",
       "19             TfidfTransformer(sublinear_tf=True)   \n",
       "4              TfidfTransformer(sublinear_tf=True)   \n",
       "3   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "8                               TfidfTransformer()   \n",
       "5   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "12  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "13  TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "1   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "17                              TfidfTransformer()   \n",
       "18                              TfidfTransformer()   \n",
       "0   TfidfTransformer(norm='l1', sublinear_tf=True)   \n",
       "\n",
       "   param_preprocessor__numerical__scaler  \\\n",
       "7                           Normalizer()   \n",
       "6                       StandardScaler()   \n",
       "2                       StandardScaler()   \n",
       "15                        RobustScaler()   \n",
       "9                           Normalizer()   \n",
       "11                          Normalizer()   \n",
       "16                      StandardScaler()   \n",
       "14                        MinMaxScaler()   \n",
       "10                        MinMaxScaler()   \n",
       "19                      StandardScaler()   \n",
       "4                           Normalizer()   \n",
       "3                         RobustScaler()   \n",
       "8                         MinMaxScaler()   \n",
       "5                           Normalizer()   \n",
       "12                      StandardScaler()   \n",
       "13                        MinMaxScaler()   \n",
       "1                         RobustScaler()   \n",
       "17                        RobustScaler()   \n",
       "18                        RobustScaler()   \n",
       "0                         RobustScaler()   \n",
       "\n",
       "     param_preprocessor__numerical__imputer  \\\n",
       "7                              KNNImputer()   \n",
       "6                              KNNImputer()   \n",
       "2                              KNNImputer()   \n",
       "15         SimpleImputer(strategy='median')   \n",
       "9                              KNNImputer()   \n",
       "11  SimpleImputer(strategy='most_frequent')   \n",
       "16  SimpleImputer(strategy='most_frequent')   \n",
       "14  SimpleImputer(strategy='most_frequent')   \n",
       "10                          SimpleImputer()   \n",
       "19                             KNNImputer()   \n",
       "4                           SimpleImputer()   \n",
       "3   SimpleImputer(strategy='most_frequent')   \n",
       "8                           SimpleImputer()   \n",
       "5                           SimpleImputer()   \n",
       "12  SimpleImputer(strategy='most_frequent')   \n",
       "13  SimpleImputer(strategy='most_frequent')   \n",
       "1   SimpleImputer(strategy='most_frequent')   \n",
       "17         SimpleImputer(strategy='median')   \n",
       "18  SimpleImputer(strategy='most_frequent')   \n",
       "0                              KNNImputer()   \n",
       "\n",
       "                     param_feature_selector  mean_test_Accuracy  \\\n",
       "7        SelectFromModel(estimator=Ridge())            0.314815   \n",
       "6   SelectFromModel(estimator=ElasticNet())            0.318342   \n",
       "2        SelectFromModel(estimator=Ridge())            0.290123   \n",
       "15  SelectFromModel(estimator=ElasticNet())            0.253968   \n",
       "9        SelectFromModel(estimator=Ridge())            0.186067   \n",
       "11  SelectFromModel(estimator=ElasticNet())            0.142857   \n",
       "16                      VarianceThreshold()            0.111111   \n",
       "14  SelectFromModel(estimator=ElasticNet())            0.111111   \n",
       "10       SelectFromModel(estimator=Ridge())            0.111111   \n",
       "19       SelectFromModel(estimator=Ridge())            0.111111   \n",
       "4   SelectFromModel(estimator=ElasticNet())            0.111111   \n",
       "3   SelectFromModel(estimator=ElasticNet())            0.111111   \n",
       "8   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "5                       VarianceThreshold()                 NaN   \n",
       "12       SelectFromModel(estimator=Ridge())                 NaN   \n",
       "13  SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "1   SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "17  SelectFromModel(estimator=ElasticNet())                 NaN   \n",
       "18                      VarianceThreshold()                 NaN   \n",
       "0        SelectFromModel(estimator=Ridge())                 NaN   \n",
       "\n",
       "    mean_test_Weighted_F1  \n",
       "7                0.297687  \n",
       "6                0.274834  \n",
       "2                0.270949  \n",
       "15               0.146825  \n",
       "9                0.085803  \n",
       "11               0.041125  \n",
       "16               0.022321  \n",
       "14               0.022321  \n",
       "10               0.022321  \n",
       "19               0.022321  \n",
       "4                0.022321  \n",
       "3                0.022321  \n",
       "8                     NaN  \n",
       "5                     NaN  \n",
       "12                    NaN  \n",
       "13                    NaN  \n",
       "1                     NaN  \n",
       "17                    NaN  \n",
       "18                    NaN  \n",
       "0                     NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.cv_results.sort_values(by=[\"rank_test_Weighted_F1\"])[[\n",
    "    'rank_test_Weighted_F1',\n",
    "    'rank_test_Accuracy',\n",
    "    'mean_fit_time',\n",
    "    'param_estimator',\n",
    "    'param_preprocessor__text__vectorizer',\n",
    "    'param_preprocessor__text__tfidf',\n",
    "    'param_preprocessor__numerical__scaler',\n",
    "    'param_preprocessor__numerical__imputer', 'param_feature_selector',\n",
    "    'mean_test_Accuracy',\n",
    "    'mean_test_Weighted_F1'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model using a sample-weighting mechanism to try to compensate for the dataset imbalance\n",
    "if retrain_with_class_weight:\n",
    "    sample_weights = compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_train,\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train, y_train, estimator__sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>macro_f1_score</th>\n",
       "      <th>weighted_f1_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>confusion_matrix_normalized</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.736583</td>\n",
       "      <td>0.169755</td>\n",
       "      <td>0.330421</td>\n",
       "      <td>0.169755</td>\n",
       "      <td>0.126593</td>\n",
       "      <td>0.202085</td>\n",
       "      <td>[[337, 16, 90, 64, 43, 181, 33, 16, 2], [0, 74...</td>\n",
       "      <td>[[0.0030052257040432324, 0.0001426813390643671...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROC_AUC  accuracy balanced_accuracy micro_f1_score macro_f1_score  \\\n",
       "0  0.736583  0.169755          0.330421       0.169755       0.126593   \n",
       "\n",
       "  weighted_f1_score                                   confusion_matrix  \\\n",
       "0          0.202085  [[337, 16, 90, 64, 43, 181, 33, 16, 2], [0, 74...   \n",
       "\n",
       "                         confusion_matrix_normalized  \\\n",
       "0  [[0.0030052257040432324, 0.0001426813390643671...   \n",
       "\n",
       "                               classification_report  \n",
       "0                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pipeline.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_decoded = label_encoder.inverse_transform(best_model['estimator'].classes_)\n",
    "\n",
    "with sns.axes_style(\"dark\"):\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=score.loc[0,'confusion_matrix'],\n",
    "                                display_labels=labels_decoded)\n",
    "    disp.plot(ax=ax, cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A510</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>782.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A511</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A514</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2091.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A529</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1576.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A530</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>48469.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A539</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.29</td>\n",
       "      <td>37927.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E109</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5022.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E119</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>13950.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E149</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2246.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.13</td>\n",
       "      <td>112138.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>112138.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score    support\n",
       "A510               0.02    0.43      0.04     782.00\n",
       "A511               0.02    0.99      0.03      75.00\n",
       "A514               0.03    0.20      0.05    2091.00\n",
       "A529               0.04    0.27      0.06    1576.00\n",
       "A530               0.45    0.09      0.15   48469.00\n",
       "A539               0.41    0.23      0.29   37927.00\n",
       "E109               0.12    0.29      0.17    5022.00\n",
       "E119               0.24    0.20      0.22   13950.00\n",
       "E149               0.09    0.28      0.13    2246.00\n",
       "accuracy           0.17    0.17      0.17       0.17\n",
       "macro avg          0.16    0.33      0.13  112138.00\n",
       "weighted avg       0.37    0.17      0.20  112138.00"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.loc[0,'classification_report'].round(2).rename(index={str(class_label):label for class_label, label in zip(best_model['estimator'].classes_, labels_decoded)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['categorical__Genero_Hombre', 'categorical__Genero_Mujer',\n",
       "       'categorical__GrupoEtnico_Blanco', ...,\n",
       "       'text__xiomarandrea26 gmail com', 'text__xmes educa vida',\n",
       "       'text__yadisofia gmail com'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.named_steps['feature_selector'].get_feature_names_out(best_model.named_steps['preprocessor'].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :['A530'], real: ['A539']\n"
     ]
    }
   ],
   "source": [
    "# Model test\n",
    "print(f'Predicted :{label_encoder.inverse_transform(best_model.predict(X_test.iloc[905].to_frame().T))}, real: {label_encoder.inverse_transform([y_test[905]])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/output/best_model_score.pickle']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dump(best_model, str(save_path))\n",
    "dump(score, str(save_path.parent / f'best_model_score{save_path.suffix}'))\n",
    "\n",
    "# class model_predictor():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the full prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/output/prediction_pipeline.pickle']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline = PredictionPipeline(estimator=best_model, preprocessing_fn=clean_and_preprocess_datasets, label_encoder=label_encoder)\n",
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dump(\n",
    "    prediction_pipeline,\n",
    "    str(save_path.parent / f\"prediction_pipeline{save_path.suffix}\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E149', 'A510', 'E109', ..., 'A539', 'A539', 'A510'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline.predict(X_test, preprocess_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E119', 'E109', 'E119', ..., 'E109', 'E109', 'A514'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline.predict(\n",
    "    X={\n",
    "        \"df_sociodemograficos\": pd.read_csv(\"data/sociodemografico.csv\", sep=\";\"),\n",
    "        \"df_laboratorios\": pd.read_csv(\"data/laboratorios.csv\", sep=\";\"),\n",
    "        \"df_notas\": pd.read_csv(\"data/notas.csv\", sep=\";\"),\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
